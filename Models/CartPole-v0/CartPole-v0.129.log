LOGGER started at 2020-01-28 17:10:21.620049.
Currently active debug channels:
	rollouts
	act
	training
	batch_info
	linesearch
	learning
	thread_rollouts
[2020-01-28 17:10:22.048680][__main__.TRPOAgent.log][learning]: Episode #0

[2020-01-28 17:10:22.259110][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:22.275540][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:22.276520][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:22.276749][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:22.282334][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:22.387069][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 31

[2020-01-28 17:10:22.415323][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 47

[2020-01-28 17:10:22.415973][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:22.416749][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:22.416839][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:22.419398][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:22.504574][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 29

[2020-01-28 17:10:22.513766][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 30

[2020-01-28 17:10:22.514359][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:22.514989][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:22.514940][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:22.516094][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:22.649606][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 47

[2020-01-28 17:10:22.655254][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 50

[2020-01-28 17:10:22.655895][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:22.656576][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:22.656648][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:22.659464][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:22.791849][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 40

[2020-01-28 17:10:22.792393][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 37

[2020-01-28 17:10:22.793369][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:22.793997][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:22.794128][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:22.796495][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:22.872289][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 27

[2020-01-28 17:10:22.877572][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 29

[2020-01-28 17:10:22.878161][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:22.879894][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 367, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:22.880254][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:22.880838][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 367

[2020-01-28 17:10:22.894678][__main__.TRPOAgent.log][training]: policy_gradient: [-1.70293532e-03  8.09763196e-04  6.76722457e-03  2.20814692e-02
  1.96556405e-02  2.68761417e-03  0.00000000e+00  0.00000000e+00
  8.08827173e-04  1.77888742e-03  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00 -3.84599036e-04  0.00000000e+00
 -2.77954414e-04  0.00000000e+00 -1.05968277e-03  1.85560129e-03
  0.00000000e+00 -6.88505551e-04  0.00000000e+00  3.14749519e-03
 -2.66422551e-03  0.00000000e+00 -1.33409946e-03  3.44225092e-04
  0.00000000e+00  0.00000000e+00  6.03013264e-05  0.00000000e+00
  3.26253363e-03  0.00000000e+00  3.57499145e-04  2.24471436e-02
  0.00000000e+00  0.00000000e+00  6.75538175e-03  1.48573936e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -3.21219835e-03  0.00000000e+00 -2.32149492e-03  0.00000000e+00
 -8.85054540e-03  1.54981132e-02  0.00000000e+00 -5.75044705e-03
  0.00000000e+00  2.62881024e-02 -2.22517999e-02  0.00000000e+00
 -1.11424930e-02  2.87499232e-03  0.00000000e+00  0.00000000e+00
  5.03640943e-04  0.00000000e+00  2.72489116e-02  0.00000000e+00
  2.98585814e-03 -1.35503656e-03  1.35503656e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -5.11299732e-04
  5.11299732e-04 -9.97022419e-04  9.97022419e-04  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -7.62710889e-04
  7.62710889e-04  0.00000000e+00  0.00000000e+00 -1.59053124e-03
  1.59053124e-03  0.00000000e+00  0.00000000e+00 -1.06288546e-03
  1.06288546e-03 -1.50257093e-03  1.50257093e-03  0.00000000e+00
  0.00000000e+00 -8.89879144e-04  8.89879144e-04  0.00000000e+00
  0.00000000e+00 -1.60512127e-03  1.60512127e-03 -1.08822986e-03
  1.08822986e-03  0.00000000e+00  0.00000000e+00 -1.77141422e-03
  1.77141422e-03 -2.87744246e-04  2.87744246e-04  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -7.44569363e-04
  7.44569363e-04  0.00000000e+00  0.00000000e+00 -1.05195999e-03
  1.05195999e-03  0.00000000e+00  0.00000000e+00 -1.73479810e-03
  1.73479810e-03 -2.39904237e-02  2.39904237e-02]

[2020-01-28 17:10:22.895391][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:22.963892][__main__.TRPOAgent.log][training]: gradient_step_direction: [-3.34822074e-01  1.17904530e+00  2.24585696e+00  5.74098543e+00
 -4.99197689e-02 -4.91792372e-01  0.00000000e+00  0.00000000e+00
 -1.48003027e-01 -3.25509247e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  7.03757593e-02  0.00000000e+00
  5.08614257e-02  0.00000000e+00  1.93905782e-01 -3.39546710e-01
  0.00000000e+00  1.25986015e-01  0.00000000e+00 -5.75943580e-01
  4.87512620e-01  0.00000000e+00  2.44119853e-01 -6.29879374e-02
  0.00000000e+00  0.00000000e+00 -1.10342181e-02  0.00000000e+00
 -5.96993863e-01  0.00000000e+00 -6.54168778e-02 -5.70096461e-02
  0.00000000e+00  0.00000000e+00 -1.71568318e-02 -3.77337407e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  8.15813354e-03  0.00000000e+00  5.89600700e-03  0.00000000e+00
  2.24780182e-02 -3.93609834e-02  0.00000000e+00  1.46046022e-02
  0.00000000e+00 -6.67646375e-02  5.65135833e-02  0.00000000e+00
  2.82989623e-02 -7.30169669e-03  0.00000000e+00  0.00000000e+00
 -1.27909439e-03  0.00000000e+00 -6.92048462e-02  0.00000000e+00
 -7.58323196e-03  2.47951016e-01 -2.47951016e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  9.35600495e-02
 -9.35600495e-02  1.82439890e-01 -1.82439890e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.39564453e-01
 -1.39564453e-01  0.00000000e+00  0.00000000e+00  2.91042946e-01
 -2.91042946e-01  0.00000000e+00  0.00000000e+00  1.94491818e-01
 -1.94491818e-01  2.74947554e-01 -2.74947554e-01  0.00000000e+00
  0.00000000e+00  1.62834303e-01 -1.62834303e-01  0.00000000e+00
  0.00000000e+00  2.93712701e-01 -2.93712701e-01  1.99129455e-01
 -1.99129455e-01  0.00000000e+00  0.00000000e+00  3.24141770e-01
 -3.24141770e-01  5.26528066e-02 -5.26528066e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.36244832e-01
 -1.36244832e-01  0.00000000e+00  0.00000000e+00  1.92492628e-01
 -1.92492628e-01  0.00000000e+00  0.00000000e+00  3.17441580e-01
 -3.17441580e-01  4.09237593e-02 -4.09237593e-02]

[2020-01-28 17:10:23.014126][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 2, New mean kl div: 0.0009498559960377444, New policy loss value: 0.000632559057388482

[2020-01-28 17:10:23.332321][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 81.04684542677154

[2020-01-28 17:10:23.332741][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:24.696624][__main__.TRPOAgent.log][learning]: Episode #1

[2020-01-28 17:10:24.697568][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:24.721755][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:24.723100][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:24.723345][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:24.728170][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:24.806840][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 20

[2020-01-28 17:10:24.810525][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 21

[2020-01-28 17:10:24.811283][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:24.811853][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:24.811919][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:24.815703][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:24.890555][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 21

[2020-01-28 17:10:24.901429][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 23

[2020-01-28 17:10:24.902063][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:24.902654][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:24.902760][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:24.905933][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:24.985008][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 19

[2020-01-28 17:10:24.990050][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 21

[2020-01-28 17:10:24.990648][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:24.991160][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:24.991367][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:24.995885][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:25.066454][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 17

[2020-01-28 17:10:25.070602][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 18

[2020-01-28 17:10:25.071027][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:25.071635][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:25.071567][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:25.072688][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:25.151837][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 21

[2020-01-28 17:10:25.155962][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 21

[2020-01-28 17:10:25.156488][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:25.158114][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 202, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:25.158490][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:25.159411][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 202

[2020-01-28 17:10:25.189256][__main__.TRPOAgent.log][training]: policy_gradient: [ 1.35016827e-04  4.97412092e-04 -1.49689681e-04 -1.21795446e-03
 -2.17951213e-03 -1.26203376e-02  0.00000000e+00  0.00000000e+00
 -3.68917567e-03 -8.24786107e-03  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  2.81213042e-03  0.00000000e+00
  3.12548976e-03  0.00000000e+00  6.65585380e-03 -8.11704265e-03
  0.00000000e+00  4.53410707e-03  0.00000000e+00 -1.47606530e-02
  1.50678925e-02  0.00000000e+00  8.83518063e-03 -1.49628490e-03
  0.00000000e+00  0.00000000e+00  4.67988676e-04  0.00000000e+00
 -1.59436522e-02  0.00000000e+00 -4.36696356e-05 -1.78160176e-02
  0.00000000e+00  0.00000000e+00 -5.20797628e-03 -1.16434317e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  3.03963760e-03  0.00000000e+00  3.37834836e-03  0.00000000e+00
  7.19432616e-03 -1.14587565e-02  0.00000000e+00  4.90092572e-03
  0.00000000e+00 -2.08374817e-02  1.62869162e-02  0.00000000e+00
  9.54996504e-03 -2.11229201e-03  0.00000000e+00  0.00000000e+00
  6.60655427e-04  0.00000000e+00 -2.25075111e-02  0.00000000e+00
 -6.16480338e-05  5.43676702e-03 -5.43676702e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.17710276e-03
 -2.17710276e-03  4.12187241e-03 -4.12187241e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  4.21354713e-03
 -4.21354713e-03  0.00000000e+00  0.00000000e+00  8.47664703e-03
 -8.47664703e-03  0.00000000e+00  0.00000000e+00  6.18177211e-03
 -6.18177211e-03  6.71693694e-03 -6.71693694e-03  0.00000000e+00
  0.00000000e+00  5.05797926e-03 -5.05797926e-03  0.00000000e+00
  0.00000000e+00  6.46229134e-03 -6.46229134e-03  7.26376805e-03
 -7.26376805e-03  0.00000000e+00  0.00000000e+00  1.00469577e-02
 -1.00469577e-02  1.29310988e-03 -1.29310988e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.85423737e-03
 -3.85423737e-03  0.00000000e+00  0.00000000e+00  3.50105817e-03
 -3.50105817e-03  0.00000000e+00  0.00000000e+00  8.84732787e-03
 -8.84732787e-03  2.43113071e-02 -2.43113071e-02]

[2020-01-28 17:10:25.189861][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:25.240498][__main__.TRPOAgent.log][training]: gradient_step_direction: [-2.20821947e-03 -2.48014972e-03  3.07234716e-03  4.01139041e-04
 -1.74524155e-02 -1.55625955e-02  0.00000000e+00  0.00000000e+00
 -4.54925618e-03 -1.01707363e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  3.46773999e-03  0.00000000e+00
  3.85415480e-03  0.00000000e+00  8.20757460e-03 -1.00094194e-02
  0.00000000e+00  5.59117181e-03  0.00000000e+00 -1.82018960e-02
  1.85807644e-02  0.00000000e+00  1.08949815e-02 -1.84512312e-03
  0.00000000e+00  0.00000000e+00  5.77093846e-04  0.00000000e+00
 -1.96606952e-02  0.00000000e+00 -5.38504963e-05 -1.42661537e-01
  0.00000000e+00  0.00000000e+00 -4.17028045e-02 -9.32346326e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -1.50831385e-02  0.00000000e+00 -1.67638722e-02  0.00000000e+00
 -3.56993275e-02 -9.17558483e-02  0.00000000e+00 -2.43191299e-02
  0.00000000e+00 -1.66855873e-01 -8.08181259e-02  0.00000000e+00
 -4.73883616e-02 -1.69141517e-02  0.00000000e+00  0.00000000e+00
  5.29019005e-03  0.00000000e+00 -1.80228612e-01  0.00000000e+00
 -4.93645784e-04  5.13739063e-03 -5.13739063e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.21311671e-03
 -2.21311671e-03  4.04573580e-03 -4.04573580e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.03887046e-03
 -5.03887046e-03  0.00000000e+00  0.00000000e+00  1.03393892e-02
 -1.03393892e-02  0.00000000e+00  0.00000000e+00  7.19036695e-03
 -7.19036695e-03  7.20107990e-03 -7.20107990e-03  0.00000000e+00
  0.00000000e+00  5.95610494e-03 -5.95610494e-03  0.00000000e+00
  0.00000000e+00  6.13389039e-03 -6.13389039e-03  7.86958455e-03
 -7.86958455e-03  0.00000000e+00  0.00000000e+00  1.18446405e-02
 -1.18446405e-02  1.39389689e-03 -1.39389689e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  4.71764446e-03
 -4.71764446e-03  0.00000000e+00  0.00000000e+00  2.41521844e-03
 -2.41521844e-03  0.00000000e+00  0.00000000e+00  1.07015390e-02
 -1.07015390e-02 -1.20636359e-01  1.20636359e-01]

[2020-01-28 17:10:25.279579][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.013367977089024732, New policy loss value: 0.0011836855357034274

[2020-01-28 17:10:25.345046][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 15.870294831720258

[2020-01-28 17:10:25.345457][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:26.383815][__main__.TRPOAgent.log][learning]: Episode #2

[2020-01-28 17:10:26.384435][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:26.399622][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:26.400422][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:26.400992][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:26.403364][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:26.437915][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 17:10:26.439325][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 10

[2020-01-28 17:10:26.439989][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:26.440743][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:26.440679][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:26.441564][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:26.477498][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 10

[2020-01-28 17:10:26.478479][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:10:26.479009][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:26.479518][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:26.479570][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:26.483146][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:26.523228][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 13

[2020-01-28 17:10:26.525940][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 13

[2020-01-28 17:10:26.526390][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:26.527125][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:26.527202][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:26.529342][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:26.564195][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:10:26.564866][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 10

[2020-01-28 17:10:26.565829][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:26.566674][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:26.566743][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:26.574311][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:26.591241][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 10

[2020-01-28 17:10:26.608380][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 12

[2020-01-28 17:10:26.609044][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:26.611403][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 108, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:26.611822][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:26.612232][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 108

[2020-01-28 17:10:26.626051][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  4.57501120e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.22163173e-05
 -1.22163173e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.13569917e-03 -1.13569917e-03]

[2020-01-28 17:10:26.626836][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:26.642018][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  9.59562369e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.56224911e-05
 -2.56224911e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.38201425e-03 -2.38201425e-03]

[2020-01-28 17:10:26.690299][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.0037911836094178847, New policy loss value: -0.0002062095994853671

[2020-01-28 17:10:26.741384][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 30.68145110204609

[2020-01-28 17:10:26.741802][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:27.568236][__main__.TRPOAgent.log][learning]: Episode #3

[2020-01-28 17:10:27.568805][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:27.588060][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:27.588685][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:27.588600][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:27.589773][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:27.624952][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 10

[2020-01-28 17:10:27.625408][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 12

[2020-01-28 17:10:27.626120][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:27.626598][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:27.626655][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:27.628719][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:27.659022][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:10:27.660590][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 10

[2020-01-28 17:10:27.667331][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:27.668182][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:27.668349][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:27.671993][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:27.701563][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 10

[2020-01-28 17:10:27.706255][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 11

[2020-01-28 17:10:27.706647][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:27.707192][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:27.707246][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:27.709160][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:27.742744][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:10:27.742145][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 10

[2020-01-28 17:10:27.744206][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:27.751163][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:27.751041][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:27.752236][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:27.790338][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 11

[2020-01-28 17:10:27.790539][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 10

[2020-01-28 17:10:27.791706][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:27.793016][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 104, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:27.793362][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:27.793849][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 104

[2020-01-28 17:10:27.813435][__main__.TRPOAgent.log][training]: policy_gradient: [-1.51345580e-04 -5.16023763e-04  4.45683187e-05  9.56780159e-04
  3.46858669e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  3.54885235e-04  0.00000000e+00
  4.42041671e-04  0.00000000e+00  7.92376609e-04  0.00000000e+00
  0.00000000e+00  5.50411602e-04  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  1.07493103e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  1.02690634e-04  0.00000000e+00
  0.00000000e+00  0.00000000e+00  1.02789120e-04  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  1.06613523e-03  0.00000000e+00  1.32796789e-03  0.00000000e+00
  2.38043326e-03  0.00000000e+00  0.00000000e+00  1.65352948e-03
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  3.22927449e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  1.54598351e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  3.08795889e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.50570975e-04
 -2.50570975e-04  0.00000000e+00  0.00000000e+00  6.87046633e-04
 -6.87046633e-04  0.00000000e+00  0.00000000e+00  1.84783451e-04
 -1.84783451e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.17078403e-04 -2.17078403e-04  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  4.43565317e-04
 -4.43565317e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  9.45914465e-04
 -9.45914465e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  9.45771903e-04
 -9.45771903e-04  3.66359860e-02 -3.66359860e-02]

[2020-01-28 17:10:27.814077][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:27.853221][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.04684034 -0.15970556  0.01379357  0.29611643  1.07350209  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.10983437  0.          0.13680865  0.
  0.24523474  0.          0.          0.17034835  0.          0.
  0.          0.          0.33268325  0.          0.          0.
  0.031782    0.          0.          0.          0.03181248  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.32996102  0.          0.41099631  0.
  0.7367266   0.          0.          0.51175523  0.          0.
  0.          0.          0.99943673  0.          0.          0.
  0.00272855  0.          0.          0.          0.09557006  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.07754988
 -0.07754988  0.          0.          0.21263588 -0.21263588  0.
  0.          0.05718912 -0.05718912  0.          0.          0.
  0.          0.06718417 -0.06718417  0.          0.          0.
  0.          0.          0.          0.          0.          0.13728021
 -0.13728021  0.          0.          0.          0.          0.
  0.          0.13106102 -0.13106102  0.          0.          0.
  0.          0.          0.          0.29270945 -0.29270945  0.06465985
 -0.06465985]

[2020-01-28 17:10:27.931498][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 3, New mean kl div: 0.0014917502420432086, New policy loss value: -0.007011787147918878

[2020-01-28 17:10:27.980556][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 16.827645101763594

[2020-01-28 17:10:27.980963][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:28.630064][__main__.TRPOAgent.log][learning]: Episode #4

[2020-01-28 17:10:28.630447][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:28.643904][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:28.644535][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:28.644698][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:28.648648][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:28.680329][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 9

[2020-01-28 17:10:28.682858][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 10

[2020-01-28 17:10:28.683588][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:28.684517][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:28.684579][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:28.690594][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:28.720104][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:10:28.726686][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 12

[2020-01-28 17:10:28.727338][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:28.727983][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:28.727928][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:28.729443][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:28.768350][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 10

[2020-01-28 17:10:28.771006][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 11

[2020-01-28 17:10:28.771739][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:28.772304][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:28.772375][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:28.774219][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:28.808344][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:10:28.808432][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 11

[2020-01-28 17:10:28.810160][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:28.810921][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:28.811016][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:28.813948][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:28.854910][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 10

[2020-01-28 17:10:28.855974][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 11

[2020-01-28 17:10:28.856775][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:28.858344][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 104, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:28.858686][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:28.859007][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 104

[2020-01-28 17:10:28.872225][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00170817 -0.0007372   0.00074033  0.00295851  0.03434296 -0.01211752
  0.          0.         -0.00323711 -0.00785548  0.          0.
  0.          0.          0.0035798   0.          0.00527057  0.
  0.00718182 -0.00692121  0.          0.00518078  0.         -0.01416096
  0.0134323   0.          0.01016032 -0.00127011  0.          0.
  0.00179557  0.         -0.01005915  0.          0.002927   -0.0036729
  0.          0.         -0.0008202  -0.00238105  0.          0.
  0.          0.          0.00179178  0.          0.00263805  0.
  0.00359467 -0.00175365  0.          0.00259311  0.         -0.00429228
  0.0013699   0.          0.00508549 -0.00032181  0.          0.
  0.00089873  0.         -0.00270681  0.          0.00146504  0.00288212
 -0.00288212  0.          0.          0.          0.          0.00142397
 -0.00142397  0.00245262 -0.00245262  0.          0.          0.
  0.          0.          0.          0.          0.          0.00467545
 -0.00467545  0.          0.          0.00884334 -0.00884334  0.
  0.          0.0074216  -0.0074216   0.00492849 -0.00492849  0.
  0.          0.00586983 -0.00586983  0.          0.          0.00347445
 -0.00347445  0.00644872 -0.00644872  0.          0.          0.01162156
 -0.01162156  0.00095969 -0.00095969  0.          0.          0.
  0.          0.00386421 -0.00386421  0.          0.          0.00036084
 -0.00036084  0.          0.          0.00847691 -0.00847691  0.01042495
 -0.01042495]

[2020-01-28 17:10:28.872661][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:28.946082][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.1594923   0.60763424  0.06318071 -0.7523551   3.25095539 -0.86899851
  0.          0.         -0.08523359 -0.56334951  0.          0.
  0.          0.         -0.07102723  0.         -0.10457392  0.
 -0.1424952  -0.1822364   0.         -0.10279246  0.         -1.01554202
 -0.4901332   0.         -0.20159208 -0.03344223  0.          0.
 -0.03562611  0.         -0.21928208  0.         -0.05807499 -0.21865487
  0.          0.          0.09744156 -0.14174836  0.          0.
  0.          0.         -0.00799446  0.         -0.01177032  0.
 -0.01603853  0.20833802  0.         -0.01156979  0.         -0.25552772
 -2.09229265  0.         -0.02269018  0.03823214  0.          0.
 -0.0040099   0.         -0.05626104  0.         -0.00653664  0.23169846
 -0.23169846  0.          0.          0.          0.          0.10533711
 -0.10533711  0.19223742 -0.19223742  0.          0.          0.
  0.          0.          0.          0.          0.         -0.08870842
  0.08870842  0.          0.         -0.16982511  0.16982511  0.
  0.         -0.13877486  0.13877486  0.27919799 -0.27919799  0.
  0.         -0.11043716  0.11043716  0.          0.          0.27841933
 -0.27841933  0.2287469  -0.2287469   0.          0.         -0.21878392
  0.21878392  0.05281891 -0.05281891  0.          0.          0.
  0.         -0.07429729  0.07429729  0.          0.          0.00936228
 -0.00936228  0.          0.         -0.16593741  0.16593741 -0.04651347
  0.04651347]

[2020-01-28 17:10:28.980538][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.006673040220995427, New policy loss value: -0.03433211898272546

[2020-01-28 17:10:29.027125][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 10.271363932057284

[2020-01-28 17:10:29.027519][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:29.730579][__main__.TRPOAgent.log][learning]: Episode #5

[2020-01-28 17:10:29.731328][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:29.746793][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:29.747709][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:29.747578][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:29.748638][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:29.787207][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 11

[2020-01-28 17:10:29.788278][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 9

[2020-01-28 17:10:29.789247][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:29.789746][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:29.789854][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:29.792144][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:29.821161][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 9

[2020-01-28 17:10:29.835563][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 16

[2020-01-28 17:10:29.835984][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:29.836594][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:29.836659][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:29.839993][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:29.878892][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 9

[2020-01-28 17:10:29.879980][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 13

[2020-01-28 17:10:29.881098][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:29.881687][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:29.881756][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:29.883945][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:29.904635][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 9

[2020-01-28 17:10:29.917180][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 11

[2020-01-28 17:10:29.918109][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:29.919011][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:29.919078][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:29.920889][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:29.960920][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 9

[2020-01-28 17:10:29.961744][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 12

[2020-01-28 17:10:29.962566][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:29.964654][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 108, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:29.965207][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:29.965739][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 108

[2020-01-28 17:10:29.987257][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00165502 -0.02414071  0.00259787  0.03855298  0.00289771  0.
  0.          0.         -0.01018957  0.          0.          0.
  0.          0.          0.01686845  0.          0.01709589  0.
  0.04157597 -0.01113376  0.          0.0279536   0.          0.
  0.          0.          0.05438735 -0.00173071  0.          0.
  0.00257958  0.          0.          0.         -0.00464065  0.
  0.          0.         -0.00066091  0.          0.          0.
  0.          0.          0.00109412  0.          0.00110887  0.
  0.0026967  -0.00072216  0.          0.00181312  0.          0.
  0.          0.          0.00352766 -0.00011226  0.          0.
  0.00016732  0.          0.          0.         -0.000301    0.
  0.          0.          0.          0.          0.          0.00916821
 -0.00916821  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.03563061
 -0.03563061  0.          0.          0.07145986 -0.07145986  0.
  0.          0.05249455 -0.05249455  0.03784498 -0.03784498  0.
  0.          0.04287213 -0.04287213  0.          0.          0.
  0.          0.          0.          0.          0.          0.0851445
 -0.0851445   0.00748001 -0.00748001  0.          0.          0.
  0.          0.03227499 -0.03227499  0.          0.          0.
  0.          0.          0.          0.07440123 -0.07440123  0.01297229
 -0.01297229]

[2020-01-28 17:10:29.988095][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:30.026560][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.01460598 -0.38301112  0.04063925  0.5990132  -0.26984315  0.
  0.          0.         -0.03607572  0.          0.          0.
  0.          0.          0.05972199  0.          0.06052724  0.
  0.14719787 -0.03941857  0.          0.09896848  0.          0.
  0.          0.          0.19255595 -0.00612751  0.          0.
  0.00913288  0.          0.          0.         -0.01643001  0.
  0.          0.          0.06154631  0.          0.          0.
  0.          0.         -0.10188759  0.         -0.10326139  0.
 -0.2511242   0.06724931  0.         -0.16884334  0.          0.
  0.          0.         -0.32850652  0.01045373  0.          0.
 -0.01558098  0.          0.          0.          0.0280301   0.
  0.          0.          0.          0.          0.          0.08287032
 -0.08287032  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.09935878
 -0.09935878  0.          0.          0.21619833 -0.21619833  0.
  0.          0.12946987 -0.12946987  0.24890853 -0.24890853  0.
  0.          0.11180776 -0.11180776  0.          0.          0.
  0.          0.          0.          0.          0.          0.22319312
 -0.22319312  0.04778101 -0.04778101  0.          0.          0.
  0.          0.09819009 -0.09819009  0.          0.          0.
  0.          0.          0.          0.24982967 -0.24982967 -1.20801755
  1.20801755]

[2020-01-28 17:10:30.068704][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.005063656901505845, New policy loss value: -0.04289676691573329

[2020-01-28 17:10:30.116620][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 9.63903354142827

[2020-01-28 17:10:30.117079][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:30.845046][__main__.TRPOAgent.log][learning]: Episode #6

[2020-01-28 17:10:30.845476][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:30.859797][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:30.860554][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:30.860379][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:30.861448][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:30.905654][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 11

[2020-01-28 17:10:30.906481][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 11

[2020-01-28 17:10:30.907379][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:30.908011][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:30.908082][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:30.910206][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:30.952147][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 10

[2020-01-28 17:10:30.953052][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 13

[2020-01-28 17:10:30.953877][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:30.954437][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:30.954378][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:30.955456][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:30.991663][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 10

[2020-01-28 17:10:30.992522][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 10

[2020-01-28 17:10:30.992928][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:30.993441][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:30.993507][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:30.995265][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:31.029296][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 10

[2020-01-28 17:10:31.032210][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:10:31.032611][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:31.033115][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:31.033168][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:31.035774][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:31.073299][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 11

[2020-01-28 17:10:31.073908][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 11

[2020-01-28 17:10:31.074921][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:31.076417][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 107, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:31.076787][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:31.077314][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 107

[2020-01-28 17:10:31.091301][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00205235  0.00661911  0.0009581  -0.0073775   0.04050258  0.
  0.          0.         -0.00230594  0.          0.          0.
  0.          0.          0.01663427  0.          0.02309223  0.
  0.03476936  0.00609075  0.          0.02471343  0.          0.
  0.          0.          0.04838848  0.00144523  0.          0.
  0.00702315  0.          0.          0.          0.01038266  0.
  0.          0.         -0.00179395  0.          0.          0.
  0.          0.          0.00065283  0.          0.00090627  0.
  0.02518666  0.00494678  0.          0.01790223  0.          0.
  0.          0.          0.03505225  0.00117379  0.          0.
  0.00027563  0.          0.          0.          0.00040748  0.
  0.          0.          0.          0.          0.          0.00257976
 -0.00257976  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.02523952
 -0.02523952  0.          0.          0.04917412 -0.04917412  0.
  0.          0.03810423 -0.03810423  0.01681238 -0.01681238  0.
  0.          0.03082814 -0.03082814  0.          0.          0.
  0.          0.          0.          0.          0.          0.0611702
 -0.0611702   0.00341991 -0.00341991  0.          0.          0.
  0.          0.02175271 -0.02175271  0.          0.          0.
  0.          0.          0.          0.04926529 -0.04926529  0.00524489
 -0.00524489]

[2020-01-28 17:10:31.091713][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:31.132095][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.02218795  0.64536096 -0.01286464 -0.93523759  0.83403939  0.
  0.          0.         -0.00560165  0.          0.          0.
  0.          0.          0.05337031  0.          0.07409036  0.
  0.11155591  0.02195874  0.          0.07929193  0.          0.
  0.          0.          0.15525222  0.00521044  0.          0.
  0.02253346  0.          0.          0.          0.03331228  0.
  0.          0.         -0.03550081  0.          0.          0.
  0.          0.         -0.0703984   0.         -0.09772929  0.
  0.51808749  0.10607582  0.          0.36824725  0.          0.
  0.          0.          0.72102172  0.02517     0.          0.
 -0.02972288  0.          0.          0.         -0.04394072  0.
  0.          0.          0.          0.          0.         -0.04321289
  0.04321289  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.08051924
 -0.08051924  0.          0.          0.15282349 -0.15282349  0.
  0.          0.11260446 -0.11260446 -0.0929757   0.0929757   0.
  0.          0.09519469 -0.09519469  0.          0.          0.
  0.          0.          0.          0.          0.          0.18966538
 -0.18966538 -0.01693362  0.01693362  0.          0.          0.
  0.          0.06415721 -0.06415721  0.          0.          0.
  0.          0.          0.          0.14845936 -0.14845936 -0.56559133
  0.56559133]

[2020-01-28 17:10:31.168467][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.003354303235669396, New policy loss value: -0.02625476510991155

[2020-01-28 17:10:31.214016][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 8.7695284223654

[2020-01-28 17:10:31.214495][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:31.841430][__main__.TRPOAgent.log][learning]: Episode #7

[2020-01-28 17:10:31.841806][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:31.856658][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:31.857275][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:31.857352][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:31.858983][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:31.895364][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 12

[2020-01-28 17:10:31.896203][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 9

[2020-01-28 17:10:31.896995][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:31.897831][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:31.897749][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:31.899491][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:31.932267][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:10:31.940242][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 13

[2020-01-28 17:10:31.940645][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:31.941365][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:31.941600][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:31.943960][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:31.980107][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 11

[2020-01-28 17:10:31.983555][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 10

[2020-01-28 17:10:31.984188][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:31.985152][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:31.985004][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:31.986590][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:32.014825][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 9

[2020-01-28 17:10:32.014072][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 9

[2020-01-28 17:10:32.016055][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:32.016787][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:32.016719][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:32.018328][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:32.054837][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 10

[2020-01-28 17:10:32.058139][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 10

[2020-01-28 17:10:32.058632][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:32.060682][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 103, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:32.061212][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:32.061757][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 103

[2020-01-28 17:10:32.077598][__main__.TRPOAgent.log][training]: policy_gradient: [-3.77519605e-03 -5.77373460e-02  6.47818014e-03  9.16913062e-02
 -4.68262074e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -4.88430148e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  2.14288007e-02  0.00000000e+00
  3.20729982e-02  0.00000000e+00  4.16360554e-02  8.14125267e-04
  0.00000000e+00  3.04527198e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  5.98114489e-02  4.84419914e-04
  0.00000000e+00  0.00000000e+00  1.07558637e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  1.89376781e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  7.25879861e-05  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -1.32704464e-03  0.00000000e+00 -1.98621944e-03  0.00000000e+00
 -7.38405379e-03 -3.15972600e-05  0.00000000e+00 -5.40071625e-03
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -1.06074159e-02 -1.88009666e-05  0.00000000e+00  0.00000000e+00
 -1.90752642e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -3.35855144e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.56782522e-03
 -5.56782522e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.72182450e-02
 -2.72182450e-02  0.00000000e+00  0.00000000e+00  5.20181777e-02
 -5.20181777e-02  0.00000000e+00  0.00000000e+00  3.98984544e-02
 -3.98984544e-02  2.63573274e-02 -2.63573274e-02  0.00000000e+00
  0.00000000e+00  3.19274665e-02 -3.19274665e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  6.32846182e-02
 -6.32846182e-02  5.26233705e-03 -5.26233705e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.25617639e-02
 -2.25617639e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.06374230e-02
 -5.06374230e-02 -2.40340930e-02  2.40340930e-02]

[2020-01-28 17:10:32.078210][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:32.118990][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.10714416 -0.18611463  0.19099568  0.51902649  0.00622254  0.
  0.          0.          0.00756578  0.          0.          0.
  0.          0.          0.0818658   0.          0.12253044  0.
  0.15906516  0.00277608  0.          0.11634066  0.          0.
  0.          0.          0.22850186  0.00165192  0.          0.
  0.04109126  0.          0.          0.          0.07234866  0.
  0.          0.          0.06098811  0.          0.          0.
  0.          0.          0.00123997  0.          0.00185588  0.
 -0.31851129 -0.00274148  0.         -0.23296     0.          0.
  0.          0.         -0.45755109 -0.0016312   0.          0.
 -0.08228122  0.          0.          0.         -0.14487126  0.
  0.          0.          0.          0.          0.          0.05187484
 -0.05187484  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.10342828
 -0.10342828  0.          0.          0.19825287 -0.19825287  0.
  0.          0.05554742 -0.05554742  0.11445602 -0.11445602  0.
  0.          0.05134714 -0.05134714  0.          0.          0.
  0.          0.          0.          0.          0.          0.10310107
 -0.10310107  0.02217179 -0.02217179  0.          0.          0.
  0.          0.08292103 -0.08292103  0.          0.          0.
  0.          0.          0.          0.18654616 -0.18654616 -1.03671096
  1.03671096]

[2020-01-28 17:10:32.159299][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.004216488712781487, New policy loss value: -0.04235834831084291

[2020-01-28 17:10:32.208991][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 5.031114534992367

[2020-01-28 17:10:32.209399][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:32.848297][__main__.TRPOAgent.log][learning]: Episode #8

[2020-01-28 17:10:32.848851][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:32.862631][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:32.863234][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:32.863433][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:32.868000][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:32.896629][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 17:10:32.904010][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 10

[2020-01-28 17:10:32.904721][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:32.905434][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:32.905511][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:32.907887][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:32.942411][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:10:32.943190][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 10

[2020-01-28 17:10:32.943800][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:32.944332][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:32.944404][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:32.945875][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:32.979617][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 10

[2020-01-28 17:10:32.981510][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 10

[2020-01-28 17:10:32.982566][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:32.983722][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:32.983962][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:32.986948][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:33.016113][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 10

[2020-01-28 17:10:33.017551][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 9

[2020-01-28 17:10:33.018661][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:33.019622][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:33.019725][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:33.021501][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:33.060132][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 10

[2020-01-28 17:10:33.060447][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 12

[2020-01-28 17:10:33.061559][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:33.062913][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 101, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:33.063269][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:33.063684][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 101

[2020-01-28 17:10:33.077865][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00230407  0.00453552  0.00177874 -0.00415761  0.03278566  0.
  0.          0.         -0.00129038  0.          0.          0.
  0.          0.          0.01460806  0.          0.02304435  0.
  0.02443388  0.00363353  0.          0.01816215  0.          0.
  0.          0.          0.03573299  0.0008872   0.          0.
  0.00817446  0.          0.          0.          0.01549396  0.
  0.          0.         -0.00092048  0.          0.          0.
  0.          0.          0.00903007  0.          0.01424501  0.
  0.00797753  0.00252986  0.          0.00592985  0.          0.
  0.          0.          0.01166663  0.00061772  0.          0.
  0.0050531   0.          0.          0.          0.00957769  0.
  0.          0.          0.          0.          0.          0.00187307
 -0.00187307  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.01540231
 -0.01540231  0.          0.          0.02971605 -0.02971605  0.
  0.          0.02657104 -0.02657104  0.01166917 -0.01166917  0.
  0.          0.02093673 -0.02093673  0.          0.          0.
  0.          0.          0.          0.          0.          0.04143691
 -0.04143691  0.00242123 -0.00242123  0.          0.          0.
  0.          0.01249564 -0.01249564  0.          0.          0.
  0.          0.          0.          0.02808171 -0.02808171  0.02436249
 -0.02436249]

[2020-01-28 17:10:33.078411][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:33.118719][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.02875022  0.23464812  0.02747966 -0.32762341  0.275694    0.
  0.          0.         -0.00453367  0.          0.          0.
  0.          0.          0.02807095  0.          0.04428218  0.
  0.04695231  0.00971705  0.          0.03490052  0.          0.
  0.          0.          0.06866477  0.00237261  0.          0.
  0.0157081   0.          0.          0.          0.02977331  0.
  0.          0.         -0.01287542  0.          0.          0.
  0.          0.          0.07545447  0.          0.11903009  0.
 -0.07334139  0.03082629  0.         -0.05451602  0.          0.
  0.          0.         -0.10725713  0.00752686  0.          0.
  0.04222323  0.          0.          0.          0.08003039  0.
  0.          0.          0.          0.          0.         -0.0073618
  0.0073618   0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.0255325
 -0.0255325   0.          0.          0.05366338 -0.05366338  0.
  0.          0.03899219 -0.03899219  0.0027299  -0.0027299   0.
  0.          0.0314724  -0.0314724   0.          0.          0.
  0.          0.          0.          0.          0.          0.06243448
 -0.06243448  0.00147078 -0.00147078  0.          0.          0.
  0.          0.02059546 -0.02059546  0.          0.          0.
  0.          0.          0.          0.04830653 -0.04830653 -0.22397642
  0.22397642]

[2020-01-28 17:10:33.157170][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.004274658361823423, New policy loss value: -0.0054280305132834526

[2020-01-28 17:10:33.208700][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 7.4578090352421205

[2020-01-28 17:10:33.209108][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:33.863181][__main__.TRPOAgent.log][learning]: Episode #9

[2020-01-28 17:10:33.863600][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:33.879614][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:33.880217][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:33.880404][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:33.883154][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:33.923722][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 11

[2020-01-28 17:10:33.924634][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 10

[2020-01-28 17:10:33.925079][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:33.925558][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:33.925608][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:33.927360][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:33.962247][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:10:33.967515][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 12

[2020-01-28 17:10:33.967906][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:33.968551][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:33.968401][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:33.969661][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:34.007447][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 10

[2020-01-28 17:10:34.007509][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 10

[2020-01-28 17:10:34.008669][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:34.009282][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:34.009383][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:34.011491][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:34.048537][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 11

[2020-01-28 17:10:34.052955][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 12

[2020-01-28 17:10:34.053889][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:34.055015][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:34.055097][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:34.059056][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:34.085229][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 9

[2020-01-28 17:10:34.095400][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 9

[2020-01-28 17:10:34.096167][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:34.097904][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 104, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:34.098606][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:34.099160][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 104

[2020-01-28 17:10:34.112354][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.00200205 -0.01763068  0.00086604  0.02309107 -0.07260566  0.
  0.          0.          0.00353092  0.          0.          0.
  0.          0.         -0.03182828  0.         -0.05233051  0.
 -0.05264836 -0.00719511  0.         -0.03952888  0.          0.
  0.          0.         -0.0778523  -0.00188427  0.          0.
 -0.0188102   0.          0.          0.         -0.03712195  0.
  0.          0.          0.00204943  0.          0.          0.
  0.          0.         -0.0184739   0.         -0.03037389  0.
 -0.03055838 -0.00417622  0.         -0.02294352  0.          0.
  0.          0.         -0.04518736 -0.00109368  0.          0.
 -0.01091789  0.          0.          0.         -0.02154648  0.
  0.          0.          0.          0.          0.         -0.00293514
  0.00293514  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -0.03506029
  0.03506029  0.          0.         -0.06555995  0.06555995  0.
  0.         -0.05248722  0.05248722 -0.02483259  0.02483259  0.
  0.         -0.04124238  0.04124238  0.          0.          0.
  0.          0.          0.          0.          0.         -0.08160239
  0.08160239 -0.0052033   0.0052033   0.          0.          0.
  0.         -0.02701278  0.02701278  0.          0.          0.
  0.          0.          0.         -0.05954862  0.05954862 -0.08236966
  0.08236966]

[2020-01-28 17:10:34.112936][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:34.142233][__main__.TRPOAgent.log][training]: gradient_step_direction: [-1.67439362e-02 -5.24710653e-01  4.49859166e-02  7.97209492e-01
 -3.15337818e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -1.31563947e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  1.18594177e-03  0.00000000e+00
  1.94986818e-03  0.00000000e+00  1.96171077e-03  2.68095237e-04
  0.00000000e+00  1.47287080e-03  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  2.90082562e-03  7.02092432e-05
  0.00000000e+00  0.00000000e+00  7.00880198e-04  0.00000000e+00
  0.00000000e+00  0.00000000e+00  1.38318834e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  8.90100058e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -8.02350671e-02  0.00000000e+00 -1.31918596e-01  0.00000000e+00
 -1.32719852e-01 -1.81379682e-02  0.00000000e+00 -9.96473004e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -1.96255802e-01 -4.75000663e-03  0.00000000e+00  0.00000000e+00
 -4.74181336e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -9.35797522e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.13962852e-02
 -1.13962852e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -8.95200129e-03
  8.95200129e-03  0.00000000e+00  0.00000000e+00 -1.73541187e-02
  1.73541187e-02  0.00000000e+00  0.00000000e+00  6.51555683e-04
 -6.51555683e-04  1.50647587e-02 -1.50647587e-02  0.00000000e+00
  0.00000000e+00  8.46835736e-04 -8.46835736e-04  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.74101938e-03
 -1.74101938e-03  2.25364125e-03 -2.25364125e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.34592101e-03
  3.34592101e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -7.02738251e-03
  7.02738251e-03 -3.57744385e-01  3.57744385e-01]

[2020-01-28 17:10:34.172432][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.014580731123365442, New policy loss value: -0.06163011992296826

[2020-01-28 17:10:34.223341][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 3.4995881880570847

[2020-01-28 17:10:34.223744][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:34.846964][__main__.TRPOAgent.log][learning]: Episode #10

[2020-01-28 17:10:34.847368][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:34.861946][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:34.862608][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:34.862491][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:34.863616][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:34.909275][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 17:10:34.909523][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 11

[2020-01-28 17:10:34.910636][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:34.911402][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:34.911459][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:34.914836][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:34.946437][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 11

[2020-01-28 17:10:34.951842][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 11

[2020-01-28 17:10:34.952286][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:34.953060][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:34.953139][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:34.957019][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:34.998792][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 14

[2020-01-28 17:10:35.006374][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 15

[2020-01-28 17:10:35.006931][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:35.007577][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:35.007514][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:35.008639][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:35.043662][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 10

[2020-01-28 17:10:35.045116][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:10:35.046033][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:35.046523][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:35.046576][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:35.048180][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:35.090197][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 14

[2020-01-28 17:10:35.090280][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 12

[2020-01-28 17:10:35.091473][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:35.093541][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 118, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:35.094066][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:35.094626][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 118

[2020-01-28 17:10:35.113050][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00090497 -0.01046183  0.0009521   0.0167756   0.00876941  0.
  0.          0.         -0.00068572  0.          0.          0.
  0.          0.          0.00941449  0.          0.01537041  0.
  0.01620887  0.00284868  0.          0.01218448  0.          0.
  0.          0.          0.0240004   0.00067187  0.          0.
  0.00564387  0.          0.          0.          0.01112074  0.
  0.          0.         -0.00028259  0.          0.          0.
  0.          0.          0.00215814  0.          0.00352346  0.
  0.00371566  0.00073514  0.          0.00279313  0.          0.
  0.          0.          0.00550177  0.00015402  0.          0.
  0.00129378  0.          0.          0.          0.00254928  0.
  0.          0.          0.          0.          0.          0.00133999
 -0.00133999  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.00998671
 -0.00998671  0.          0.          0.01872816 -0.01872816  0.
  0.          0.01549169 -0.01549169  0.00814259 -0.00814259  0.
  0.          0.01220743 -0.01220743  0.          0.          0.
  0.          0.          0.          0.          0.          0.02416047
 -0.02416047  0.00166578 -0.00166578  0.          0.          0.
  0.          0.00790872 -0.00790872  0.          0.          0.
  0.          0.          0.          0.01749757 -0.01749757 -0.00495586
  0.00495586]

[2020-01-28 17:10:35.113533][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:35.154693][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 1.11951034e-03  1.42841856e-04 -3.20724014e-03  3.58469091e-03
  4.61050514e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -2.62590742e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  2.28386620e-02  0.00000000e+00
  3.72871707e-02  0.00000000e+00  3.93211811e-02  6.14631184e-03
  0.00000000e+00  2.95584024e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  5.82227082e-02  1.62988637e-03
  0.00000000e+00  0.00000000e+00  1.36915029e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  2.69778637e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00 -2.48869817e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  1.15356596e-02  0.00000000e+00  1.88335078e-02  0.00000000e+00
  1.98608726e-02  2.34556470e-04  0.00000000e+00  1.49297568e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  2.94079112e-02  8.23245228e-04  0.00000000e+00  0.00000000e+00
  6.91548948e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  1.36263447e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.43569195e-03
 -2.43569195e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.39522197e-02
 -2.39522197e-02  0.00000000e+00  0.00000000e+00  4.52183788e-02
 -4.52183788e-02  0.00000000e+00  0.00000000e+00  3.58599068e-02
 -3.58599068e-02  1.85625500e-02 -1.85625500e-02  0.00000000e+00
  0.00000000e+00  2.82981887e-02 -2.82981887e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.60145744e-02
 -5.60145744e-02  3.80901489e-03 -3.80901489e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.88851721e-02
 -1.88851721e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  4.19072803e-02
 -4.19072803e-02 -2.10170504e-01  2.10170504e-01]

[2020-01-28 17:10:35.194405][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.003842507511340617, New policy loss value: -0.010294082828984183

[2020-01-28 17:10:35.246839][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 11.43081896248222

[2020-01-28 17:10:35.247338][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:35.981896][__main__.TRPOAgent.log][learning]: Episode #11

[2020-01-28 17:10:35.982258][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:35.996696][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:35.997307][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:35.997426][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:35.999918][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:36.032842][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 17:10:36.033240][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 10

[2020-01-28 17:10:36.034518][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:36.035333][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:36.035449][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:36.040161][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:36.072037][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:10:36.075908][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 11

[2020-01-28 17:10:36.076602][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:36.077304][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:36.077438][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:36.079267][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:36.113178][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 10

[2020-01-28 17:10:36.113659][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 10

[2020-01-28 17:10:36.114675][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:36.115176][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:36.115234][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:36.117155][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:36.153299][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 11

[2020-01-28 17:10:36.156856][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 11

[2020-01-28 17:10:36.157577][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:36.158223][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:36.158294][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:36.163212][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:36.191326][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 11

[2020-01-28 17:10:36.206406][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 11

[2020-01-28 17:10:36.207211][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:36.208889][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 105, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:36.209270][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:36.209781][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 105

[2020-01-28 17:10:36.224886][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00433029  0.00892606  0.00137044 -0.00837865  0.09651124  0.
  0.          0.         -0.00161301  0.          0.          0.
  0.          0.          0.03808547  0.          0.06348706  0.
  0.06442119  0.0139397   0.          0.04871346  0.          0.
  0.          0.          0.09601205  0.00316704  0.          0.
  0.02379979  0.          0.          0.          0.04789963  0.
  0.          0.         -0.00094814  0.          0.          0.
  0.          0.          0.02213698  0.          0.04157179  0.
  0.03744449  0.00831465  0.          0.02831445  0.          0.
  0.          0.          0.05580652  0.00184083  0.          0.
  0.01383351  0.          0.          0.          0.02784142  0.
  0.          0.          0.          0.          0.          0.00300813
 -0.00300813  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.03761981
 -0.03761981  0.          0.          0.07040128 -0.07040128  0.
  0.          0.05650959 -0.05650959  0.02664827 -0.02664827  0.
  0.          0.04440695 -0.04440695  0.          0.          0.
  0.          0.          0.          0.          0.          0.0878646
 -0.0878646   0.00563052 -0.00563052  0.          0.          0.
  0.          0.02903089 -0.02903089  0.          0.          0.
  0.          0.          0.          0.06400087 -0.06400087  0.10000243
 -0.10000243]

[2020-01-28 17:10:36.225379][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:36.264548][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.00327175 -0.33882943  0.01167279  0.49673013 -0.16730621  0.
  0.          0.         -0.00356318  0.          0.          0.
  0.          0.          0.08476053  0.          0.14129268  0.
  0.14337161  0.03205441  0.          0.10841351  0.          0.
  0.          0.          0.21367817  0.00704836  0.          0.
  0.05296727  0.          0.          0.          0.1066023   0.
  0.          0.          0.00107546  0.          0.          0.
  0.          0.         -0.0386227   0.          0.06048303  0.
 -0.06532992 -0.00906746  0.         -0.04940061  0.          0.
  0.          0.         -0.09736639 -0.00321171  0.          0.
 -0.02413551  0.          0.          0.         -0.04857529  0.
  0.          0.          0.          0.          0.          0.01516837
 -0.01516837  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.0841928
 -0.0841928   0.          0.          0.15623019 -0.15623019  0.
  0.          0.14164756 -0.14164756  0.07603014 -0.07603014  0.
  0.          0.11103283 -0.11103283  0.          0.          0.
  0.          0.          0.          0.          0.          0.21963768
 -0.21963768  0.01512914 -0.01512914  0.          0.          0.
  0.          0.06653244 -0.06653244  0.          0.          0.
  0.          0.          0.          0.14559542 -0.14559542  0.14549396
 -0.14549396]

[2020-01-28 17:10:36.296723][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.014692952809557024, New policy loss value: -0.07278152350348151

[2020-01-28 17:10:36.346880][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 8.330055862132992

[2020-01-28 17:10:36.347291][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:37.052332][__main__.TRPOAgent.log][learning]: Episode #12

[2020-01-28 17:10:37.052898][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:37.067498][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:37.068881][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:37.068764][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:37.070112][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:37.102632][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 9

[2020-01-28 17:10:37.106312][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 9

[2020-01-28 17:10:37.107319][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:37.107918][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:37.107848][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:37.109059][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:37.145840][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 11

[2020-01-28 17:10:37.148749][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 11

[2020-01-28 17:10:37.149298][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:37.149995][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:37.150111][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:37.153457][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:37.178887][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 9

[2020-01-28 17:10:37.182351][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 9

[2020-01-28 17:10:37.182921][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:37.183643][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:37.183756][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:37.187660][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:37.231608][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:10:37.235872][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 13

[2020-01-28 17:10:37.236347][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:37.237016][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:37.236931][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:37.237966][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:37.271414][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 9

[2020-01-28 17:10:37.273473][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 9

[2020-01-28 17:10:37.274648][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:37.275960][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 99, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:37.276306][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:37.276629][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 99

[2020-01-28 17:10:37.292179][__main__.TRPOAgent.log][training]: policy_gradient: [ 6.83626538e-03  5.67147606e-02 -7.98316044e-03 -9.29005485e-02
 -5.26397194e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -3.01879127e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00 -4.75841136e-02  0.00000000e+00
 -8.13042724e-02  0.00000000e+00 -8.03926999e-02 -2.30068469e-02
  0.00000000e+00 -6.12804941e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00 -1.20880621e-01 -4.97179666e-03
  0.00000000e+00  0.00000000e+00 -3.14736322e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00 -6.48039223e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00 -6.69690057e-05  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -1.03698178e-02  0.00000000e+00 -2.80101012e-02  0.00000000e+00
 -1.75196634e-02 -5.01379122e-03  0.00000000e+00 -1.33546159e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -2.63430361e-02 -1.08348400e-03  0.00000000e+00  0.00000000e+00
 -6.85892428e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -1.41224627e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.35665151e-03
  4.35665151e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.14563426e-02
  4.14563426e-02  0.00000000e+00  0.00000000e+00 -7.83795052e-02
  7.83795052e-02  0.00000000e+00  0.00000000e+00 -6.55013347e-02
  6.55013347e-02 -3.03886286e-02  3.03886286e-02  0.00000000e+00
  0.00000000e+00 -5.11912051e-02  5.11912051e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.01232996e-01
  1.01232996e-01 -6.27513460e-03  6.27513460e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.15311961e-02
  3.15311961e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.87756114e-02
  6.87756114e-02 -5.12129369e-02  5.12129369e-02]

[2020-01-28 17:10:37.292824][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:37.357188][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 2.17151276e+00  1.39005601e-02 -3.46718717e+00 -2.58648511e+00
  1.67419455e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00
  9.38853406e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  6.91471422e-02  0.00000000e+00
  1.18148112e-01  0.00000000e+00  1.16823955e-01  3.34333808e-02
  0.00000000e+00  8.90507470e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  1.75659643e-01  7.22493205e-03
  0.00000000e+00  0.00000000e+00  4.57361822e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  9.41703367e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  1.81100886e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  3.28559091e-02  0.00000000e+00 -4.32848424e-01  0.00000000e+00
  5.55098041e-02  1.58859899e-02  0.00000000e+00  4.23131492e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  8.34660337e-02  3.43296278e-03  0.00000000e+00  0.00000000e+00
  2.17319542e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  4.47458846e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -8.96917484e-02
  8.96917484e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.92662440e-02
 -5.92662440e-02  0.00000000e+00  0.00000000e+00  8.68462397e-02
 -8.68462397e-02  0.00000000e+00  0.00000000e+00  9.11529697e-02
 -9.11529697e-02  4.13034767e-02 -4.13034767e-02  0.00000000e+00
  0.00000000e+00  7.13104727e-02 -7.13104727e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.41033893e-01
 -1.41033893e-01  8.63401343e-03 -8.63401343e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  4.49525318e-02
 -4.49525318e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  9.83084179e-02
 -9.83084179e-02 -7.91409132e-01  7.91409132e-01]

[2020-01-28 17:10:37.398447][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.005004968224239673, New policy loss value: -0.11254566268264048

[2020-01-28 17:10:37.446529][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 4.2824800474239355

[2020-01-28 17:10:37.446934][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:38.151493][__main__.TRPOAgent.log][learning]: Episode #13

[2020-01-28 17:10:38.151913][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:38.165983][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:38.166659][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:38.166532][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:38.167613][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:38.200632][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 9

[2020-01-28 17:10:38.204062][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 11

[2020-01-28 17:10:38.204484][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:38.204976][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:38.205059][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:38.208484][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:38.238706][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 9

[2020-01-28 17:10:38.239411][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 9

[2020-01-28 17:10:38.240131][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:38.240740][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:38.240670][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:38.241767][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:38.279264][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 9

[2020-01-28 17:10:38.280237][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 12

[2020-01-28 17:10:38.281047][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:38.281527][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:38.281588][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:38.283344][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:38.315414][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 9

[2020-01-28 17:10:38.314879][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 10

[2020-01-28 17:10:38.316430][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:38.316987][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:38.317102][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:38.319790][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:38.357356][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 11

[2020-01-28 17:10:38.358499][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 9

[2020-01-28 17:10:38.359270][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:38.360625][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 98, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:38.360959][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:38.361289][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 98

[2020-01-28 17:10:38.375444][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.00627867  0.02765141 -0.00564424 -0.04954233 -0.07949706  0.
  0.          0.          0.00329462  0.          0.          0.
  0.          0.         -0.03611469  0.         -0.06113948  0.
 -0.06061519 -0.01788248  0.         -0.0462767   0.          0.
  0.          0.         -0.09129895 -0.00386657  0.          0.
 -0.02411384  0.          0.          0.         -0.04987661  0.
  0.          0.          0.00128815  0.          0.          0.
  0.          0.         -0.01522833  0.         -0.02578043  0.
 -0.02508149 -0.00709291  0.         -0.01914848  0.          0.
  0.          0.         -0.03777789 -0.00159992  0.          0.
 -0.01016798  0.          0.          0.         -0.02103126  0.
  0.          0.          0.          0.          0.         -0.00287344
  0.00287344  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -0.03068763
  0.03068763  0.          0.         -0.05463144  0.05463144  0.
  0.         -0.04771777  0.04771777 -0.0212953   0.0212953   0.
  0.         -0.03726653  0.03726653  0.          0.          0.
  0.          0.          0.          0.          0.         -0.07369113
  0.07369113 -0.00444141  0.00444141  0.          0.          0.
  0.         -0.02313037  0.02313037  0.          0.          0.
  0.          0.          0.         -0.05041966  0.05041966 -0.03384841
  0.03384841]

[2020-01-28 17:10:38.376069][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:38.466529][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 1.41791564 -0.67116848 -2.21364634 -1.1613764  -1.80823766  0.
  0.          0.         -0.02488155  0.          0.          0.
  0.          0.          0.01804228  0.          0.03054384  0.
  0.12288269  0.09226671  0.          0.0938149   0.          0.
  0.          0.          0.1850867   0.00783854  0.          0.
  0.01204692  0.          0.          0.          0.02491778  0.
  0.          0.         -0.06188152  0.          0.          0.
  0.          0.         -0.71582614  0.         -1.21184045  0.
 -0.21569473  0.23101211  0.         -0.16467227  0.          0.
  0.          0.         -0.32488063 -0.01375889  0.          0.
 -0.47795833  0.          0.          0.         -0.98859986  0.
  0.          0.          0.          0.          0.         -0.01976643
  0.01976643  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.03947827
 -0.03947827  0.          0.          0.13191741 -0.13191741  0.
  0.          0.12555783 -0.12555783  0.0545552  -0.0545552   0.
  0.          0.09756754 -0.09756754  0.          0.          0.
  0.          0.          0.          0.          0.          0.19283437
 -0.19283437  0.01275108 -0.01275108  0.          0.          0.
  0.          0.03595147 -0.03595147  0.          0.          0.
  0.          0.          0.          0.06962379 -0.06962379  1.61491573
 -1.61491573]

[2020-01-28 17:10:38.504390][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.014398173370688605, New policy loss value: -0.05407237616977321

[2020-01-28 17:10:38.551516][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 2.430976818030586

[2020-01-28 17:10:38.551932][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:39.202320][__main__.TRPOAgent.log][learning]: Episode #14

[2020-01-28 17:10:39.202804][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:39.218756][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:39.219384][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:39.219635][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:39.223168][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:39.264100][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 9

[2020-01-28 17:10:39.264713][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 13

[2020-01-28 17:10:39.265400][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:39.265873][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:39.265925][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:39.267663][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:39.306406][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 10

[2020-01-28 17:10:39.308216][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 14

[2020-01-28 17:10:39.309047][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:39.309597][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:39.309660][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:39.311863][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:39.342886][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 9

[2020-01-28 17:10:39.345577][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 9

[2020-01-28 17:10:39.345951][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:39.346527][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:39.346583][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:39.348128][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:39.388116][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:10:39.390305][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 12

[2020-01-28 17:10:39.391599][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:39.392440][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:39.392515][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:39.395137][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:39.422101][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 9

[2020-01-28 17:10:39.432333][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 11

[2020-01-28 17:10:39.433036][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:39.434614][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 106, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:39.435177][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:39.435893][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 106

[2020-01-28 17:10:39.453797][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00397682 -0.08144173  0.00496902  0.12905749  0.03481119  0.
  0.          0.         -0.00479464  0.          0.          0.
  0.          0.          0.02564727  0.          0.04636294  0.
  0.04575971  0.01433377  0.          0.03501265  0.          0.
  0.          0.          0.06909175  0.00313345  0.          0.
  0.01755861  0.          0.          0.          0.03610359  0.
  0.          0.         -0.00259496  0.          0.          0.
  0.          0.          0.00589729  0.          0.01066061  0.
  0.0105219   0.00329588  0.          0.00805074  0.          0.
  0.          0.          0.01588683  0.0007205   0.          0.
  0.00403739  0.          0.          0.          0.00830159  0.
  0.          0.          0.          0.          0.          0.00051241
 -0.00051241  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.01711383
 -0.01711383  0.          0.          0.03114598 -0.03114598  0.
  0.          0.03400637 -0.03400637  0.01798165 -0.01798165  0.
  0.          0.02651562 -0.02651562  0.          0.          0.
  0.          0.          0.          0.          0.          0.05242381
 -0.05242381  0.00314609 -0.00314609  0.          0.          0.
  0.          0.01322367 -0.01322367  0.          0.          0.
  0.          0.          0.          0.0290163  -0.0290163   0.01603318
 -0.01603318]

[2020-01-28 17:10:39.454317][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:39.497083][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 0.6618795   0.21712821 -0.91695778 -0.65271467 -0.92955215  0.
  0.          0.         -0.11642499  0.          0.          0.
  0.          0.          0.1965262   0.          0.35526321  0.
  0.35064113  0.10983484  0.          0.26829002  0.          0.
  0.          0.          0.52942657  0.02401056  0.          0.
  0.13454553  0.          0.          0.          0.27664929  0.
  0.          0.         -0.22032596  0.          0.          0.
  0.          0.         -0.15604762  0.         -0.28208951  0.
 -0.2784191  -0.08721197  0.         -0.21302996  0.          0.
  0.          0.         -0.42037986 -0.01906508  0.          0.
 -0.10683314  0.          0.          0.         -0.21966776  0.
  0.          0.          0.          0.          0.         -0.14774176
  0.14774176  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.26441828
 -0.26441828  0.          0.          0.4807928  -0.4807928   0.
  0.          0.33286087 -0.33286087  0.12328397 -0.12328397  0.
  0.          0.25838112 -0.25838112  0.          0.          0.
  0.          0.          0.          0.          0.          0.5106149
 -0.5106149   0.03097018 -0.03097018  0.          0.          0.
  0.          0.19246131 -0.19246131  0.          0.          0.
  0.          0.          0.          0.40928022 -0.40928022 -0.42425234
  0.42425234]

[2020-01-28 17:10:39.539808][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.011776223755317497, New policy loss value: -0.004858185879546325

[2020-01-28 17:10:39.588530][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 1.4689610841971512

[2020-01-28 17:10:39.588939][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:40.252792][__main__.TRPOAgent.log][learning]: Episode #15

[2020-01-28 17:10:40.253173][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:40.267691][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:40.268288][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:40.268518][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:40.271178][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:40.299137][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 17:10:40.304676][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 10

[2020-01-28 17:10:40.305193][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:40.305972][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:40.305917][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:40.306987][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:40.339066][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:10:40.346960][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 11

[2020-01-28 17:10:40.347555][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:40.348160][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:40.348089][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:40.349533][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:40.394247][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 11

[2020-01-28 17:10:40.394083][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 10

[2020-01-28 17:10:40.395257][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:40.395905][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:40.395829][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:40.397086][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:40.431728][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 11

[2020-01-28 17:10:40.432541][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 11

[2020-01-28 17:10:40.433797][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:40.434430][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:40.434487][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:40.436580][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:40.477769][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 11

[2020-01-28 17:10:40.483366][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 13

[2020-01-28 17:10:40.483854][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:40.485145][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 108, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:40.485475][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:40.485803][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 108

[2020-01-28 17:10:40.500497][__main__.TRPOAgent.log][training]: policy_gradient: [-0.01072001 -0.03681223  0.00656439  0.06772064  0.18466434  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.02798018  0.          0.05066821  0.
  0.04870575  0.01499619  0.          0.03739101  0.          0.
  0.          0.          0.07381     0.00361006  0.          0.
  0.0195153   0.          0.          0.          0.04138712  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.02616636  0.          0.04738363  0.
  0.04655393  0.00548744  0.          0.03573908  0.          0.
  0.          0.          0.07054907  0.00345057  0.          0.
  0.01825022  0.          0.          0.          0.03907778  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.00473248
 -0.00473248  0.          0.          0.00863271 -0.00863271  0.
  0.          0.02381868 -0.02381868  0.01533794 -0.01533794  0.
  0.          0.0186392  -0.0186392   0.          0.          0.
  0.          0.          0.          0.          0.          0.03686464
 -0.03686464  0.0021561  -0.0021561   0.          0.          0.
  0.          0.00440353 -0.00440353  0.          0.          0.
  0.          0.          0.          0.01050115 -0.01050115  0.01973473
 -0.01973473]

[2020-01-28 17:10:40.500901][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:40.552352][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.01452003 -0.0483447  -0.00260256  0.04210595  0.24942303  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.05577392  0.          0.1009988   0.
  0.04880121  0.00359475  0.          0.03746429  0.          0.
  0.          0.          0.07395466  0.00361714  0.          0.
  0.03890056  0.          0.          0.          0.09918191  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.08284649  0.          0.15002345  0.
  0.00608406 -0.06760383  0.          0.00467069  0.          0.
  0.          0.          0.00921995  0.00045095  0.          0.
  0.05778283  0.          0.          0.          0.14544499  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -0.00754315
  0.00754315  0.          0.         -0.01360932  0.01360932  0.
  0.          0.03405213 -0.03405213  0.00346154 -0.00346154  0.
  0.          0.02646093 -0.02646093  0.          0.          0.
  0.          0.          0.          0.          0.          0.05229789
 -0.05229789  0.00302436 -0.00302436  0.          0.          0.
  0.         -0.00283257  0.00283257  0.          0.          0.
  0.          0.          0.         -0.00258039  0.00258039 -0.2431268
  0.2431268 ]

[2020-01-28 17:10:40.596783][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.003912887929558685, New policy loss value: -0.024095703913476048

[2020-01-28 17:10:40.643417][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 9.10859192019781

[2020-01-28 17:10:40.643826][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:41.429023][__main__.TRPOAgent.log][learning]: Episode #16

[2020-01-28 17:10:41.429666][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:41.443298][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:41.444285][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:41.444547][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:41.447736][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:41.482040][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 11

[2020-01-28 17:10:41.485742][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 11

[2020-01-28 17:10:41.486151][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:41.486718][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:41.486770][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:41.489009][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:41.533462][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 13

[2020-01-28 17:10:41.536241][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 12

[2020-01-28 17:10:41.536711][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:41.537536][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:41.537619][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:41.539583][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:41.580094][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 10

[2020-01-28 17:10:41.582562][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 10

[2020-01-28 17:10:41.583001][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:41.583699][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:41.583756][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:41.591516][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:41.614006][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 10

[2020-01-28 17:10:41.625001][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:10:41.626000][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:41.627145][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:41.627251][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:41.630256][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:41.662105][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 10

[2020-01-28 17:10:41.670457][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 12

[2020-01-28 17:10:41.670987][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:41.673588][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 109, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:41.673993][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:41.674372][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 109

[2020-01-28 17:10:41.690328][__main__.TRPOAgent.log][training]: policy_gradient: [-0.0126519   0.01213737  0.00532589 -0.00381175  0.25395082  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.02761133  0.          0.05000185  0.
  0.05733671  0.01697899  0.          0.0440294   0.          0.
  0.          0.          0.08652629  0.00425015  0.          0.
  0.02275545  0.          0.          0.          0.04849308  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.02893393  0.          0.05239698  0.
  0.06573415  0.01577652  0.          0.05047787  0.          0.
  0.          0.          0.09845699  0.00483619  0.          0.
  0.02513721  0.          0.          0.          0.05416892  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.00522758
 -0.00522758  0.          0.          0.0095213  -0.0095213   0.
  0.          0.02579672 -0.02579672  0.01620192 -0.01620192  0.
  0.          0.02022    -0.02022     0.          0.          0.
  0.          0.          0.          0.          0.          0.03999744
 -0.03999744  0.00233222 -0.00233222  0.          0.          0.
  0.          0.00496777 -0.00496777  0.          0.          0.
  0.          0.          0.          0.01280907 -0.01280907  0.0275079
 -0.0275079 ]

[2020-01-28 17:10:41.690828][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:41.779591][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.65565091 -0.1075195   0.77671413  0.49253042  1.13148681  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.12129988  0.         -0.21966416  0.
 -0.39480362 -0.17408647  0.         -0.30317341  0.          0.
  0.          0.         -0.67229591 -0.03302304  0.          0.
 -0.11428066  0.          0.          0.         -0.18503706  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.29669247  0.          0.53728581  0.
  0.20892813  0.14867286  0.          0.16043787  0.          0.
  0.          0.          0.09183398  0.00451087  0.          0.
  0.16593271  0.          0.          0.          0.43368258  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -0.23933666
  0.23933666  0.          0.         -0.43469124  0.43469124  0.
  0.         -0.33855162  0.33855162 -0.18740925  0.18740925  0.
  0.         -0.26220912  0.26220912  0.          0.          0.
  0.          0.          0.          0.          0.         -0.51809413
  0.51809413 -0.02979542  0.02979542  0.          0.          0.
  0.         -0.17036669  0.17036669  0.          0.          0.
  0.          0.          0.         -0.35604818  0.35604818 -0.40422011
  0.40422011]

[2020-01-28 17:10:41.813498][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.007564384508597772, New policy loss value: 0.0009528061117701637

[2020-01-28 17:10:41.867357][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 9.036663982205503

[2020-01-28 17:10:41.867751][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:42.648115][__main__.TRPOAgent.log][learning]: Episode #17

[2020-01-28 17:10:42.648588][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:42.662781][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:42.663463][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:42.663606][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:42.665721][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:42.695763][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 17:10:42.700297][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 10

[2020-01-28 17:10:42.700696][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:42.701424][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:42.701366][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:42.702663][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:42.743296][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:10:42.746948][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 13

[2020-01-28 17:10:42.747550][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:42.748178][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:42.748121][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:42.749350][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:42.781895][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 10

[2020-01-28 17:10:42.787446][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 10

[2020-01-28 17:10:42.787928][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:42.788613][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:42.788555][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:42.790263][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:42.826640][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:10:42.827247][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 11

[2020-01-28 17:10:42.828149][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:42.828869][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:42.828987][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:42.831287][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:42.863497][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 10

[2020-01-28 17:10:42.868188][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 10

[2020-01-28 17:10:42.868866][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:42.870218][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 104, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:42.870567][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:42.870975][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 104

[2020-01-28 17:10:42.884470][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00397323  0.00858098  0.0015057  -0.00877102  0.08217088  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.01945955  0.          0.03516754  0.
  0.03613027  0.0071199   0.          0.02750479  0.          0.
  0.          0.          0.05479858  0.00244527  0.          0.
  0.01346943  0.          0.          0.          0.02797563  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.01470243  0.          0.02657041  0.
  0.02676779  0.00552007  0.          0.02001283  0.          0.
  0.          0.          0.0414024   0.00184749  0.          0.
  0.01017666  0.          0.          0.          0.02108714  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.01409872
 -0.01409872  0.          0.          0.02562044 -0.02562044  0.
  0.          0.02352493 -0.02352493  0.01534789 -0.01534789  0.
  0.          0.01843978 -0.01843978  0.          0.          0.
  0.          0.          0.          0.          0.          0.02960516
 -0.02960516  0.00186774 -0.00186774  0.          0.          0.
  0.          0.00938214 -0.00938214  0.          0.          0.
  0.          0.          0.          0.02512349 -0.02512349  0.04875513
 -0.04875513]

[2020-01-28 17:10:42.884899][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:42.926220][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.02001062  0.03116757  0.01541493 -0.06196235  0.11627297  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.01549609  0.          0.02800472  0.
  0.01264556  0.00059428  0.          0.00567008  0.          0.
  0.          0.          0.04363737  0.00194723  0.          0.
  0.01072601  0.          0.          0.          0.01456709  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.03120306  0.          0.05639056  0.
  0.00814575 -0.00105948  0.         -0.00950038  0.          0.
  0.          0.          0.08786859  0.00392095  0.          0.
  0.02159799  0.          0.          0.          0.02309273  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.00275933
 -0.00275933  0.          0.          0.00498704 -0.00498704  0.
  0.          0.00848899 -0.00848899  0.00065013 -0.00065013  0.
  0.          0.00663423 -0.00663423  0.          0.          0.
  0.          0.          0.          0.          0.          0.00577988
 -0.00577988  0.00046649 -0.00046649  0.          0.          0.
  0.          0.00065135 -0.00065135  0.          0.          0.
  0.          0.          0.          0.00840137 -0.00840137 -0.00935774
  0.00935774]

[2020-01-28 17:10:42.966663][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.004208272387436546, New policy loss value: -0.01332318388908323

[2020-01-28 17:10:43.015341][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 7.70264000471238

[2020-01-28 17:10:43.015738][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:43.781497][__main__.TRPOAgent.log][learning]: Episode #18

[2020-01-28 17:10:43.782004][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:43.798377][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:43.799181][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:43.799054][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:43.800819][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:43.832263][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 17:10:43.837516][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 9

[2020-01-28 17:10:43.837973][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:43.838437][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:43.838497][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:43.841076][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:43.878208][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 11

[2020-01-28 17:10:43.882936][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 13

[2020-01-28 17:10:43.883310][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:43.883766][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:43.883817][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:43.885159][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:43.925011][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 10

[2020-01-28 17:10:43.928482][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 10

[2020-01-28 17:10:43.928901][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:43.929386][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:43.929438][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:43.931336][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:43.963049][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:10:43.962492][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 10

[2020-01-28 17:10:43.964003][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:43.964660][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:43.964586][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:43.965706][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:44.002128][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 10

[2020-01-28 17:10:44.002782][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 11

[2020-01-28 17:10:44.003411][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:44.004792][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 104, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:44.005150][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:44.005493][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 104

[2020-01-28 17:10:44.020768][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00749466  0.01666029  0.00258862 -0.0164821   0.1622501   0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.03969737  0.          0.07174163  0.
  0.07467014  0.01449146  0.          0.05697326  0.          0.
  0.          0.          0.1114934   0.00500611  0.          0.
  0.02747812  0.          0.          0.          0.05769185  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.02801806  0.          0.05063461  0.
  0.05294927  0.00840727  0.          0.03999514  0.          0.
  0.          0.          0.07869107  0.00353327  0.          0.
  0.01976477  0.          0.          0.          0.04049959  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.03209728
 -0.03209728  0.          0.          0.05830262 -0.05830262  0.
  0.          0.04965252 -0.04965252  0.02986508 -0.02986508  0.
  0.          0.03776116 -0.03776116  0.          0.          0.
  0.          0.          0.          0.          0.          0.06939446
 -0.06939446  0.00422302 -0.00422302  0.          0.          0.
  0.          0.02153553 -0.02153553  0.          0.          0.
  0.          0.          0.          0.05410166 -0.05410166  0.07376675
 -0.07376675]

[2020-01-28 17:10:44.021196][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:44.059019][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.022703   -0.01256254  0.01590349  0.01407673  0.20959815  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.05136854  0.          0.09283392  0.
  0.0976795   0.01529433  0.          0.07179425  0.          0.
  0.          0.          0.14427285  0.00647792  0.          0.
  0.04030665  0.          0.          0.          0.07269977  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.03731265  0.          0.06743192  0.
  0.07605985 -0.03048779  0.          0.04692622  0.          0.
  0.          0.          0.1047957   0.00470538  0.          0.
  0.03907128  0.          0.          0.          0.04751809  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.0411412
 -0.0411412   0.          0.          0.07472791 -0.07472791  0.
  0.          0.06361345 -0.06361345  0.01550302 -0.01550302  0.
  0.          0.04833687 -0.04833687  0.          0.          0.
  0.          0.          0.          0.          0.          0.08901525
 -0.08901525  0.00541756 -0.00541756  0.          0.          0.
  0.          0.02710563 -0.02710563  0.          0.          0.
  0.          0.          0.          0.06940108 -0.06940108 -0.26750487
  0.26750487]

[2020-01-28 17:10:44.095658][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.0042012479669577, New policy loss value: -0.029773376412906307

[2020-01-28 17:10:44.141779][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 8.125934557344477

[2020-01-28 17:10:44.142193][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:44.739266][__main__.TRPOAgent.log][learning]: Episode #19

[2020-01-28 17:10:44.739672][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:44.754237][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:44.754818][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:44.755024][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:44.756729][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:44.794345][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 17:10:44.795291][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 9

[2020-01-28 17:10:44.796475][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:44.797266][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:44.797325][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:44.802332][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:44.825928][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 9

[2020-01-28 17:10:44.833725][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 9

[2020-01-28 17:10:44.834235][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:44.834821][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:44.834969][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:44.836797][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:44.876489][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 12

[2020-01-28 17:10:44.877028][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 9

[2020-01-28 17:10:44.877795][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:44.878812][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:44.878936][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:44.881959][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:44.918074][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 9

[2020-01-28 17:10:44.922308][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 13

[2020-01-28 17:10:44.922841][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:44.923348][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:44.923510][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:44.926359][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:44.952518][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 9

[2020-01-28 17:10:44.958803][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 10

[2020-01-28 17:10:44.959326][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:44.960860][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 99, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:44.961231][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:44.961690][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 99

[2020-01-28 17:10:44.976825][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.00952387  0.04169342 -0.00744785 -0.07319993 -0.13656423  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.0447308   0.         -0.08086592  0.
 -0.08336252 -0.01659926  0.         -0.06372565  0.          0.
  0.          0.         -0.12367251 -0.00565778  0.          0.
 -0.03066422  0.          0.          0.         -0.06580495  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.02239816  0.         -0.04049218  0.
 -0.04287792 -0.00883694  0.         -0.0327776   0.          0.
  0.          0.         -0.06192683 -0.00283303  0.          0.
 -0.01535457  0.          0.          0.         -0.03295067  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -0.03947381
  0.03947381  0.          0.         -0.07169707  0.07169707  0.
  0.         -0.06038483  0.06038483 -0.03150656  0.03150656  0.
  0.         -0.04586143  0.04586143  0.          0.          0.
  0.          0.          0.          0.          0.         -0.08646515
  0.08646515 -0.00514189  0.00514189  0.          0.          0.
  0.         -0.02746105  0.02746105  0.          0.          0.
  0.          0.          0.         -0.06472337  0.06472337 -0.07217105
  0.07217105]

[2020-01-28 17:10:44.977260][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:45.018462][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 0.45944782  0.32681715 -0.64824888 -0.65817762 -0.36045218  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.12456613  0.          0.22519504  0.
  0.1556167   0.02839699  0.          0.11895964  0.          0.
  0.          0.          0.3444026   0.01575577  0.          0.
  0.08539358  0.          0.          0.          0.18325334  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.01267895  0.         -0.02292145  0.
 -0.34621025 -0.14780394  0.         -0.264657    0.          0.
  0.          0.         -0.03505499 -0.0016037   0.          0.
 -0.00869177  0.          0.          0.         -0.01865241  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.1336108
 -0.1336108   0.          0.          0.24286196 -0.24286196  0.
  0.          0.17759988 -0.17759988  0.00327723 -0.00327723  0.
  0.          0.14336294 -0.14336294  0.          0.          0.
  0.          0.          0.          0.          0.          0.28601309
 -0.28601309  0.01714072 -0.01714072  0.          0.          0.
  0.          0.09545203 -0.09545203  0.          0.          0.
  0.          0.          0.          0.21277794 -0.21277794 -1.20711122
  1.20711122]

[2020-01-28 17:10:45.058532][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.011014038997672558, New policy loss value: -0.040373268788335026

[2020-01-28 17:10:45.108423][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 3.983660055474952

[2020-01-28 17:10:45.108883][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:45.723982][__main__.TRPOAgent.log][learning]: Episode #20

[2020-01-28 17:10:45.724449][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:45.737749][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:45.738329][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:45.738639][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:45.742553][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:45.771871][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 9

[2020-01-28 17:10:45.777123][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 10

[2020-01-28 17:10:45.777533][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:45.778266][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:45.778191][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:45.779050][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:45.813631][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:10:45.813951][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 9

[2020-01-28 17:10:45.814917][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:45.815481][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:45.815551][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:45.818370][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:45.844089][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 9

[2020-01-28 17:10:45.852466][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 12

[2020-01-28 17:10:45.852905][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:45.853531][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:45.853707][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:45.855166][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:45.889003][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 9

[2020-01-28 17:10:45.890198][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 11

[2020-01-28 17:10:45.891029][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:45.892863][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:45.893030][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:45.896496][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:45.933323][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 9

[2020-01-28 17:10:45.934295][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 9

[2020-01-28 17:10:45.935205][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:45.936585][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 97, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:45.936932][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:45.937366][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 97

[2020-01-28 17:10:45.952329][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.00107293 -0.10022894  0.00742873  0.14819255 -0.16112716  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.02523984  0.         -0.04568525  0.
 -0.04295841 -0.00737216  0.         -0.03315459  0.          0.
  0.          0.         -0.06624716 -0.00320268  0.          0.
 -0.01746622  0.          0.          0.         -0.0378189   0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.02457015  0.         -0.04447309  0.
 -0.04014176 -0.00717655  0.         -0.03098074  0.          0.
  0.          0.         -0.06448942 -0.0031177   0.          0.
 -0.01700278  0.          0.          0.         -0.03681545  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -0.01673302
  0.01673302  0.          0.         -0.03034988  0.03034988  0.
  0.         -0.02001638  0.02001638 -0.0122719   0.0122719   0.
  0.         -0.01488755  0.01488755  0.          0.          0.
  0.          0.          0.          0.          0.         -0.03883975
  0.03883975 -0.00220316  0.00220316  0.          0.          0.
  0.         -0.01130817  0.01130817  0.          0.          0.
  0.          0.          0.         -0.02781179  0.02781179 -0.05750588
  0.05750588]

[2020-01-28 17:10:45.952805][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:45.979706][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.0032302  -0.17098617  0.01365595  0.25931392 -0.14756713  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.0142838   0.         -0.02585432  0.
 -0.02354227 -0.00417207  0.         -0.01816953  0.          0.
  0.          0.         -0.03749077 -0.00181247  0.          0.
 -0.00988453  0.          0.          0.         -0.02140257  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.02266741  0.         -0.04102904  0.
 -0.03579922 -0.00662079  0.         -0.02762924  0.          0.
  0.          0.         -0.05949529 -0.00287627  0.          0.
 -0.01568607  0.          0.          0.         -0.03396442  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -0.00723179
  0.00723179  0.          0.         -0.01309544  0.01309544  0.
  0.         -0.0069208   0.0069208  -0.00663724  0.00663724  0.
  0.         -0.00484501  0.00484501  0.          0.          0.
  0.          0.          0.          0.          0.         -0.01762738
  0.01762738 -0.00097954  0.00097954  0.          0.          0.
  0.         -0.00461717  0.00461717  0.          0.          0.
  0.          0.          0.         -0.01265603  0.01265603 -0.05305256
  0.05305256]

[2020-01-28 17:10:46.010116][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.011129291024600838, New policy loss value: -0.045101114307184484

[2020-01-28 17:10:46.058723][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 2.0619735030662754

[2020-01-28 17:10:46.059157][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:46.878462][__main__.TRPOAgent.log][learning]: Episode #21

[2020-01-28 17:10:46.879024][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:46.900630][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:46.901581][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:46.901277][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:46.902541][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:46.938058][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 17:10:46.938251][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 10

[2020-01-28 17:10:46.939194][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:46.939681][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:46.939732][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:46.941639][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:46.977458][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:10:46.978894][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 10

[2020-01-28 17:10:46.979923][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:46.980678][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:46.980601][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:46.981802][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:47.018891][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 10

[2020-01-28 17:10:47.020941][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 11

[2020-01-28 17:10:47.021727][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:47.022437][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:47.022508][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:47.024643][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:47.051290][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 10

[2020-01-28 17:10:47.057099][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:10:47.057519][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:47.058121][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:47.058174][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:47.061017][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:47.099948][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 10

[2020-01-28 17:10:47.100478][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 10

[2020-01-28 17:10:47.101735][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:47.103075][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 101, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:47.103408][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:47.103729][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 101

[2020-01-28 17:10:47.116823][__main__.TRPOAgent.log][training]: policy_gradient: [-0.01104089  0.03709375  0.00311557 -0.04245745  0.25410549  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.04773971  0.          0.08641039  0.
  0.08393273  0.01336783  0.          0.06463826  0.          0.
  0.          0.          0.12540177  0.00604708  0.          0.
  0.03313106  0.          0.          0.          0.07148184  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.03889245  0.          0.07039656  0.
  0.06883371  0.01062657  0.          0.05274089  0.          0.
  0.          0.          0.10200089  0.00491865  0.          0.
  0.02709289  0.          0.          0.          0.05870884  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.03221955
 -0.03221955  0.          0.          0.05846517 -0.05846517  0.
  0.          0.03913235 -0.03913235  0.02332107 -0.02332107  0.
  0.          0.0292293  -0.0292293   0.          0.          0.
  0.          0.          0.          0.          0.          0.07344119
 -0.07344119  0.00422751 -0.00422751  0.          0.          0.
  0.          0.02197821 -0.02197821  0.          0.          0.
  0.          0.          0.          0.05331534 -0.05331534  0.08827827
 -0.08827827]

[2020-01-28 17:10:47.117228][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:47.155322][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.0137105  -0.16580275  0.00778802  0.2584546   0.21227261  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.07544766  0.          0.13656265  0.
  0.1389341   0.02021991  0.          0.09253901  0.          0.
  0.          0.          0.19670649  0.0094855   0.          0.
  0.05339863  0.          0.          0.          0.1229041   0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.02990866  0.          0.05413561  0.
  0.06957325 -0.00386936  0.          0.02169197  0.          0.
  0.          0.          0.0733893   0.00353895  0.          0.
  0.02400437  0.          0.          0.          0.08115185  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.06003301
 -0.06003301  0.          0.          0.10900272 -0.10900272  0.
  0.          0.07907076 -0.07907076  0.03841273 -0.03841273  0.
  0.          0.06013218 -0.06013218  0.          0.          0.
  0.          0.          0.          0.          0.          0.13435645
 -0.13435645  0.00777511 -0.00777511  0.          0.          0.
  0.          0.04186432 -0.04186432  0.          0.          0.
  0.          0.          0.          0.09698673 -0.09698673 -0.13774724
  0.13774724]

[2020-01-28 17:10:47.196818][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.004300382995104329, New policy loss value: -0.03879812217844357

[2020-01-28 17:10:47.244896][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 7.702672624351955

[2020-01-28 17:10:47.245489][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:47.943975][__main__.TRPOAgent.log][learning]: Episode #22

[2020-01-28 17:10:47.945271][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:47.959666][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:47.960965][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:47.961145][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:47.966142][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:47.995821][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 17:10:48.004251][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 12

[2020-01-28 17:10:48.004942][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:48.005791][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:48.005871][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:48.007863][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:48.045378][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:10:48.051682][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 11

[2020-01-28 17:10:48.052288][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:48.052859][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:48.052800][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:48.053870][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:48.089401][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 10

[2020-01-28 17:10:48.091102][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 11

[2020-01-28 17:10:48.091972][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:48.092453][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:48.092523][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:48.095086][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:48.120630][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 9

[2020-01-28 17:10:48.132356][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:10:48.132983][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:48.133602][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:48.133678][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:48.135701][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:48.171803][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 9

[2020-01-28 17:10:48.172565][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 10

[2020-01-28 17:10:48.173492][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:48.175570][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 102, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:48.176112][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:48.176679][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 102

[2020-01-28 17:10:48.195960][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00707007  0.0854168  -0.00412307 -0.11765143  0.28654674  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.04779614  0.          0.08652812  0.
  0.07848042  0.01500133  0.          0.05741145  0.          0.
  0.          0.          0.12566363  0.00606499  0.          0.
  0.03313431  0.          0.          0.          0.07237629  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.0434266   0.          0.0786177   0.
  0.06294298  0.01576106  0.          0.04062124  0.          0.
  0.          0.          0.1174461   0.00551053  0.          0.
  0.03010517  0.          0.          0.          0.06764338  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.03153001
 -0.03153001  0.          0.          0.05719416 -0.05719416  0.
  0.          0.03965893 -0.03965893  0.02283099 -0.02283099  0.
  0.          0.02908724 -0.02908724  0.          0.          0.
  0.          0.          0.          0.          0.          0.07288375
 -0.07288375  0.00413308 -0.00413308  0.          0.          0.
  0.          0.02150144 -0.02150144  0.          0.          0.
  0.          0.          0.          0.05316398 -0.05316398  0.13510006
 -0.13510006]

[2020-01-28 17:10:48.196462][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:48.285187][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 0.06828489 -0.41915799 -0.13374912 -0.22803684 -0.52722142  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.12181407  0.          0.22052709  0.
 -1.35725464  0.18070522  0.         -1.36983357  0.          0.
  0.          0.          0.71173914  0.01545734  0.          0.
  0.08444669  0.          0.          0.          0.40992797  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.30512578  0.          0.55238693  0.
 -4.15293303  0.67598415  0.         -4.1184629   0.          0.
  0.          0.          2.30434246  0.0387183   0.          0.
  0.21152615  0.          0.          0.          1.32719206  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.03021527
 -0.03021527  0.          0.          0.05437235 -0.05437235  0.
  0.          0.19911044 -0.19911044  0.20488444 -0.20488444  0.
  0.          0.30538361 -0.30538361  0.          0.          0.
  0.          0.          0.          0.          0.          0.09026952
 -0.09026952  0.00450224 -0.00450224  0.          0.          0.
  0.          0.01542805 -0.01542805  0.          0.          0.
  0.          0.          0.          0.08758294 -0.08758294  1.83856418
 -1.83856418]

[2020-01-28 17:10:48.333383][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 2, New mean kl div: 0.0030231078685903235, New policy loss value: -0.03838544114502392

[2020-01-28 17:10:48.381021][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 7.61123054427113

[2020-01-28 17:10:48.381425][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:49.076305][__main__.TRPOAgent.log][learning]: Episode #23

[2020-01-28 17:10:49.076714][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:49.091934][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:49.092637][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:49.092524][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:49.094170][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:49.124306][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 9

[2020-01-28 17:10:49.134268][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 12

[2020-01-28 17:10:49.134872][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:49.136299][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:49.136122][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:49.137682][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:49.169958][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 9

[2020-01-28 17:10:49.172521][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 10

[2020-01-28 17:10:49.172888][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:49.173556][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:49.173623][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:49.175645][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:49.205512][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 9

[2020-01-28 17:10:49.207889][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 10

[2020-01-28 17:10:49.208339][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:49.208970][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:49.209033][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:49.212261][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:49.250278][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 11

[2020-01-28 17:10:49.252297][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 9

[2020-01-28 17:10:49.252888][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:49.253497][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:49.253553][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:49.256337][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:49.302494][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 11

[2020-01-28 17:10:49.302246][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 14

[2020-01-28 17:10:49.303562][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:49.304885][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 104, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:49.305264][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:49.305619][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 104

[2020-01-28 17:10:49.319502][__main__.TRPOAgent.log][training]: policy_gradient: [ 1.05235706e-03 -4.30350744e-02  1.44678787e-03  6.45878056e-02
 -4.78705287e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00 -3.61638809e-03  0.00000000e+00
 -6.54658640e-03  0.00000000e+00 -1.13875765e-02 -1.33252301e-03
  0.00000000e+00  3.97394216e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00 -9.59160950e-03 -4.59649796e-04
  0.00000000e+00  0.00000000e+00 -2.50079153e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00 -5.56523526e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -8.14806308e-03  0.00000000e+00 -1.47500759e-02  0.00000000e+00
 -1.90117632e-02 -8.70563159e-05  0.00000000e+00  2.08911159e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -2.22461271e-02 -1.03563429e-03  0.00000000e+00  0.00000000e+00
 -5.63451891e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -1.29076284e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.57882282e-03
  1.57882282e-03  0.00000000e+00  0.00000000e+00 -2.85144975e-03
  2.85144975e-03  0.00000000e+00  0.00000000e+00  5.52488164e-03
 -5.52488164e-03 -1.95469831e-03  1.95469831e-03  0.00000000e+00
  0.00000000e+00  5.40711059e-03 -5.40711059e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.39938252e-03
  6.39938252e-03 -2.18452633e-04  2.18452633e-04  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -9.53604906e-04
  9.53604906e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.30778381e-03
  4.30778381e-03 -5.34377960e-04  5.34377960e-04]

[2020-01-28 17:10:49.319917][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:49.401568][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 3.22882973e-01 -2.00499671e-01 -4.07375685e-01  3.50020314e-02
 -1.06397942e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  1.22528499e-02  0.00000000e+00
  2.21807905e-02  0.00000000e+00 -1.10495267e+00 -1.59396131e-02
  0.00000000e+00  1.77859816e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00 -1.14732512e-01  1.55736181e-03
  0.00000000e+00  0.00000000e+00  8.47304509e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00 -6.65698653e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  1.40177912e-02  0.00000000e+00  2.53757843e-02  0.00000000e+00
 -7.25087405e-01  3.81882830e-01  0.00000000e+00  1.36210356e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -8.94432913e-01  1.78168841e-03  0.00000000e+00  0.00000000e+00
  9.69353156e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -5.18967031e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  8.17194495e-03
 -8.17194495e-03  0.00000000e+00  0.00000000e+00  1.48139052e-02
 -1.48139052e-02  0.00000000e+00  0.00000000e+00 -1.85900247e-01
  1.85900247e-01  4.28134761e-02 -4.28134761e-02  0.00000000e+00
  0.00000000e+00 -7.85840714e-02  7.85840714e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.10309392e-02
  4.10309392e-02  1.07538734e-03 -1.07538734e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.50685782e-03
 -5.50685782e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.05443980e-02
  2.05443980e-02  2.34411238e+00 -2.34411238e+00]

[2020-01-28 17:10:49.440437][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.006034793111715484, New policy loss value: -0.015539978896681

[2020-01-28 17:10:49.486782][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 4.812941982982291

[2020-01-28 17:10:49.487194][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:50.118063][__main__.TRPOAgent.log][learning]: Episode #24

[2020-01-28 17:10:50.118685][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:50.134511][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:50.135397][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:50.135763][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:50.138330][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:50.169199][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 17:10:50.172001][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 10

[2020-01-28 17:10:50.172376][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:50.172866][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:50.172915][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:50.175135][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:50.209574][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 10

[2020-01-28 17:10:50.209687][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 11

[2020-01-28 17:10:50.210884][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:50.211837][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:50.211958][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:50.214569][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:50.253503][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 10

[2020-01-28 17:10:50.254171][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 12

[2020-01-28 17:10:50.254848][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:50.255551][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:50.255631][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:50.258020][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:50.287195][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 9

[2020-01-28 17:10:50.289765][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 9

[2020-01-28 17:10:50.290525][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:50.291280][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:50.291190][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:50.292319][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:50.330290][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 9

[2020-01-28 17:10:50.330612][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 10

[2020-01-28 17:10:50.331804][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:50.333865][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 100, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:50.334360][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:50.334929][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 100

[2020-01-28 17:10:50.350075][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.00568174 -0.01889687 -0.00387124  0.0201582  -0.09055429  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.01211479  0.         -0.02193107  0.
  0.00191835 -0.00480941  0.         -0.01624753  0.          0.
  0.          0.         -0.0309784  -0.00154019  0.          0.
 -0.00837611  0.          0.          0.         -0.01800738  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.01450148  0.         -0.02625164  0.
  0.0009204  -0.00784782  0.         -0.0194484   0.          0.
  0.          0.         -0.03708135 -0.00184361  0.          0.
 -0.01002626  0.          0.          0.         -0.02155496  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -0.00803952
  0.00803952  0.          0.         -0.0145718   0.0145718   0.
  0.         -0.00013371  0.00013371 -0.01069055  0.01069055  0.
  0.         -0.01103418  0.01103418  0.          0.          0.
  0.          0.          0.          0.          0.         -0.01692114
  0.01692114 -0.001059    0.001059    0.          0.          0.
  0.         -0.00540269  0.00540269  0.          0.          0.
  0.          0.          0.         -0.01234656  0.01234656 -0.04380691
  0.04380691]

[2020-01-28 17:10:50.350586][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:50.411876][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 1.0316323  -0.0770134  -1.54976236 -1.74616507 -1.52969995  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.37198269  0.          0.67339013  0.
  0.29573797  0.16024161  0.          0.4988774   0.          0.
  0.          0.          0.95118756  0.04729115  0.          0.
  0.25718714  0.          0.          0.          0.55291374  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.25658368  0.         -0.46448646  0.
  0.20215105 -0.18054808  0.         -0.34411289  0.          0.
  0.          0.         -0.65610314 -0.03262017  0.          0.
 -0.17740083  0.          0.          0.         -0.38138526  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.38751736
 -0.38751736  0.          0.          0.70427217 -0.70427217  0.
  0.         -0.0746415   0.0746415   0.10805911 -0.10805911  0.
  0.          0.67947954 -0.67947954  0.          0.          0.
  0.          0.          0.          0.          0.          0.88538831
 -0.88538831  0.04918835 -0.04918835  0.          0.          0.
  0.          0.27978008 -0.27978008  0.          0.          0.
  0.          0.          0.          0.62139699 -0.62139699 -1.00782982
  1.00782982]

[2020-01-28 17:10:50.461063][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 2, New mean kl div: 0.005816572560142266, New policy loss value: -0.024406374878228217

[2020-01-28 17:10:50.507164][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 2.530668793673394

[2020-01-28 17:10:50.507556][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:51.194729][__main__.TRPOAgent.log][learning]: Episode #25

[2020-01-28 17:10:51.195386][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:51.210650][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:51.211235][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:51.211400][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:51.216410][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:51.243565][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 11

[2020-01-28 17:10:51.251119][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 9

[2020-01-28 17:10:51.251871][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:51.252904][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:51.253020][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:51.255956][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:51.286887][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 11

[2020-01-28 17:10:51.292916][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 12

[2020-01-28 17:10:51.293355][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:51.294033][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:51.294211][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:51.298084][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:51.333033][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 12

[2020-01-28 17:10:51.339010][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 15

[2020-01-28 17:10:51.339409][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:51.339920][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:51.339974][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:51.341815][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:51.370452][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 9

[2020-01-28 17:10:51.372053][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 9

[2020-01-28 17:10:51.372460][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:51.373011][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:51.373059][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:51.375733][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:51.418141][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 13

[2020-01-28 17:10:51.418557][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 9

[2020-01-28 17:10:51.419595][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:51.421152][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 110, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:51.421525][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:51.421981][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 110

[2020-01-28 17:10:51.435633][__main__.TRPOAgent.log][training]: policy_gradient: [-3.63680882e-03 -1.34108663e-01  2.87039141e-03  1.95832210e-01
  2.87764483e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  2.36332267e-02  0.00000000e+00
  4.28145067e-02  0.00000000e+00  2.96247760e-03  8.79845134e-03
  0.00000000e+00  3.47563553e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  5.74839906e-02  3.00365582e-03
  0.00000000e+00  0.00000000e+00  1.64769812e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  3.56533235e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  4.54700652e-03  0.00000000e+00  8.23746344e-03  0.00000000e+00
  1.38998214e-03  2.93289534e-05  0.00000000e+00  9.52593588e-03
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  5.67963515e-03  5.77900036e-04  0.00000000e+00  0.00000000e+00
  3.17015285e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  6.85965975e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.84307761e-02
 -1.84307761e-02  0.00000000e+00  0.00000000e+00  3.34537489e-02
 -3.34537489e-02  0.00000000e+00  0.00000000e+00  4.03472188e-05
 -4.03472188e-05  1.08049583e-02 -1.08049583e-02  0.00000000e+00
  0.00000000e+00  2.93882714e-02 -2.93882714e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  4.15879294e-02
 -4.15879294e-02  2.36830462e-03 -2.36830462e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.29527107e-02
 -1.29527107e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.89329521e-02
 -2.89329521e-02  1.40549433e-04 -1.40549433e-04]

[2020-01-28 17:10:51.436168][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:51.530809][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 0.15328561 -0.47596637 -0.39056863 -0.4040949  -0.07030354  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.34212982  0.          0.61981038  0.
  1.06946796  0.13249141  0.          0.48722116  0.          0.
  0.          0.         -0.38638103  0.04348285  0.          0.
  0.2385314   0.          0.          0.          0.51614041  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.60967136  0.          1.1044949   0.
  0.49900245 -0.15835783  0.          0.54447086  0.          0.
  0.          0.         -2.58472931  0.07748594  0.          0.
  0.42506018  0.          0.          0.          0.9197563   0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.14434476
 -0.14434476  0.          0.          0.26120734 -0.26120734  0.
  0.          0.01702775 -0.01702775  0.10495057 -0.10495057  0.
  0.          0.27370651 -0.27370651  0.          0.          0.
  0.          0.          0.          0.          0.          0.31295726
 -0.31295726  0.01947555 -0.01947555  0.          0.          0.
  0.          0.09238962 -0.09238962  0.          0.          0.
  0.          0.          0.          0.21595571 -0.21595571 -0.75887727
  0.75887727]

[2020-01-28 17:10:51.570231][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.00654278754395463, New policy loss value: -0.0198737897172451

[2020-01-28 17:10:51.617147][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 6.033703722144154

[2020-01-28 17:10:51.617554][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:52.305534][__main__.TRPOAgent.log][learning]: Episode #26

[2020-01-28 17:10:52.306026][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:52.321726][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:52.322561][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:52.322433][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:52.323722][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:52.355981][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 9

[2020-01-28 17:10:52.359682][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 9

[2020-01-28 17:10:52.360068][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:52.360635][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:52.360683][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:52.363204][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:52.398791][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 11

[2020-01-28 17:10:52.401836][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 10

[2020-01-28 17:10:52.402727][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:52.403530][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:52.403421][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:52.404669][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:52.435257][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 9

[2020-01-28 17:10:52.438969][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 9

[2020-01-28 17:10:52.439369][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:52.439946][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:52.439884][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:52.441029][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:52.475338][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:10:52.475819][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 11

[2020-01-28 17:10:52.476674][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:52.477142][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:52.477193][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:52.479370][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:52.505681][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 9

[2020-01-28 17:10:52.515592][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 13

[2020-01-28 17:10:52.516283][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:52.518582][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 100, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:52.519226][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:52.519855][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 100

[2020-01-28 17:10:52.537914][__main__.TRPOAgent.log][training]: policy_gradient: [-9.29018438e-03 -1.69176840e-01  8.81070691e-03  2.66100730e-01
  1.19913802e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  2.06141239e-02  0.00000000e+00
  3.73404111e-02  0.00000000e+00  2.90739195e-02  8.51302789e-03
  0.00000000e+00  3.03503977e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  1.57554223e-01  2.63787930e-03
  0.00000000e+00  0.00000000e+00  1.42411952e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  3.10700407e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  5.10115345e-04  0.00000000e+00  9.24022616e-04  0.00000000e+00
  7.02573167e-03  2.10662659e-04  0.00000000e+00  7.51048342e-04
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  1.19139171e-01  6.52767351e-05  0.00000000e+00  0.00000000e+00
  3.52411398e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00
  7.68856566e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.78161169e-02
 -1.78161169e-02  0.00000000e+00  0.00000000e+00  3.23326980e-02
 -3.23326980e-02  0.00000000e+00  0.00000000e+00  1.78789546e-02
 -1.78789546e-02  9.48257348e-03 -9.48257348e-03  0.00000000e+00
  0.00000000e+00  2.81446971e-02 -2.81446971e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.35864471e-02
 -2.35864471e-02  2.28010675e-03 -2.28010675e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.25560577e-02
 -1.25560577e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.78546493e-02
 -2.78546493e-02  8.12014303e-04 -8.12014303e-04]

[2020-01-28 17:10:52.538400][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:52.589805][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 0.34545625 -0.21455667 -0.54462022 -0.36958762 -0.39119566  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.10768334  0.          0.19505754  0.
 -0.67415714  0.04447012  0.          0.15854319  0.          0.
  0.          0.          1.62457158  0.01377966  0.          0.
  0.07439265  0.          0.          0.          0.16230259  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.149917    0.         -0.27155956  0.
 -1.07870224 -0.06191128  0.         -0.22072452  0.          0.
  0.          0.          1.05491865 -0.01918408  0.          0.
 -0.10356964  0.          0.          0.         -0.22595806  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.08780071
 -0.08780071  0.          0.          0.15966157 -0.15966157  0.
  0.          0.23041471 -0.23041471  0.04040197 -0.04040197  0.
  0.          0.17980978 -0.17980978  0.          0.          0.
  0.          0.          0.          0.          0.          0.349603
 -0.349603    0.0110529  -0.0110529   0.          0.          0.
  0.          0.06434607 -0.06434607  0.          0.          0.
  0.          0.          0.          0.14208368 -0.14208368 -0.23864191
  0.23864191]

[2020-01-28 17:10:52.621111][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.013415755094232509, New policy loss value: -0.011757184140722365

[2020-01-28 17:10:52.670042][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 1.066339592628026

[2020-01-28 17:10:52.670437][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:53.389100][__main__.TRPOAgent.log][learning]: Episode #27

[2020-01-28 17:10:53.389502][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:53.403184][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:53.404156][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:53.403987][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:53.405617][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:53.440126][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 17:10:53.441832][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 11

[2020-01-28 17:10:53.442718][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:53.443225][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:53.443276][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:53.444729][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:53.478683][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:10:53.485203][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 10

[2020-01-28 17:10:53.485843][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:53.486922][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:53.487012][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:53.488367][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:53.522595][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 9

[2020-01-28 17:10:53.522539][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 9

[2020-01-28 17:10:53.523629][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:53.524372][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:53.524441][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:53.526734][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:53.559771][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 10

[2020-01-28 17:10:53.562888][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:10:53.563479][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:53.564494][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:53.564637][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:53.567513][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:53.603773][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 11

[2020-01-28 17:10:53.604601][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 9

[2020-01-28 17:10:53.605666][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:53.607739][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 99, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:53.608264][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:53.608793][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 99

[2020-01-28 17:10:53.625774][__main__.TRPOAgent.log][training]: policy_gradient: [-0.01692641 -0.34095331  0.01608299  0.52891153  0.20885543  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.04876809  0.          0.08836579  0.
  0.          0.02032239  0.          0.07402935  0.          0.
  0.          0.          0.12621554  0.00623255  0.          0.
  0.03385387  0.          0.          0.          0.07393396  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.02225227  0.          0.04032021  0.
  0.          0.00927285  0.          0.03377867  0.          0.
  0.          0.          0.05759058  0.00284383  0.          0.
  0.0154471   0.          0.          0.          0.03373515  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.04033846
 -0.04033846  0.          0.          0.07316258 -0.07316258  0.
  0.          0.          0.          0.02217054 -0.02217054  0.
  0.          0.0584109  -0.0584109   0.          0.          0.
  0.          0.          0.          0.          0.          0.08337112
 -0.08337112  0.00518585 -0.00518585  0.          0.          0.
  0.          0.02810346 -0.02810346  0.          0.          0.
  0.          0.          0.          0.0624076  -0.0624076   0.03261093
 -0.03261093]

[2020-01-28 17:10:53.626229][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:53.663632][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 2.12986338 -1.20603037 -3.29211564 -1.69827903 -2.95251092  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          1.20314803  0.          2.18005513  0.
  0.          0.50136964  0.          1.82636369  0.          0.
  0.          0.          3.11383882  0.15376199  0.          0.
  0.83520221  0.          0.          0.          1.82401039  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.31457198  0.         -0.5699916   0.
  0.         -0.13108682  0.         -0.47751638  0.          0.
  0.          0.         -0.81413637 -0.04020221  0.          0.
 -0.21836982  0.          0.          0.         -0.47690107  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          1.02624263
 -1.02624263  0.          0.          1.86282058 -1.86282058  0.
  0.          0.          0.          0.52353832 -0.52353832  0.
  0.          1.69802107 -1.69802107  0.          0.          0.
  0.          0.          0.          0.          0.          2.84813292
 -2.84813292  0.13095536 -0.13095536  0.          0.          0.
  0.          0.72726949 -0.72726949  0.          0.          0.
  0.          0.          0.          1.60998781 -1.60998781 -0.4610083
  0.4610083 ]

[2020-01-28 17:10:53.710958][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 2, New mean kl div: 0.0015625123583629503, New policy loss value: -0.031928660853141236

[2020-01-28 17:10:53.756640][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0.6458572153714467

[2020-01-28 17:10:53.757052][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:54.496594][__main__.TRPOAgent.log][learning]: Episode #28

[2020-01-28 17:10:54.496955][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:54.510196][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:54.511081][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:54.510799][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:54.511765][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:54.546916][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 9

[2020-01-28 17:10:54.547328][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 11

[2020-01-28 17:10:54.548571][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:54.549470][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:54.549565][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:54.552533][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:54.580224][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 9

[2020-01-28 17:10:54.602433][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 20

[2020-01-28 17:10:54.602947][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:54.603697][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:54.603782][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:54.607024][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:54.645722][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 9

[2020-01-28 17:10:54.651220][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 18

[2020-01-28 17:10:54.651672][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:54.652199][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:54.652376][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:54.655226][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:54.688217][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 10

[2020-01-28 17:10:54.692229][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 12

[2020-01-28 17:10:54.692821][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:54.693649][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:54.693701][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:54.696452][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:54.731501][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 13

[2020-01-28 17:10:54.732118][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 10

[2020-01-28 17:10:54.733635][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:54.735364][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 121, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:54.735880][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:54.736440][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 121

[2020-01-28 17:10:54.752266][__main__.TRPOAgent.log][training]: policy_gradient: [-0.03490133 -0.3177945   0.03029819  0.51700691  0.45445279  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.04593474  0.          0.08324967  0.
  0.          0.01965683  0.          0.06955066  0.          0.
  0.          0.          0.13955485  0.00586938  0.          0.
  0.03150976  0.          0.          0.          0.0689295   0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.04006998  0.          0.07262069  0.
  0.          0.01554257  0.          0.04888216  0.          0.
  0.          0.          0.14737039  0.00512     0.          0.
  0.02196996  0.          0.          0.          0.04806063  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.0353244
 -0.0353244   0.          0.          0.06403478 -0.06403478  0.
  0.          0.          0.          0.01981109 -0.01981109  0.
  0.          0.04879957 -0.04879957  0.          0.          0.
  0.          0.          0.          0.          0.          0.06161526
 -0.06161526  0.00455838 -0.00455838  0.          0.          0.
  0.          0.02439143 -0.02439143  0.          0.          0.
  0.          0.          0.          0.05415388 -0.05415388  0.04683919
 -0.04683919]

[2020-01-28 17:10:54.752783][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:54.859765][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 0.44480049  0.06311646 -0.38702319  0.23157316 -0.09706817  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.05688802  0.          0.10310082  0.
  0.          0.02434385  0.         -0.54003062  0.          0.
  0.          0.          1.78064227  0.00726895  0.          0.
 -0.24023854  0.          0.          0.         -0.5255363   0.
  0.          0.          0.          0.          0.          0.
  0.          0.          2.7043537   0.          4.90122574  0.
  0.         -0.07013025  0.         -3.96072247  0.          0.
  0.          0.          0.39360076  0.34555299  0.          0.
 -1.7389262   0.          0.          0.         -3.8040062   0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -0.0891151
  0.0891151   0.          0.         -0.16566014  0.16566014  0.
  0.          0.          0.          0.02114999 -0.02114999  0.
  0.          0.2974505  -0.2974505   0.          0.          0.
  0.          0.          0.          0.          0.          1.27251879
 -1.27251879 -0.00875597  0.00875597  0.          0.          0.
  0.         -0.07904602  0.07904602  0.          0.          0.
  0.          0.          0.         -0.18804874  0.18804874 -0.21134437
  0.21134437]

[2020-01-28 17:10:54.900921][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.009256487999026295, New policy loss value: -0.01922145600949066

[2020-01-28 17:10:54.950511][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 9.405389006374682

[2020-01-28 17:10:54.950906][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:55.702746][__main__.TRPOAgent.log][learning]: Episode #29

[2020-01-28 17:10:55.703582][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:55.718408][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:55.719062][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:55.718989][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:55.720474][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:55.751533][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 9

[2020-01-28 17:10:55.756520][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 9

[2020-01-28 17:10:55.756884][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:55.757652][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:55.757723][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:55.760901][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:55.792914][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:10:55.796709][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 10

[2020-01-28 17:10:55.797334][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:55.797798][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:55.797846][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:55.800828][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:55.835169][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 9

[2020-01-28 17:10:55.836630][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 10

[2020-01-28 17:10:55.837800][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:55.838778][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:55.838880][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:55.841468][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:55.874566][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 10

[2020-01-28 17:10:55.878586][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 11

[2020-01-28 17:10:55.878976][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:55.879595][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:55.879642][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:55.882234][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:55.907090][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 10

[2020-01-28 17:10:55.916445][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 9

[2020-01-28 17:10:55.917429][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:55.918942][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 97, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:55.919594][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:55.920354][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 97

[2020-01-28 17:10:55.938463][__main__.TRPOAgent.log][training]: policy_gradient: [-0.0365845  -0.37336214  0.03649791  0.60229115  0.39862048  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.04212271  0.          0.07627951  0.
  0.          0.01890276  0.          0.06759443  0.          0.
  0.          0.          0.13276459  0.00542122  0.          0.
  0.0284221   0.          0.          0.          0.06195611  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.00533615  0.          0.00966316  0.
  0.          0.00239462  0.          0.05228146  0.          0.
  0.          0.          0.11113089  0.00068677  0.          0.
  0.02243896  0.          0.          0.          0.04891372  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.03798343
 -0.03798343  0.          0.          0.06890395 -0.06890395  0.
  0.          0.          0.          0.01838258 -0.01838258  0.
  0.          0.01828329 -0.01828329  0.          0.          0.
  0.          0.          0.          0.          0.          0.07409943
 -0.07409943  0.00486428 -0.00486428  0.          0.          0.
  0.          0.01102989 -0.01102989  0.          0.          0.
  0.          0.          0.          0.02489132 -0.02489132  0.00709697
 -0.00709697]

[2020-01-28 17:10:55.939139][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:56.053508][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 1.06840849 -1.64557534 -1.65255027 -0.4551365   0.54825196  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.80840612  0.          1.46393265  0.
  0.          0.36277403  0.          3.16445921  0.          0.
  0.          0.          0.71122253  0.10404244  0.          0.
  1.09663287  0.          0.          0.          2.39050269  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.49809019  0.         -0.90198543  0.
  0.         -0.22352138  0.         -5.50548189  0.          0.
  0.          0.         -2.52962249 -0.06410454  0.          0.
 -2.52059932  0.          0.          0.         -5.49454587  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.47473978
 -0.47473978  0.          0.          0.8626098  -0.8626098   0.
  0.          0.          0.          0.35015418 -0.35015418  0.
  0.          5.54461836 -5.54461836  0.          0.          0.
  0.          0.          0.          0.          0.          1.20482622
 -1.20482622  0.06026886 -0.06026886  0.          0.          0.
  0.          2.16431776 -2.16431776  0.          0.          0.
  0.          0.          0.          4.74369519 -4.74369519 -0.662444
  0.662444  ]

[2020-01-28 17:10:56.083280][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.007987229186527372, New policy loss value: -0.0530028688228327

[2020-01-28 17:10:56.132311][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 4.3116953283063495

[2020-01-28 17:10:56.132721][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:56.915140][__main__.TRPOAgent.log][learning]: Episode #30

[2020-01-28 17:10:56.915603][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:56.931736][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:56.932533][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:56.932335][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:56.933576][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:56.968640][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 9

[2020-01-28 17:10:56.969891][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 9

[2020-01-28 17:10:56.970926][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:56.971697][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:56.971775][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:56.976044][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:57.005793][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 11

[2020-01-28 17:10:57.012469][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 13

[2020-01-28 17:10:57.012889][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:57.013611][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:57.013526][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:57.014623][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:57.043387][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 9

[2020-01-28 17:10:57.045055][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 9

[2020-01-28 17:10:57.045494][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:57.046025][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:57.045954][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:57.047209][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:57.090855][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:10:57.094039][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 13

[2020-01-28 17:10:57.094543][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:57.095041][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:57.095090][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:57.096975][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:57.131536][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 10

[2020-01-28 17:10:57.132476][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 9

[2020-01-28 17:10:57.133212][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:57.135816][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 102, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:57.136431][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:57.136995][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 102

[2020-01-28 17:10:57.158083][__main__.TRPOAgent.log][training]: policy_gradient: [-0.01695806 -0.19934654  0.00259092  0.31567817  0.43625572  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.03417962  0.          0.06193286  0.
  0.          0.01715773  0.          0.08946295  0.          0.
  0.          0.          0.09741389  0.00438827  0.          0.
  0.03558767  0.          0.          0.          0.07782605  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.0063536   0.          0.01151261  0.
  0.          0.01281944  0.          0.07159049  0.          0.
  0.          0.          0.07805986  0.00081573  0.          0.
  0.02847815  0.          0.          0.          0.06227835  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.03062261
 -0.03062261  0.          0.          0.05553257 -0.05553257  0.
  0.          0.          0.          0.01363326 -0.01363326  0.
  0.          0.00308205 -0.00308205  0.          0.          0.
  0.          0.          0.          0.          0.          0.03906011
 -0.03906011  0.00392603 -0.00392603  0.          0.          0.
  0.          0.00112777 -0.00112777  0.          0.          0.
  0.          0.          0.          0.00289442 -0.00289442  0.00694154
 -0.00694154]

[2020-01-28 17:10:57.158554][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:57.269044][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 3.07633381 -1.67009353 -4.91309287 -0.62576642  1.12333542  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.30501355  0.          0.55267899  0.
  0.          0.20408195  0.          8.97244832  0.          0.
  0.          0.         -0.51692458  0.0391602   0.          0.
  3.56917109  0.          0.          0.          7.80535602  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.40815448  0.         -0.7395685   0.
  0.         -0.84651929  0.          7.21060665  0.          0.
  0.          0.         -1.99934939 -0.05240229  0.          0.
  2.86832399  0.          0.          0.          6.27268613  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.15514127
 -0.15514127  0.          0.          0.28202655 -0.28202655  0.
  0.          0.          0.          0.23887338 -0.23887338  0.
  0.          0.29272457 -0.29272457  0.          0.          0.
  0.          0.          0.          0.          0.          0.38996718
 -0.38996718  0.01959917 -0.01959917  0.          0.          0.
  0.          0.10634154 -0.10634154  0.          0.          0.
  0.          0.          0.          0.27555109 -0.27555109 -0.44592352
  0.44592352]

[2020-01-28 17:10:57.315380][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 2, New mean kl div: 0.0030396247611054208, New policy loss value: -0.029563689202739225

[2020-01-28 17:10:57.362647][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 6.052029441441775

[2020-01-28 17:10:57.363054][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:58.049450][__main__.TRPOAgent.log][learning]: Episode #31

[2020-01-28 17:10:58.049826][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:58.064214][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:58.064773][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:58.064903][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:58.067079][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:58.100224][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 17:10:58.104522][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 11

[2020-01-28 17:10:58.105495][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:58.106165][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:58.106087][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:58.107461][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:58.139090][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 9

[2020-01-28 17:10:58.139408][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 9

[2020-01-28 17:10:58.140581][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:58.141270][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:58.141452][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:58.143199][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:58.165979][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 9

[2020-01-28 17:10:58.171614][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 10

[2020-01-28 17:10:58.172144][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:58.172828][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:58.172926][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:58.174894][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:58.209281][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 11

[2020-01-28 17:10:58.210192][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 9

[2020-01-28 17:10:58.211079][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:58.211651][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:58.211704][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:58.213705][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:58.244659][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 11

[2020-01-28 17:10:58.250383][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 11

[2020-01-28 17:10:58.251398][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:58.253495][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 100, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:58.253911][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:58.254290][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 100

[2020-01-28 17:10:58.272519][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.12283163  0.88545603 -0.16329934 -1.50059726 -0.63818131  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.05796329  0.         -0.1050313   0.
  0.         -0.02950873  0.         -0.06310071  0.          0.
  0.          0.         -0.17548496 -0.00744081  0.          0.
 -0.02509094  0.          0.          0.         -0.05491364  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.06096206  0.         -0.11046517  0.
  0.         -0.03103538  0.         -0.01901518  0.          0.
  0.          0.         -0.18456379 -0.00782576  0.          0.
 -0.00756107  0.          0.          0.         -0.01654803  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -0.06394281
  0.06394281  0.          0.         -0.11588399  0.11588399  0.
  0.          0.          0.         -0.02109357  0.02109357  0.
  0.         -0.02441971  0.02441971  0.          0.          0.
  0.          0.          0.          0.          0.         -0.04929863
  0.04929863 -0.00822902  0.00822902  0.          0.          0.
  0.         -0.00989943  0.00989943  0.          0.          0.
  0.          0.          0.         -0.02189049  0.02189049 -0.06604086
  0.06604086]

[2020-01-28 17:10:58.273127][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:58.364360][__main__.TRPOAgent.log][training]: gradient_step_direction: [-3.97409432  4.51355615  7.37880198 -8.70009222  6.08258776  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -1.08020351  0.         -1.9573628   0.
  0.         -0.54993266  0.         -6.72817271  0.          0.
  0.          0.         -3.27043481 -0.1386668   0.          0.
 -2.67534395  0.          0.          0.         -5.85521507  0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -2.67533414  0.         -4.84778977  0.
  0.         -1.36200142  0.          9.53324131  0.          0.
  0.          0.         -8.09970193 -0.34343533  0.          0.
  3.7907356   0.          0.          0.          8.29634312  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -1.56240421
  1.56240421  0.          0.         -2.82975363  2.82975363  0.
  0.          0.          0.         -0.29900669  0.29900669  0.
  0.         -8.08850296  8.08850296  0.          0.          0.
  0.          0.          0.          0.          0.          0.90853226
 -0.90853226 -0.20184304  0.20184304  0.          0.          0.
  0.         -3.33075875  3.33075875  0.          0.          0.
  0.          0.          0.         -7.28808339  7.28808339 -2.89824946
  2.89824946]

[2020-01-28 17:10:58.412876][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 2, New mean kl div: 0.0017436367609744857, New policy loss value: -4.59131481340307

[2020-01-28 17:10:58.461051][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 1.3661792776221409

[2020-01-28 17:10:58.461456][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:10:59.306407][__main__.TRPOAgent.log][learning]: Episode #32

[2020-01-28 17:10:59.308140][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:10:59.333885][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:10:59.334670][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:10:59.334787][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:10:59.339339][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:10:59.369994][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 17:10:59.375915][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 11

[2020-01-28 17:10:59.376519][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:10:59.377199][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:10:59.377128][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:10:59.378006][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:10:59.413540][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:10:59.413939][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 11

[2020-01-28 17:10:59.415022][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:10:59.415665][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:10:59.415600][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:10:59.416751][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:10:59.451491][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 10

[2020-01-28 17:10:59.455526][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 10

[2020-01-28 17:10:59.456088][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:10:59.456802][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:10:59.456884][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:10:59.459249][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:10:59.492450][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 10

[2020-01-28 17:10:59.494851][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 11

[2020-01-28 17:10:59.495219][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:10:59.495679][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:10:59.495730][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:10:59.499495][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:10:59.527473][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 9

[2020-01-28 17:10:59.528148][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 9

[2020-01-28 17:10:59.529128][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:10:59.530656][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 101, Batch size: 1000, Number of batches: 1

[2020-01-28 17:10:59.531039][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:10:59.531428][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 101

[2020-01-28 17:10:59.546388][__main__.TRPOAgent.log][training]: policy_gradient: [-0.06946526 -0.85417054  0.06188865  1.35869546  0.89108003  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.04795591  0.          0.08689918  0.
  0.          0.02497608  0.          0.27500002  0.          0.
  0.          0.          0.15157176  0.0061547   0.          0.
  0.10913014  0.          0.          0.          0.23884346  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.02163062  0.          0.03919607  0.
  0.          0.01126552  0.          0.21737123  0.          0.
  0.          0.          0.06836679  0.00277609  0.          0.
  0.08626091  0.          0.          0.          0.18879161  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.04636532
 -0.04636532  0.          0.          0.08406351 -0.08406351  0.
  0.          0.          0.          0.01926224 -0.01926224  0.
  0.          0.04578335 -0.04578335  0.          0.          0.
  0.          0.          0.          0.          0.          0.07382888
 -0.07382888  0.00595235 -0.00595235  0.          0.          0.
  0.          0.01791759 -0.01791759  0.          0.          0.
  0.          0.          0.          0.0405625  -0.0405625   0.02429707
 -0.02429707]

[2020-01-28 17:10:59.546846][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:10:59.658743][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 16.93418494 -18.11232647 -27.33909893  -5.76955048 -14.63043428
   0.           0.           0.           0.           0.
   0.           0.           0.           0.           7.293223
   0.          13.21578598   0.           0.           3.79841069
   0.          21.46395178   0.           0.           0.
   0.          23.05139689   0.93601876   0.           0.
   8.5176837    0.           0.           0.          18.64189852
   0.           0.           0.           0.           0.
   0.           0.           0.           0.           0.55005334
   0.           0.99673165   0.           0.           0.28647743
   0.          -6.31189438   0.           0.           0.
   0.           1.73859592   0.07059436   0.           0.
  -2.5047945    0.           0.           0.          -5.48202236
   0.           0.           0.           0.           0.
   0.           0.           0.           0.           0.
   0.           0.           0.           0.           0.
   0.           0.           0.           6.4536677   -6.4536677
   0.           0.          11.70469945 -11.70469945   0.
   0.           0.           0.           3.14713166  -3.14713166
   0.           0.          14.46641311 -14.46641311   0.
   0.           0.           0.           0.           0.
   0.           0.          14.86193695 -14.86193695   0.82687772
  -0.82687772   0.           0.           0.           0.
   5.93048084  -5.93048084   0.           0.           0.
   0.           0.           0.          13.03030303 -13.03030303
   0.61796143  -0.61796143]

[2020-01-28 17:10:59.707626][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 2, New mean kl div: 0.0031497640991849066, New policy loss value: -0.04225369008005539

[2020-01-28 17:10:59.754736][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 1.1530265956275663

[2020-01-28 17:10:59.755144][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:11:00.437957][__main__.TRPOAgent.log][learning]: Episode #33

[2020-01-28 17:11:00.438502][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:11:00.462529][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:11:00.463359][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:11:00.463438][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:11:00.469089][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:11:00.493730][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 9

[2020-01-28 17:11:00.498859][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 9

[2020-01-28 17:11:00.499306][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:11:00.499777][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:11:00.499823][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:11:00.501613][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:11:00.537230][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 9

[2020-01-28 17:11:00.538907][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 9

[2020-01-28 17:11:00.539908][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:11:00.541003][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:11:00.541172][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:11:00.545734][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:11:00.575111][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 9

[2020-01-28 17:11:00.579897][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 11

[2020-01-28 17:11:00.580294][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:11:00.580882][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:11:00.580952][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:11:00.583395][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:11:00.618836][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 12

[2020-01-28 17:11:00.622136][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 11

[2020-01-28 17:11:00.622735][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:11:00.623858][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:11:00.624050][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:11:00.627211][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:11:00.662593][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 10

[2020-01-28 17:11:00.666158][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 11

[2020-01-28 17:11:00.666804][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:11:00.668182][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 100, Batch size: 1000, Number of batches: 1

[2020-01-28 17:11:00.668535][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:11:00.669030][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 100

[2020-01-28 17:11:00.684486][__main__.TRPOAgent.log][training]: policy_gradient: [-0.0685727  -0.75761256  0.06830639  1.21267128  0.72509644  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.03832432  0.          0.06945509  0.
  0.          0.02025816  0.          0.15294751  0.          0.
  0.          0.          0.12126275  0.00491736  0.          0.
  0.05311569  0.          0.          0.          0.13334332  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.01941372  0.          0.03518344  0.
  0.          0.01281641  0.          0.13652668  0.          0.
  0.          0.          0.0886601   0.00249096  0.          0.
  0.04465603  0.          0.          0.          0.11902724  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.0352999
 -0.0352999   0.          0.          0.06399533 -0.06399533  0.
  0.          0.          0.          0.01474817 -0.01474817  0.
  0.          0.02486853 -0.02486853  0.          0.          0.
  0.          0.          0.          0.          0.          0.0509026
 -0.0509026   0.00453274 -0.00453274  0.          0.          0.
  0.          0.00965927 -0.00965927  0.          0.          0.
  0.          0.          0.          0.02175429 -0.02175429  0.0185907
 -0.0185907 ]

[2020-01-28 17:11:00.685067][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:11:00.832856][__main__.TRPOAgent.log][training]: gradient_step_direction: [  6.40808329  -9.10416602 -11.7607827   -1.47761362  -1.37814708
   0.           0.           0.           0.           0.
   0.           0.           0.           0.          -0.54373054
   0.          -0.98540166   0.           0.          -0.78592572
   0.          16.41825566   0.           0.           0.
   0.           2.57665011  -0.0697656    0.           0.
  16.4793535    0.           0.           0.          14.31382661
   0.           0.           0.           0.           0.
   0.           0.           0.           0.           3.45640395
   0.           6.26403384   0.           0.          -2.52237899
   0.         -14.18219519   0.           0.           0.
   0.          -1.21930939   0.443488     0.           0.
   6.76536277   0.           0.           0.         -12.36438165
   0.           0.           0.           0.           0.
   0.           0.           0.           0.           0.
   0.           0.           0.           0.           0.
   0.           0.           0.           0.21672876  -0.21672876
   0.           0.           0.38863994  -0.38863994   0.
   0.           0.           0.          -0.31906319   0.31906319
   0.           0.          15.42573588 -15.42573588   0.
   0.           0.           0.           0.           0.
   0.           0.           2.21786354  -2.21786354   0.02971365
  -0.02971365   0.           0.           0.           0.
   6.26566593  -6.26566593   0.           0.           0.
   0.           0.           0.          13.86297058 -13.86297058
   3.30987436  -3.30987436]

[2020-01-28 17:11:00.872565][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.01163854935297395, New policy loss value: -0.039961568530128534

[2020-01-28 17:11:00.929039][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 2.2543054163589478

[2020-01-28 17:11:00.929445][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

