LOGGER started at 2020-01-29 22:25:44.530091.
Currently active debug channels:
	act
	batch_info
	linesearch
	learning
[2020-01-29 22:25:44.937601][__main__.TRPOAgent.log][learning]: Episode #0

[2020-01-29 22:25:45.135247][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:25:45.469372][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:25:45.469751][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:25:45.470344][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:25:47.301432][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.015216958716135005, New policy loss value: tf.Tensor(0.11289718113318153, shape=(), dtype=float64)

[2020-01-29 22:25:47.301876][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0.0024733036768338932

[2020-01-29 22:25:48.861730][__main__.TRPOAgent.log][learning]: Episode #1

[2020-01-29 22:25:48.862565][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:25:49.192303][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:25:49.192663][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:25:49.193271][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:25:50.931445][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.701762595898396e-11, Discarded policy loss value: tf.Tensor(6.827354435968324e-06, shape=(), dtype=float64)

[2020-01-29 22:25:50.931830][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0.0005796395702418522

[2020-01-29 22:25:51.521795][__main__.TRPOAgent.log][learning]: Episode #2

[2020-01-29 22:25:51.522193][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:25:51.798863][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:25:51.799201][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:25:51.799709][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:25:53.440841][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.852645115075963e-11, Discarded policy loss value: tf.Tensor(7.057873745325765e-06, shape=(), dtype=float64)

[2020-01-29 22:25:53.441240][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0.002127933422646796

[2020-01-29 22:25:53.923236][__main__.TRPOAgent.log][learning]: Episode #3

[2020-01-29 22:25:53.923658][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:25:54.213649][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:25:54.213988][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:25:54.214529][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:25:55.863784][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.381527603280258e-11, Discarded policy loss value: tf.Tensor(6.540868455314041e-06, shape=(), dtype=float64)

[2020-01-29 22:25:55.864165][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0.00030043972583371215

[2020-01-29 22:25:56.442610][__main__.TRPOAgent.log][learning]: Episode #4

[2020-01-29 22:25:56.443277][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:25:56.728104][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:25:56.728449][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:25:56.728956][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:25:58.440540][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.615625999045857e-11, Discarded policy loss value: tf.Tensor(7.138802704402013e-06, shape=(), dtype=float64)

[2020-01-29 22:25:58.440929][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 3.163562222141536e-06

[2020-01-29 22:25:58.915862][__main__.TRPOAgent.log][learning]: Episode #5

[2020-01-29 22:25:58.916309][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:25:59.201248][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:25:59.201600][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:25:59.202125][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:00.850300][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.371125460561382e-11, Discarded policy loss value: tf.Tensor(6.826753678829834e-06, shape=(), dtype=float64)

[2020-01-29 22:26:00.850712][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 6.007944709267577e-05

[2020-01-29 22:26:01.424955][__main__.TRPOAgent.log][learning]: Episode #6

[2020-01-29 22:26:01.425639][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:01.710213][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:01.710581][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:01.711114][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:03.395250][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.403262607312539e-11, Discarded policy loss value: tf.Tensor(6.926482871938855e-06, shape=(), dtype=float64)

[2020-01-29 22:26:03.395737][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0.0003694178376463242

[2020-01-29 22:26:03.873446][__main__.TRPOAgent.log][learning]: Episode #7

[2020-01-29 22:26:03.873790][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:04.155557][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:04.155910][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:04.156413][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:05.808286][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.775344914429432e-11, Discarded policy loss value: tf.Tensor(6.671766219880395e-06, shape=(), dtype=float64)

[2020-01-29 22:26:05.808668][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 2.3666564755497887e-06

[2020-01-29 22:26:06.394703][__main__.TRPOAgent.log][learning]: Episode #8

[2020-01-29 22:26:06.395466][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:06.672459][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:06.672845][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:06.679614][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:08.323257][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.775163176554682e-11, Discarded policy loss value: tf.Tensor(7.098503931515014e-06, shape=(), dtype=float64)

[2020-01-29 22:26:08.323657][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0.0001288966854190221

[2020-01-29 22:26:08.823302][__main__.TRPOAgent.log][learning]: Episode #9

[2020-01-29 22:26:08.823651][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:09.099224][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:09.099594][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:09.100138][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:10.769482][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.610178155532615e-11, Discarded policy loss value: tf.Tensor(7.0523042417615434e-06, shape=(), dtype=float64)

[2020-01-29 22:26:10.769859][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 2.4301078283883725e-06

[2020-01-29 22:26:11.337201][__main__.TRPOAgent.log][learning]: Episode #10

[2020-01-29 22:26:11.337625][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:11.623203][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:11.623544][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:11.624096][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:13.392003][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.464431245109417e-11, Discarded policy loss value: tf.Tensor(6.5411677825634475e-06, shape=(), dtype=float64)

[2020-01-29 22:26:13.392392][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 2.5219399604736735e-05

[2020-01-29 22:26:13.877445][__main__.TRPOAgent.log][learning]: Episode #11

[2020-01-29 22:26:13.877789][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:14.150963][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:14.151335][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:14.151843][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:15.814749][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.91424959058825e-11, Discarded policy loss value: tf.Tensor(7.502214147034124e-06, shape=(), dtype=float64)

[2020-01-29 22:26:15.815169][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 7.87195345127016e-06

[2020-01-29 22:26:16.430306][__main__.TRPOAgent.log][learning]: Episode #12

[2020-01-29 22:26:16.431088][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:16.715132][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:16.715516][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:16.716081][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:18.400329][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.57799472061924e-11, Discarded policy loss value: tf.Tensor(6.701556577514967e-06, shape=(), dtype=float64)

[2020-01-29 22:26:18.400797][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 1.0343474480123405e-05

[2020-01-29 22:26:18.895973][__main__.TRPOAgent.log][learning]: Episode #13

[2020-01-29 22:26:18.896336][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:19.177124][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:19.177479][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:19.178083][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:20.835776][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.401126970063782e-11, Discarded policy loss value: tf.Tensor(7.462733458223274e-06, shape=(), dtype=float64)

[2020-01-29 22:26:20.836183][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 7.305026265385095e-05

[2020-01-29 22:26:21.363489][__main__.TRPOAgent.log][learning]: Episode #14

[2020-01-29 22:26:21.363918][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:21.640136][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:21.640500][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:21.641098][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:23.347976][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.720608834546384e-11, Discarded policy loss value: tf.Tensor(7.41144161677926e-06, shape=(), dtype=float64)

[2020-01-29 22:26:23.348567][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 5.307848717279739e-05

[2020-01-29 22:26:23.867830][__main__.TRPOAgent.log][learning]: Episode #15

[2020-01-29 22:26:23.868194][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:24.141259][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:24.141623][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:24.142172][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:25.808739][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.61321675020694e-11, Discarded policy loss value: tf.Tensor(7.504622231604104e-06, shape=(), dtype=float64)

[2020-01-29 22:26:25.809148][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 8.041273687808826e-07

[2020-01-29 22:26:26.330089][__main__.TRPOAgent.log][learning]: Episode #16

[2020-01-29 22:26:26.330447][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:26.613914][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:26.614264][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:26.614788][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:28.292036][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.556240188030982e-11, Discarded policy loss value: tf.Tensor(6.95920249324079e-06, shape=(), dtype=float64)

[2020-01-29 22:26:28.292414][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 3.300439420286239e-05

[2020-01-29 22:26:28.817085][__main__.TRPOAgent.log][learning]: Episode #17

[2020-01-29 22:26:28.817589][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:29.093438][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:29.093782][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:29.100516][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:30.865176][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.650869755234246e-11, Discarded policy loss value: tf.Tensor(7.846273094898469e-06, shape=(), dtype=float64)

[2020-01-29 22:26:30.865554][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 5.246171553494605e-05

[2020-01-29 22:26:31.417551][__main__.TRPOAgent.log][learning]: Episode #18

[2020-01-29 22:26:31.417969][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:31.688579][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:31.688942][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:31.689515][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:33.353923][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.531640956234007e-11, Discarded policy loss value: tf.Tensor(7.648557296384813e-06, shape=(), dtype=float64)

[2020-01-29 22:26:33.354312][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 4.233265600284142e-07

[2020-01-29 22:26:34.001595][__main__.TRPOAgent.log][learning]: Episode #19

[2020-01-29 22:26:34.002364][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:34.278961][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:34.279566][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:34.280140][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:35.974000][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.646874047564987e-11, Discarded policy loss value: tf.Tensor(7.844661439073902e-06, shape=(), dtype=float64)

[2020-01-29 22:26:35.974493][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0.0004831629352793243

[2020-01-29 22:26:36.517648][__main__.TRPOAgent.log][learning]: Episode #20

[2020-01-29 22:26:36.518052][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:36.797749][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:36.798102][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:36.798622][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:38.455368][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.884964544026613e-11, Discarded policy loss value: tf.Tensor(7.645746669287708e-06, shape=(), dtype=float64)

[2020-01-29 22:26:38.455822][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 4.117384549701979e-07

[2020-01-29 22:26:39.121771][__main__.TRPOAgent.log][learning]: Episode #21

[2020-01-29 22:26:39.122660][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:39.412450][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:39.412816][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:39.413359][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:41.081660][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.497921066503402e-11, Discarded policy loss value: tf.Tensor(7.71031414968786e-06, shape=(), dtype=float64)

[2020-01-29 22:26:41.082082][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 1.074029778792493e-05

[2020-01-29 22:26:41.655055][__main__.TRPOAgent.log][learning]: Episode #22

[2020-01-29 22:26:41.655419][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:41.939518][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:41.939873][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:41.940336][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:43.621649][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.642954858614508e-11, Discarded policy loss value: tf.Tensor(7.164994701968821e-06, shape=(), dtype=float64)

[2020-01-29 22:26:43.622070][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 1.174450392582571e-06

[2020-01-29 22:26:44.132621][__main__.TRPOAgent.log][learning]: Episode #23

[2020-01-29 22:26:44.132966][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:44.408229][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:44.408636][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:44.409184][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:46.082809][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.703945128035049e-11, Discarded policy loss value: tf.Tensor(7.42125138429942e-06, shape=(), dtype=float64)

[2020-01-29 22:26:46.083199][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 7.343292713812843e-06

[2020-01-29 22:26:46.662135][__main__.TRPOAgent.log][learning]: Episode #24

[2020-01-29 22:26:46.662601][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:46.935893][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:46.936243][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:46.936757][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:48.720171][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.78068559401342e-11, Discarded policy loss value: tf.Tensor(7.576128169076837e-06, shape=(), dtype=float64)

[2020-01-29 22:26:48.720626][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 2.1928665848644501e-07

[2020-01-29 22:26:49.251064][__main__.TRPOAgent.log][learning]: Episode #25

[2020-01-29 22:26:49.251473][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:49.527806][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:49.528177][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:49.528714][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:51.236681][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.57771804890339e-11, Discarded policy loss value: tf.Tensor(7.87806035228884e-06, shape=(), dtype=float64)

[2020-01-29 22:26:51.237188][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 2.108445968218575e-06

[2020-01-29 22:26:51.768924][__main__.TRPOAgent.log][learning]: Episode #26

[2020-01-29 22:26:51.769281][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:52.056380][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:52.056743][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:52.057278][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:53.723952][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.246409052833673e-11, Discarded policy loss value: tf.Tensor(7.164564022404988e-06, shape=(), dtype=float64)

[2020-01-29 22:26:53.724336][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 1.1670390085350064e-07

[2020-01-29 22:26:54.359690][__main__.TRPOAgent.log][learning]: Episode #27

[2020-01-29 22:26:54.360337][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:54.642821][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:54.643163][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:54.643779][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:56.467603][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.619338824298812e-11, Discarded policy loss value: tf.Tensor(7.12912120572924e-06, shape=(), dtype=float64)

[2020-01-29 22:26:56.468058][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0.0003264471350121312

[2020-01-29 22:26:57.054777][__main__.TRPOAgent.log][learning]: Episode #28

[2020-01-29 22:26:57.055196][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:57.409779][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:57.410176][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:57.410780][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:26:59.148853][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.649826551138418e-11, Discarded policy loss value: tf.Tensor(7.4740245925369395e-06, shape=(), dtype=float64)

[2020-01-29 22:26:59.149237][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 5.438173820948577e-06

[2020-01-29 22:26:59.705493][__main__.TRPOAgent.log][learning]: Episode #29

[2020-01-29 22:26:59.705853][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:26:59.989528][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:26:59.989887][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:26:59.990418][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-29 22:27:01.678626][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.593443019619139e-11, Discarded policy loss value: tf.Tensor(7.973117661575676e-06, shape=(), dtype=float64)

[2020-01-29 22:27:01.679036][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0.00041383867010154064

[2020-01-29 22:27:02.298078][__main__.TRPOAgent.log][learning]: Episode #30

[2020-01-29 22:27:02.298713][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 5000

[2020-01-29 22:27:02.671094][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-29 22:27:02.671493][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: None, Batch size: 100

[2020-01-29 22:27:02.672067][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



