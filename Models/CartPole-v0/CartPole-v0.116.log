LOGGER started at 2020-01-28 16:56:21.289075.
Currently active debug channels:
	rollouts
	act
	training
	batch_info
	linesearch
	learning
	thread_rollouts
[2020-01-28 16:56:21.763522][__main__.TRPOAgent.log][learning]: Episode #0

[2020-01-28 16:56:22.017595][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 16:56:22.039852][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 16:56:22.040892][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 16:56:22.040964][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 16:56:22.045791][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 16:56:22.079609][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 10

[2020-01-28 16:56:22.079904][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 16:56:22.080644][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 16:56:22.081316][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 16:56:22.081385][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 16:56:22.084277][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 16:56:22.122144][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 11

[2020-01-28 16:56:22.122778][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 10

[2020-01-28 16:56:22.123586][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 16:56:22.124163][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 16:56:22.124215][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 16:56:22.126206][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 16:56:22.160888][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 11

[2020-01-28 16:56:22.161194][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 10

[2020-01-28 16:56:22.162321][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 16:56:22.162906][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 16:56:22.162985][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 16:56:22.167072][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 16:56:22.199401][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 10

[2020-01-28 16:56:22.204615][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 12

[2020-01-28 16:56:22.205164][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 16:56:22.205836][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 16:56:22.205901][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 16:56:22.207895][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 16:56:22.230985][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 10

[2020-01-28 16:56:22.237105][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 10

[2020-01-28 16:56:22.237622][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 16:56:22.239380][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 104, Batch size: 1000, Number of batches: 10

[2020-01-28 16:56:22.239894][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 16:56:22.240286][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 10

[2020-01-28 16:56:22.255715][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.00633956  0.07376481 -0.00910722 -0.11468033 -0.00121578  0.
  0.00146707 -0.00791484  0.          0.01324282 -0.00558051  0.00144065
  0.0138757   0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -0.00959825
 -0.01854231  0.         -0.02368388  0.01213198  0.0027365   0.00261404
  0.          0.0183768   0.01173537  0.00505817  0.          0.
 -0.00020755  0.00111975  0.         -0.00187353  0.0007895  -0.00020382
 -0.00196306  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.00135791
  0.00262327  0.          0.00335067 -0.00171637 -0.00038715 -0.00036982
  0.         -0.00259986 -0.00166026 -0.0007156   0.          0.
  0.         -0.00791088  0.00791088 -0.00539249  0.00539249  0.
  0.         -0.01130908  0.01130908 -0.00072188  0.00072188 -0.00981995
  0.00981995 -0.01379588  0.01379588  0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -0.00715412
  0.00715412 -0.0035136   0.0035136   0.          0.         -0.01238563
  0.01238563 -0.00818816  0.00818816 -0.00082406  0.00082406 -0.0101667
  0.0101667   0.          0.         -0.01213619  0.01213619 -0.00123259
  0.00123259 -0.00250419  0.00250419  0.          0.          0.00446806
 -0.00446806]

[2020-01-28 16:56:22.256289][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 16:56:22.284122][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 0.26265547  2.92268897 -0.36955032 -4.55652455 -0.20745196  0.
  0.05706906 -0.3078874   0.          0.51514623 -0.21708194  0.05604135
  0.53976524  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -0.37337233
 -0.72129643  0.         -0.92130368  0.47193464  0.10645013  0.10168608
  0.          0.71485837  0.4565065   0.19676286  0.          0.
 -0.03541532  0.19106555  0.         -0.31968407  0.13471445 -0.03477756
 -0.33496188  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.23170351
  0.44761461  0.          0.57173303 -0.29286827 -0.06605971 -0.06310329
  0.         -0.44361935 -0.28329404 -0.12210504  0.          0.
  0.         -0.30773342  0.30773342 -0.20976797  0.20976797  0.
  0.         -0.43992354  0.43992354 -0.02808098  0.02808098 -0.38199654
  0.38199654 -0.53666022  0.53666022  0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -0.27829564
  0.27829564 -0.13667918  0.13667918  0.          0.         -0.48180147
  0.48180147 -0.31851981  0.31851981 -0.03205578  0.03205578 -0.39548519
  0.39548519  0.          0.         -0.47209828  0.47209828 -0.04794779
  0.04794779 -0.09741316  0.09741316  0.          0.          0.76239465
 -0.76239465]

[2020-01-28 16:56:22.332688][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 2, New mean kl div: 0.0036159703105111116, New policy loss value: -0.06920158271136626

