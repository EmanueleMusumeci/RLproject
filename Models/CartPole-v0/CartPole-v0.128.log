LOGGER started at 2020-01-28 17:04:30.017054.
Currently active debug channels:
	rollouts
	act
	training
	batch_info
	linesearch
	learning
	thread_rollouts
[2020-01-28 17:04:30.433529][__main__.TRPOAgent.log][learning]: Episode #0

[2020-01-28 17:04:30.639597][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:04:30.651735][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:04:30.652455][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:04:30.652677][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:04:30.659347][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:04:30.690908][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 9

[2020-01-28 17:04:30.693066][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 9

[2020-01-28 17:04:30.694036][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:04:30.694805][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:04:30.694686][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:04:30.696062][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:04:30.731066][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 9

[2020-01-28 17:04:30.731626][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 10

[2020-01-28 17:04:30.732631][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:04:30.733152][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:04:30.733249][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:04:30.736845][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:04:30.766401][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 11

[2020-01-28 17:04:30.774803][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 11

[2020-01-28 17:04:30.775473][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:04:30.776120][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:04:30.776193][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:04:30.778497][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:04:30.813433][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 11

[2020-01-28 17:04:30.817976][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 13

[2020-01-28 17:04:30.818353][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:04:30.818817][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:04:30.818864][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:04:30.820840][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:04:30.854441][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 10

[2020-01-28 17:04:30.856598][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 11

[2020-01-28 17:04:30.857248][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:04:30.858512][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 104, Batch size: 1000, Number of batches: 10

[2020-01-28 17:04:30.858954][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:04:30.859296][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 9

[2020-01-28 17:04:30.872456][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.00375746  0.0290176  -0.00362034 -0.0481422  -0.04230814  0.03151155
 -0.05126914  0.04821552 -0.05188571 -0.04111724 -0.07909308 -0.02220278
  0.          0.04805522  0.04353017  0.          0.          0.
  0.06877627 -0.00342529  0.          0.          0.          0.10271925
  0.         -0.1300825   0.         -0.02844363  0.          0.
  0.0419795   0.          0.01775557  0.         -0.01762723  0.02874052
 -0.04676068  0.04397559 -0.04732303 -0.03750151 -0.07213787 -0.02025033
  0.          0.04382939  0.03970226  0.          0.          0.
  0.06272828 -0.00312408  0.          0.          0.          0.09368642
  0.         -0.11864343  0.         -0.02594238  0.          0.
  0.03828795  0.          0.0161942   0.         -0.01607714 -0.02666268
  0.02666268 -0.04891508  0.04891508 -0.06402764  0.06402764 -0.02891753
  0.02891753 -0.01185416  0.01185416 -0.00287808  0.00287808 -0.05392211
  0.05392211  0.          0.         -0.00055533  0.00055533 -0.0031968
  0.0031968   0.          0.          0.          0.          0.
  0.         -0.00100183  0.00100183 -0.03594707  0.03594707  0.
  0.          0.          0.          0.          0.         -0.01504776
  0.01504776  0.          0.         -0.06833165  0.06833165  0.
  0.         -0.0115969   0.0115969   0.          0.          0.
  0.         -0.06090649  0.06090649  0.          0.         -0.01802437
  0.01802437  0.          0.         -0.03445164  0.03445164 -0.2282863
  0.2282863 ]

[2020-01-28 17:04:30.873098][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:30.919875][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 2.72217673e-02 -2.31141405e-02 -5.62946818e-02 -1.16522667e-02
  2.40541224e-01 -1.36345428e-02  2.21833157e-02 -2.08620852e-02
  2.24500990e-02  1.77907619e-02  3.42222942e-02  9.60677427e-03
  0.00000000e+00 -2.07927151e-02 -1.88348012e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00 -2.97583757e-02  1.48206051e-03
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.44449557e-02
  0.00000000e+00  5.62845761e-02  0.00000000e+00  1.23070958e-02
  0.00000000e+00  0.00000000e+00 -1.81638614e-02  0.00000000e+00
 -7.68255202e-03  0.00000000e+00  7.62701069e-03 -1.63403084e-01
  2.65855981e-01 -2.50021468e-01  2.69053205e-01  2.13213358e-01
  4.10136990e-01  1.15132468e-01  0.00000000e+00 -2.49190232e-01
 -2.25725613e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -3.56639164e-01  1.77618231e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -5.32650410e-01  0.00000000e+00  6.74542476e-01
  0.00000000e+00  1.47494377e-01  0.00000000e+00  0.00000000e+00
 -2.17684619e-01  0.00000000e+00 -9.20714854e-02  0.00000000e+00
  9.14059575e-02  1.15365113e-02 -1.15365113e-02  2.11647587e-02
 -2.11647587e-02  2.77037219e-02 -2.77037219e-02  1.25121438e-02
 -1.25121438e-02  5.12909995e-03 -5.12909995e-03  1.24529398e-03
 -1.24529398e-03  2.33312224e-02 -2.33312224e-02  0.00000000e+00
  0.00000000e+00  2.40284658e-04 -2.40284658e-04  1.38320673e-03
 -1.38320673e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  4.33478202e-04
 -4.33478202e-04  1.55537163e-02 -1.55537163e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  6.51092512e-03 -6.51092512e-03  0.00000000e+00
  0.00000000e+00  2.95659930e-02 -2.95659930e-02  0.00000000e+00
  0.00000000e+00  5.01778998e-03 -5.01778998e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.63532534e-02
 -2.63532534e-02  0.00000000e+00  0.00000000e+00  7.79885514e-03
 -7.79885514e-03  0.00000000e+00  0.00000000e+00  1.49066677e-02
 -1.49066677e-02 -1.49018404e+00  1.49018404e+00]

[2020-01-28 17:04:30.950504][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.014283424449451656, New policy loss value: -0.09233753883176073

[2020-01-28 17:04:31.227854][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 13.39966242801812

[2020-01-28 17:04:31.228224][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:31.230826][__main__.TRPOAgent.log][batch_info]: Batch #1, batch length: 9

[2020-01-28 17:04:31.241536][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00208451 -0.07320233  0.00727902  0.11195897 -0.06730962 -0.05427442
  0.09314517 -0.0814167   0.09284745  0.07281579  0.13869603  0.04259272
  0.          0.          0.          0.          0.          0.
  0.          0.00847388  0.          0.          0.         -0.18368676
  0.          0.23249052  0.          0.05060565  0.          0.
 -0.07052495  0.         -0.03037128  0.          0.03323952 -0.00367658
 -0.02733814 -0.00551522 -0.02725076 -0.02137146 -0.04070733 -0.01250098
  0.          0.          0.          0.          0.          0.
  0.         -0.00248709  0.          0.          0.         -0.08025248
  0.         -0.06823605  0.         -0.01485278  0.          0.
 -0.0047774   0.         -0.00205737  0.         -0.00975581  0.04550332
 -0.04550332  0.08120896 -0.08120896  0.11101458 -0.11101458  0.04613833
 -0.04613833  0.01719271 -0.01719271 -0.00181749  0.00181749  0.09249664
 -0.09249664  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.062649   -0.062649    0.
  0.          0.          0.          0.          0.          0.00440614
 -0.00440614  0.          0.          0.10837584 -0.10837584  0.
  0.          0.01784102 -0.01784102  0.          0.          0.
  0.          0.10584966 -0.10584966  0.          0.          0.0309861
 -0.0309861   0.          0.          0.05879911 -0.05879911 -0.08071217
  0.08071217]

[2020-01-28 17:04:31.242089][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:31.281421][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 0.01737602 -0.29110615  0.01180148  0.41475738 -0.67643596 -0.16818469
  0.27786989 -0.25229272  0.27698173  0.21722347  0.41375684  0.12706224
  0.          0.          0.          0.          0.          0.
  0.          0.02527919  0.          0.          0.          0.15282084
  0.          0.69356376  0.          0.15096635  0.          0.
 -0.21854156  0.         -0.09411404  0.          0.09915985  0.00585542
 -0.33820951  0.00878367 -0.33712848 -0.26439367 -0.50360436 -0.1546539
  0.          0.          0.          0.          0.          0.
  0.         -0.0307686   0.          0.          0.          0.06886552
  0.         -0.84417154  0.         -0.18374879  0.          0.
  0.00760861  0.          0.00327662  0.         -0.12069247  0.14521038
 -0.14521038  0.18395602 -0.18395602  0.35044484 -0.35044484  0.07863242
 -0.07863242  0.00452855 -0.00452855 -0.09537059  0.09537059  0.25068507
 -0.25068507  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.18299856 -0.18299856  0.
  0.          0.          0.          0.          0.         -0.00316828
  0.00316828  0.          0.          0.1753695  -0.1753695   0.
  0.          0.02087564 -0.02087564  0.          0.          0.
  0.          0.33360764 -0.33360764  0.          0.          0.09838882
 -0.09838882  0.          0.          0.15536244 -0.15536244 -0.99851792
  0.99851792]

[2020-01-28 17:04:31.320988][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.003876531164821042, New policy loss value: -0.08771426763404934

[2020-01-28 17:04:31.357990][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 3.96366594837875

[2020-01-28 17:04:31.358553][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:31.361069][__main__.TRPOAgent.log][batch_info]: Batch #2, batch length: 9

[2020-01-28 17:04:31.370538][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.00374926  0.04395582  0.00039704 -0.06989835 -0.11358101  0.01617783
 -0.0423194   0.02643799 -0.04014131 -0.03036643 -0.05581212 -0.02260031
  0.          0.          0.          0.          0.          0.
  0.         -0.0070929   0.          0.          0.         -0.01157315
  0.         -0.1000942   0.         -0.0214499   0.          0.
  0.02231517  0.          0.01049306  0.         -0.01685186  0.01830035
 -0.08842931  0.03945259 -0.08387804 -0.06345275 -0.11662327 -0.04722492
  0.          0.          0.          0.          0.          0.
  0.         -0.01482109  0.          0.          0.         -0.0155618
  0.         -0.20915374  0.         -0.04482105  0.          0.
  0.03330023  0.          0.01565847  0.         -0.03521312 -0.00942266
  0.00942266 -0.05055424  0.05055424 -0.031249    0.031249   -0.03623678
  0.03623678 -0.02069596  0.02069596 -0.02536472  0.02536472 -0.04562995
  0.04562995  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.         -0.02707099  0.02707099  0.
  0.          0.          0.          0.          0.         -0.00183889
  0.00183889  0.          0.         -0.08782762  0.08782762  0.
  0.         -0.01677945  0.01677945  0.          0.          0.
  0.         -0.03097483  0.03097483  0.          0.         -0.00745235
  0.00745235  0.          0.         -0.03016654  0.03016654 -0.23894074
  0.23894074]

[2020-01-28 17:04:31.370946][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:31.456928][__main__.TRPOAgent.log][training]: gradient_step_direction: [-1.48764798e+00  3.02559205e-01  2.38842731e+00  1.61781459e+00
 -4.82253553e-03 -3.32205788e-01  4.87879410e-02 -3.04793117e-02
  4.62770176e-02  3.50080693e-02  6.43433309e-02  2.60546435e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  8.17690924e-03
  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.17569514e+00
  0.00000000e+00  1.15393881e-01  0.00000000e+00  2.47285934e-02
  0.00000000e+00  0.00000000e+00 -2.57263022e-02  0.00000000e+00
 -1.20970067e-02  0.00000000e+00  1.94275990e-02 -1.24865799e+00
 -2.98764904e-01 -2.94161232e-01 -2.83388131e-01 -2.14379796e-01
 -3.94020317e-01 -1.59552813e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -5.00741284e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -7.00163937e+00  0.00000000e+00 -7.06641282e-01
  0.00000000e+00 -1.51431206e-01  0.00000000e+00  0.00000000e+00
 -2.48288825e-01  0.00000000e+00 -1.16750644e-01  0.00000000e+00
 -1.18970104e-01 -4.79050344e-02  4.79050344e-02  6.19825275e-03
 -6.19825275e-03 -4.10021049e-02  4.10021049e-02 -1.14094497e-02
  1.14094497e-02 -1.85430502e-02  1.85430502e-02 -5.27836604e-02
  5.27836604e-02  3.08053178e-02 -3.08053178e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.84838855e-02 -2.84838855e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -2.06365862e+00  2.06365862e+00  0.00000000e+00
  0.00000000e+00 -3.21841947e-02  3.21841947e-02  0.00000000e+00
  0.00000000e+00 -9.91001723e-03  9.91001723e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.13592896e-02
  3.13592896e-02  0.00000000e+00  0.00000000e+00 -1.97704355e-02
  1.97704355e-02  0.00000000e+00  0.00000000e+00  1.72776601e-02
 -1.72776601e-02 -8.07278875e-01  8.07278875e-01]

[2020-01-28 17:04:31.498610][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.0036352539657798994, New policy loss value: -0.06810390682876849

[2020-01-28 17:04:31.530662][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 3.4607529044151306

[2020-01-28 17:04:31.531059][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:31.534522][__main__.TRPOAgent.log][batch_info]: Batch #3, batch length: 10

[2020-01-28 17:04:31.547515][__main__.TRPOAgent.log][training]: policy_gradient: [-9.72498659e-04 -2.44414265e-02  5.41780527e-03  3.82177460e-02
 -6.59845901e-02 -6.94293742e-02  1.14775128e-01 -7.43314259e-02
  1.07643984e-01  8.07297143e-02  1.47053544e-01  6.32411354e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.11796655e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.50057567e-01
  0.00000000e+00  2.68150848e-01  0.00000000e+00  5.72506577e-02
  0.00000000e+00  0.00000000e+00 -6.25099608e-02  0.00000000e+00
 -3.21994987e-02  0.00000000e+00  4.67526024e-02 -2.98693160e-02
 -2.02986745e-02 -1.13217551e-03 -1.90374887e-02 -1.42775375e-02
 -2.60073073e-02 -1.11845767e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  3.22597047e-04  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.41639018e-01  0.00000000e+00 -4.74240967e-02
  0.00000000e+00 -1.01251245e-02  0.00000000e+00  0.00000000e+00
 -9.52117433e-04  0.00000000e+00 -7.33087256e-03  0.00000000e+00
 -8.26848004e-03  1.22327919e-02 -1.22327919e-02  1.06500439e-01
 -1.06500439e-01  1.15868881e-01 -1.15868881e-01  6.69206475e-02
 -6.69206475e-02  3.10753968e-02 -3.10753968e-02  2.02285099e-02
 -2.02285099e-02  1.11104348e-01 -1.11104348e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  7.17885461e-02 -7.17885461e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.34420788e-02 -2.34420788e-02  0.00000000e+00
  0.00000000e+00  1.59504726e-01 -1.59504726e-01  0.00000000e+00
  0.00000000e+00  2.82388019e-02 -2.82388019e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.11096008e-01
 -1.11096008e-01  0.00000000e+00  0.00000000e+00  3.14615140e-02
 -3.14615140e-02  0.00000000e+00  0.00000000e+00  7.16178549e-02
 -7.16178549e-02 -5.46384201e-02  5.46384201e-02]

[2020-01-28 17:04:31.547942][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:31.607235][__main__.TRPOAgent.log][training]: gradient_step_direction: [-1.64946774e-01 -5.01090643e-01  3.83385847e-01  8.50154133e-01
 -2.09677744e+00  9.60125535e-01  3.18436410e-01 -2.06228008e-01
  2.98651513e-01  2.23979560e-01  4.07990908e-01  1.75458548e-01
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.87616315e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  4.73366577e-01
  0.00000000e+00  7.43967786e-01  0.00000000e+00  1.58838378e-01
  0.00000000e+00  0.00000000e+00 -1.73430081e-01  0.00000000e+00
 -1.85508575e-04  0.00000000e+00  1.29712156e-01  4.49067227e-01
 -3.69365995e-01  7.31183272e-01 -3.46416851e-01 -2.59802158e-01
 -4.73243799e-01 -2.03520637e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -2.08339892e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.67467437e-01  0.00000000e+00 -8.62955557e-01
  0.00000000e+00 -1.84242482e-01  0.00000000e+00  0.00000000e+00
  6.14897925e-01  0.00000000e+00  5.23791784e-01  0.00000000e+00
 -1.50457788e-01 -1.31221399e-01  1.31221399e-01  2.83788840e-01
 -2.83788840e-01  6.42908151e-01 -6.42908151e-01  1.71635207e-01
 -1.71635207e-01  7.39141021e-02 -7.39141021e-02  3.03267036e-02
 -3.03267036e-02  3.06690570e-01 -3.06690570e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.09001614e-01 -2.09001614e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -3.35355905e-01  3.35355905e-01  0.00000000e+00
  0.00000000e+00  4.06910791e-01 -4.06910791e-01  0.00000000e+00
  0.00000000e+00  7.01994232e-02 -7.01994232e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.85365918e-01
 -5.85365918e-01  0.00000000e+00  0.00000000e+00  2.16395066e-01
 -2.16395066e-01  0.00000000e+00  0.00000000e+00  1.96565754e-01
 -1.96565754e-01 -9.94231920e-01  9.94231920e-01]

[2020-01-28 17:04:31.646453][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.003961509717387094, New policy loss value: -0.0929328767303561

[2020-01-28 17:04:31.677825][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 3.7966746613383293

[2020-01-28 17:04:31.678300][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:31.680848][__main__.TRPOAgent.log][batch_info]: Batch #4, batch length: 11

[2020-01-28 17:04:31.690092][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00214196 -0.02774814  0.00777079  0.04634855 -0.07208446 -0.03510924
  0.04056678 -0.01337884  0.03657214  0.02657321  0.04677768  0.02469677
  0.          0.          0.          0.          0.          0.
  0.          0.00992874  0.          0.          0.         -0.03519916
  0.          0.09078246  0.          0.01912212  0.          0.
 -0.01055389  0.         -0.0059926   0.          0.01778728 -0.01954457
 -0.02689629  0.00887034 -0.02424779 -0.01761838 -0.0310142  -0.01637427
  0.          0.          0.          0.          0.          0.
  0.         -0.00658288  0.          0.          0.         -0.01228756
  0.         -0.06018993  0.         -0.01267821  0.          0.
  0.00699737  0.          0.0045891   0.         -0.01179319  0.01827499
 -0.01827499  0.03727201 -0.03727201  0.03804552 -0.03804552  0.02440461
 -0.02440461  0.01218448 -0.01218448  0.01055013 -0.01055013  0.03731775
 -0.03731775  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.02435289 -0.02435289  0.
  0.          0.          0.          0.          0.          0.00482155
 -0.00482155  0.          0.          0.0584891  -0.0584891   0.
  0.          0.01062586 -0.01062586  0.          0.          0.
  0.          0.03644191 -0.03644191  0.          0.          0.00986465
 -0.00986465  0.          0.          0.02422093 -0.02422093 -0.07449723
  0.07449723]

[2020-01-28 17:04:31.690517][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:31.770087][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.37788495  0.45073856  0.67696491  0.10696792 -0.83981901 -2.55168184
  0.19909222 -0.0656605   0.17948751  0.13041515  0.22957405  0.12120584
  0.          0.          0.          0.          0.          0.
  0.          0.04872784  0.          0.          0.          0.31350282
  0.          0.44553911  0.          0.09384689  0.          0.
 -0.05179631  0.         -0.02941037  0.          0.08729575 -4.05891789
 -0.48890452  0.16124006 -0.44076178 -0.3202563  -0.56375757 -0.29764147
  0.          0.          0.          0.          0.          0.
  0.         -0.11965952  0.          0.          0.          2.13837311
  0.         -1.09409622  0.         -0.2304568   0.          0.
  0.12719423  0.          0.02269968  0.         -0.21436948 -0.68924616
  0.68924616  0.19638978 -0.19638978  0.22669319 -0.22669319  0.12928637
 -0.12928637  0.06512693 -0.06512693  0.05804419 -0.05804419  0.19552371
 -0.19552371  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.13656806 -0.13656806  0.
  0.          0.          0.          0.          0.          1.61798104
 -1.61798104  0.          0.          0.31007092 -0.31007092  0.
  0.          0.05651423 -0.05651423  0.          0.          0.
  0.          0.21437817 -0.21437817  0.          0.          0.04840704
 -0.04840704  0.          0.          0.12702609 -0.12702609 -0.36849374
  0.36849374]

[2020-01-28 17:04:31.809998][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.004119995002606327, New policy loss value: -0.03206695732946419

[2020-01-28 17:04:31.845989][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 4.226816392471929

[2020-01-28 17:04:31.846389][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:31.849408][__main__.TRPOAgent.log][batch_info]: Batch #5, batch length: 11

[2020-01-28 17:04:31.859636][__main__.TRPOAgent.log][training]: policy_gradient: [ 4.55669273e-03  4.45411914e-02 -1.94558224e-03 -7.22982987e-02
 -9.94951151e-02  0.00000000e+00 -6.52227847e-03  3.56314529e-04
 -5.72440321e-03 -4.06546274e-03 -1.40086395e-02 -8.16781204e-04
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.88467653e-03
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -9.72193428e-02
  0.00000000e+00 -1.41742329e-02  0.00000000e+00 -2.95694845e-03
  0.00000000e+00  0.00000000e+00  2.46726455e-04  0.00000000e+00
  2.10939571e-04  0.00000000e+00 -2.99312289e-03  0.00000000e+00
 -3.42245560e-02 -2.00463207e-04 -3.00378402e-02 -2.13328299e-02
 -5.07885125e-02  4.46290749e-03  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -9.88952218e-03  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -2.75383010e-02  0.00000000e+00 -7.43768961e-02
  0.00000000e+00 -1.55160882e-02  0.00000000e+00  0.00000000e+00
 -1.38808755e-04  0.00000000e+00 -4.18248253e-03  0.00000000e+00
 -1.57059075e-02  0.00000000e+00  0.00000000e+00 -2.37840979e-04
  2.37840979e-04 -1.54099001e-03  1.54099001e-03  8.63319052e-04
 -8.63319052e-04  1.27738861e-03 -1.27738861e-03  3.75477893e-03
 -3.75477893e-03 -1.78867110e-03  1.78867110e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -9.26954240e-04  9.26954240e-04  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  4.00224982e-02 -4.00224982e-02  0.00000000e+00
  0.00000000e+00  2.38792275e-03 -2.38792275e-03  0.00000000e+00
  0.00000000e+00  7.01499476e-04 -7.01499476e-04  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.49016029e-03
  1.49016029e-03  0.00000000e+00  0.00000000e+00 -1.37850592e-05
  1.37850592e-05  0.00000000e+00  0.00000000e+00 -1.02747662e-03
  1.02747662e-03  8.29518854e-02 -8.29518854e-02]

[2020-01-28 17:04:31.860052][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:31.972208][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 0.05227895  0.34257069 -0.13718772 -0.61489768  0.40915762  0.
 -0.0798762   0.16985511 -0.07010492 -0.04978843 -1.80687207  0.85088285
  0.          0.          0.          0.          0.          0.
  0.         -0.02308101  0.          0.          0.         -1.67645809
  0.         -0.17358726  0.         -0.0362128   0.          0.
  0.11761451  0.          0.10055493  0.         -0.03665577  0.
 -1.23888309  1.78644184 -1.08732958 -0.77221987 -4.92955954  6.25613447
  0.          0.          0.          0.          0.          0.
  0.         -0.35798746  0.          0.          0.          0.66278217
  0.         -2.69234401  0.         -0.56166161  0.          0.
  1.23700388  0.         -0.08075225  0.         -0.56853282  0.
  0.          0.12508626 -0.12508626 -0.11397754  0.11397754  0.12052572
 -0.12052572  0.09225263 -0.09225263  0.24672886 -0.24672886  0.08242088
 -0.08242088  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.04846622 -0.04846622  0.
  0.          0.          0.          0.          0.          1.70492397
 -1.70492397  0.          0.          0.3009419  -0.3009419   0.
  0.          0.06481817 -0.06481817  0.          0.          0.
  0.         -0.11762582  0.11762582  0.          0.         -0.19109324
  0.19109324  0.          0.          0.048202   -0.048202    1.60157108
 -1.60157108]

[2020-01-28 17:04:32.013365][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.004837254011800512, New policy loss value: -0.0839399768768058

[2020-01-28 17:04:32.050000][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 2.200849394821985

[2020-01-28 17:04:32.050388][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:32.053211][__main__.TRPOAgent.log][batch_info]: Batch #6, batch length: 11

[2020-01-28 17:04:32.064816][__main__.TRPOAgent.log][training]: policy_gradient: [-5.64350075e-03 -6.06929642e-02  9.20046713e-03  9.88637427e-02
 -6.10744054e-04  0.00000000e+00  7.41361411e-02 -1.54203650e-02
  5.97257718e-02  4.25655336e-02  0.00000000e+00  4.66135247e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.17228331e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.21895754e-01
  0.00000000e+00  1.47943281e-01  0.00000000e+00  3.09085139e-02
  0.00000000e+00  0.00000000e+00 -1.15945353e-02  0.00000000e+00
 -1.20573573e-02  0.00000000e+00  3.37972606e-02  0.00000000e+00
  1.80537019e-02  2.48746924e-03  4.36528797e-03  3.11106590e-03
  0.00000000e+00 -7.51925838e-03  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  5.28996447e-03  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -4.87853107e-02  0.00000000e+00  1.08130043e-02
  0.00000000e+00  2.25906773e-03  0.00000000e+00  0.00000000e+00
  1.87032213e-03  0.00000000e+00 -9.42884599e-05  0.00000000e+00
  8.23034026e-03  0.00000000e+00  0.00000000e+00  5.34803782e-02
 -5.34803782e-02  5.19280837e-02 -5.19280837e-02  3.48342069e-02
 -3.48342069e-02  1.75134984e-02 -1.75134984e-02  0.00000000e+00
  0.00000000e+00  5.72530661e-02 -5.72530661e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  3.47144600e-02 -3.47144600e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  3.08808278e-02 -3.08808278e-02  0.00000000e+00
  0.00000000e+00  8.35310093e-02 -8.35310093e-02  0.00000000e+00
  0.00000000e+00  1.52138238e-02 -1.52138238e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.06201202e-02
 -5.06201202e-02  0.00000000e+00  0.00000000e+00  1.60833539e-02
 -1.60833539e-02  0.00000000e+00  0.00000000e+00  3.54388959e-02
 -3.54388959e-02 -2.40922381e-02  2.40922381e-02]

[2020-01-28 17:04:32.065485][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:32.134017][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 0.00604779  0.05317498  0.01061309 -0.08922889 -0.41108745  0.
  0.92682362 -0.17350871 -0.23973323 -0.17085376  0.          0.52449134
  0.          0.          0.          0.          0.          0.
  0.          0.27157108  0.          0.          0.         -0.50533124
  0.         -0.59382941  0.         -0.12406366  0.          0.
 -0.1304608   0.         -0.13566838  0.          0.42252129  0.
  1.64820485  0.08711235 -0.70178158 -0.5001477   0.         -0.26332784
  0.          0.          0.          0.          0.          0.
  0.          0.482945    0.          0.          0.         -0.16787496
  0.         -1.73834287  0.         -0.36317699  0.          0.
  0.06549958  0.         -0.09323323  0.          0.75138533  0.
  0.          0.16577315 -0.16577315  0.51924366 -0.51924366  0.09890913
 -0.09890913  0.09790453 -0.09790453  0.          0.          0.38805425
 -0.38805425  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.25070351 -0.25070351  0.
  0.          0.          0.          0.          0.          0.17083361
 -0.17083361  0.          0.          0.25532993 -0.25532993  0.
  0.          0.06173263 -0.06173263  0.          0.          0.
  0.          0.5287563  -0.5287563   0.          0.          0.17920926
 -0.17920926  0.          0.          0.20889341 -0.20889341 -0.84372119
  0.84372119]

[2020-01-28 17:04:32.176140][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.005316596525553941, New policy loss value: -0.0302183257296483

[2020-01-28 17:04:32.217994][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0.9124360368057917

[2020-01-28 17:04:32.218393][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:32.220654][__main__.TRPOAgent.log][batch_info]: Batch #7, batch length: 13

[2020-01-28 17:04:32.234009][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.00403981  0.07225725 -0.00370634 -0.1122742  -0.05691415  0.
 -0.07075249 -0.02260132 -0.0081963   0.          0.         -0.06489978
  0.          0.          0.          0.          0.          0.
  0.         -0.03448653  0.          0.          0.          0.
  0.          0.0279307   0.          0.00583066  0.          0.
 -0.02640794  0.         -0.00230078  0.         -0.04132732  0.
  0.10842248  0.03463469 -0.00644219  0.          0.          0.09945367
  0.          0.          0.          0.          0.          0.
  0.          0.05284782  0.          0.          0.          0.
  0.          0.01096657  0.          0.00228155  0.          0.
  0.04046803  0.         -0.00195494  0.          0.06333079  0.
  0.         -0.0258308   0.0258308  -0.01322654  0.01322654  0.00130207
 -0.00130207  0.          0.          0.          0.         -0.00321195
  0.00321195  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.         -0.02551507  0.02551507  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.0029244  -0.0029244   0.
  0.          0.00024197 -0.00024197  0.          0.          0.
  0.         -0.02189322  0.02189322  0.          0.         -0.00597065
  0.00597065  0.          0.         -0.02101227  0.02101227  0.18899636
 -0.18899636]

[2020-01-28 17:04:32.234518][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:32.304253][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.06484625  0.37847884  0.16258754 -0.50572499 -1.30352767  0.
 -0.75073003 -0.23981464  2.49341854  0.          0.         -0.68862906
  0.          0.          0.          0.          0.          0.
  0.         -0.36592444  0.          0.          0.          0.
  0.          1.36388183  0.          0.7246243   0.          0.
 -0.28020531  0.         -0.01796383  0.         -0.43850978  0.
  0.84617105  0.27030252  1.24376766  0.          0.          0.77617506
  0.          0.          0.          0.          0.          0.
  0.          0.4124448   0.          0.          0.          0.
  0.          0.39055598  0.          0.28354692  0.          0.
  0.31582812  0.         -0.06946496  0.          0.49425795  0.
  0.         -0.42484962  0.42484962 -0.21333456  0.21333456  0.11439272
 -0.11439272  0.          0.          0.          0.         -0.23279669
  0.23279669  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.         -0.30844473  0.30844473  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.24559673 -0.24559673  0.
  0.          0.03007102 -0.03007102  0.          0.          0.
  0.         -0.27968977  0.27968977  0.          0.          0.03478852
 -0.03478852  0.          0.         -0.29080058  0.29080058  1.47500112
 -1.47500112]

[2020-01-28 17:04:32.335205][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.013017035848595497, New policy loss value: -0.1680159009471495

[2020-01-28 17:04:32.374836][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 1.2776849621351665

[2020-01-28 17:04:32.375307][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:32.379006][__main__.TRPOAgent.log][batch_info]: Batch #8, batch length: 10

[2020-01-28 17:04:32.388989][__main__.TRPOAgent.log][training]: policy_gradient: [-0.02261527 -0.2005788   0.02668177  0.32898388  0.17659213  0.
  0.0827164   0.02177641  0.1002304   0.          0.          0.08526733
  0.          0.          0.          0.          0.          0.
  0.          0.03425     0.          0.          0.          0.
  0.          0.10256274  0.          0.05177649  0.          0.
  0.02362274  0.          0.00573721  0.          0.04576287  0.
 -0.00824429 -0.00217044  0.0911851   0.          0.         -0.00849854
  0.          0.          0.          0.          0.          0.
  0.         -0.00341368  0.          0.          0.          0.
  0.          0.06418307  0.          0.04896632  0.          0.
 -0.00235446  0.          0.00542583  0.         -0.00456116  0.
  0.          0.09127043 -0.09127043  0.04940591 -0.04940591  0.08881305
 -0.08881305  0.          0.          0.          0.          0.08318208
 -0.08318208  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.04602433 -0.04602433  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.01476029 -0.01476029  0.
  0.          0.01382049 -0.01382049  0.          0.          0.
  0.          0.0482694  -0.0482694   0.          0.          0.00613121
 -0.00613121  0.          0.          0.05207092 -0.05207092 -0.01878979
  0.01878979]

[2020-01-28 17:04:32.389510][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:32.461962][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.53197175 -0.16345939  0.84737388  0.50160484 -0.00769589  0.
  0.50314536  0.13246084  1.02278942  0.          0.          0.51866237
  0.          0.          0.          0.          0.          0.
  0.          0.20833492  0.          0.          0.          0.
  0.         -1.25882511  0.          0.51066554  0.          0.
  0.14369162  0.          0.0565855   0.          0.27836525  0.
 -0.53945986 -0.14202137  3.19338189  0.          0.         -0.55609653
  0.          0.          0.          0.          0.          0.
  0.         -0.22337167  0.          0.          0.          0.
  0.         -0.09387602  0.          2.1258769   0.          0.
 -0.15406281  0.          0.23556275  0.         -0.29845633  0.
  0.          0.08833262 -0.08833262  0.09918448 -0.09918448  0.27287905
 -0.27287905  0.          0.          0.          0.         -0.04929188
  0.04929188  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.12762687 -0.12762687  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.         -0.60922244  0.60922244  0.
  0.         -0.68314369  0.68314369  0.          0.          0.
  0.          0.13804691 -0.13804691  0.          0.         -0.17826911
  0.17826911  0.          0.          0.08655939 -0.08655939 -1.22949769
  1.22949769]

[2020-01-28 17:04:32.489421][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.007526845560380521, New policy loss value: -0.09797463794176493

[2020-01-28 17:04:32.530518][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 1.2272921323776245

[2020-01-28 17:04:32.530927][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:32.533445][__main__.TRPOAgent.log][batch_info]: Batch #9, batch length: 11

[2020-01-28 17:04:32.543490][__main__.TRPOAgent.log][training]: policy_gradient: [-1.47432905e-02 -1.31022401e-01  1.30486596e-02  2.15411837e-01
  1.94058624e-01  0.00000000e+00  4.97873976e-02  1.61114408e-02
  6.52189459e-02  0.00000000e+00  0.00000000e+00  4.57699841e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.42176478e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  4.39191656e-02  0.00000000e+00  7.73895205e-04
  0.00000000e+00  0.00000000e+00  1.86823251e-02  0.00000000e+00
 -3.97245296e-03  0.00000000e+00  2.90360555e-02  0.00000000e+00
 -8.23709876e-03 -2.66556469e-03 -1.07901783e-02  0.00000000e+00
  0.00000000e+00 -7.57243595e-03  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -4.00669981e-03  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.90604959e-02
  0.00000000e+00 -1.28037446e-04  0.00000000e+00  0.00000000e+00
 -3.09090581e-03  0.00000000e+00  6.57224296e-04  0.00000000e+00
 -4.80388348e-03  0.00000000e+00  0.00000000e+00  5.98936727e-02
 -5.98936727e-02  2.94824854e-02 -2.94824854e-02  7.43836939e-02
 -7.43836939e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  5.51781447e-02 -5.51781447e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.96621767e-02 -2.96621767e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  3.77932738e-03 -3.77932738e-03  0.00000000e+00
  0.00000000e+00  2.59741416e-02 -2.59741416e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.93928679e-02
 -2.93928679e-02  0.00000000e+00  0.00000000e+00  8.12984331e-03
 -8.12984331e-03  0.00000000e+00  0.00000000e+00  3.41928403e-02
 -3.41928403e-02 -1.74555923e-02  1.74555923e-02]

[2020-01-28 17:04:32.543933][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:32.594474][__main__.TRPOAgent.log][training]: gradient_step_direction: [-1.09322699e-01 -5.21186622e-01  7.70149720e-03  9.12603298e-01
  2.96699313e+00  0.00000000e+00 -1.01763267e-01 -3.29310719e-02
 -1.33304669e-01  0.00000000e+00  0.00000000e+00 -9.35518274e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.94998272e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -4.45519916e-01  0.00000000e+00 -1.58175615e-03
  0.00000000e+00  0.00000000e+00 -3.81858593e-02  0.00000000e+00
  8.11952521e-03  0.00000000e+00 -5.93484366e-02  0.00000000e+00
 -2.76260015e-01 -8.93990657e-02 -3.61886497e-01  0.00000000e+00
  0.00000000e+00 -2.53968213e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.34378741e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.46385747e-01
  0.00000000e+00 -4.29418110e-03  0.00000000e+00  0.00000000e+00
 -1.03664374e-01  0.00000000e+00  2.20423236e-02  0.00000000e+00
 -1.61115092e-01  0.00000000e+00  0.00000000e+00 -3.19605384e-01
  3.19605384e-01 -1.55858267e-01  1.55858267e-01 -4.34252028e-01
  4.34252028e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -3.57277801e-01  3.57277801e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.19454493e-01  1.19454493e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.44075819e-03 -2.44075819e-03  0.00000000e+00
  0.00000000e+00 -2.19029432e-01  2.19029432e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.28778024e-01
  1.28778024e-01  0.00000000e+00  0.00000000e+00 -2.02665131e-02
  2.02665131e-02  0.00000000e+00  0.00000000e+00 -1.63327999e-01
  1.63327999e-01 -5.85434557e-01  5.85434557e-01]

[2020-01-28 17:04:32.627711][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.0071403476624894964, New policy loss value: -0.02971898358973886

[2020-01-28 17:04:32.665899][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0.8667597092770104

[2020-01-28 17:04:32.666475][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:34.211817][__main__.TRPOAgent.log][learning]: Episode #1

[2020-01-28 17:04:34.212296][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:04:34.230700][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:04:34.231573][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:04:34.231705][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:04:34.235588][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:04:34.273601][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 10

[2020-01-28 17:04:34.277367][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 11

[2020-01-28 17:04:34.278225][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:04:34.279017][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:04:34.278922][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:04:34.280225][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:04:34.320914][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 12

[2020-01-28 17:04:34.320799][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 10

[2020-01-28 17:04:34.322397][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:04:34.322967][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:04:34.323034][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:04:34.327565][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:04:34.363490][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 11

[2020-01-28 17:04:34.377472][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 15

[2020-01-28 17:04:34.378151][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:04:34.378738][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:04:34.378796][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:04:34.382591][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:04:34.418059][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 10

[2020-01-28 17:04:34.420788][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 10

[2020-01-28 17:04:34.421390][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:04:34.421940][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:04:34.421999][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:04:34.425823][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:04:34.462852][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 10

[2020-01-28 17:04:34.471289][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 12

[2020-01-28 17:04:34.471964][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:04:34.473216][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 111, Batch size: 1000, Number of batches: 10

[2020-01-28 17:04:34.473542][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:04:34.473842][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 10

[2020-01-28 17:04:34.486511][__main__.TRPOAgent.log][training]: policy_gradient: [-1.09041261e-03  1.13874026e-03  3.24674397e-04 -5.13795361e-04
  2.44684666e-02  0.00000000e+00  9.05701463e-04  2.31243676e-04
  1.16803927e-03  0.00000000e+00  0.00000000e+00  7.57764009e-04
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  4.83025392e-04
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.38413879e-04
  0.00000000e+00  0.00000000e+00  3.29420024e-04  0.00000000e+00
 -1.26248326e-04  0.00000000e+00  5.55413150e-04  0.00000000e+00
  5.97220679e-04  1.52482370e-04  7.70206555e-04  0.00000000e+00
  0.00000000e+00  4.99670536e-04  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  3.18507549e-04  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.57210411e-04  0.00000000e+00  0.00000000e+00
  2.17219976e-04  0.00000000e+00 -8.32483046e-05  0.00000000e+00
  3.66240127e-04  0.00000000e+00  0.00000000e+00  2.08740417e-03
 -2.08740417e-03  1.05046410e-03 -1.05046410e-03  2.71575302e-03
 -2.71575302e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.15021110e-03 -2.15021110e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  8.95093449e-04 -8.95093449e-04  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.26558392e-03 -1.26558392e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  9.42415456e-04
 -9.42415456e-04  0.00000000e+00  0.00000000e+00  2.35985811e-04
 -2.35985811e-04  0.00000000e+00  0.00000000e+00  1.12055831e-03
 -1.12055831e-03  1.79238121e-03 -1.79238121e-03]

[2020-01-28 17:04:34.486975][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:34.515329][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.10052146  0.10497662  0.02993064 -0.04736506  2.25566539  0.
  0.08349356  0.02131757  0.1076776   0.          0.          0.06985571
  0.          0.          0.          0.          0.          0.
  0.          0.04452848  0.          0.          0.          0.
  0.          0.          0.         -0.02197857  0.          0.
  0.03036812  0.         -0.01163841  0.          0.05120167  0.
 -0.06022412 -0.01537642 -0.07766813  0.          0.         -0.0503871
  0.          0.          0.          0.          0.          0.
  0.         -0.03211851  0.          0.          0.          0.
  0.          0.          0.          0.0158532   0.          0.
 -0.0219046   0.          0.00839481  0.         -0.03693189  0.
  0.          0.10333063 -0.10333063  0.05029909 -0.05029909  0.12031964
 -0.12031964  0.          0.          0.          0.          0.08109371
 -0.08109371  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.05983504 -0.05983504  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.02455908 -0.02455908  0.          0.          0.
  0.          0.05639176 -0.05639176  0.          0.          0.01806723
 -0.01806723  0.          0.          0.06334641 -0.06334641 -0.18074491
  0.18074491]

[2020-01-28 17:04:34.558811][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.008403178441222176, New policy loss value: -0.04809964274074563

[2020-01-28 17:04:34.599314][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 12.716854402422905

[2020-01-28 17:04:34.599788][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:34.602250][__main__.TRPOAgent.log][batch_info]: Batch #1, batch length: 11

[2020-01-28 17:04:34.614314][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00454508  0.02006112  0.00109847 -0.0244967   0.10843933  0.
  0.02550291  0.00759621  0.0323029   0.          0.          0.02109419
  0.          0.          0.          0.          0.          0.
  0.          0.01381553  0.          0.          0.          0.
  0.          0.          0.         -0.00436561  0.          0.
  0.01012898  0.         -0.00208212  0.          0.01563851  0.
 -0.00750829 -0.0022364  -0.00951027  0.          0.         -0.00621033
  0.          0.          0.          0.          0.          0.
  0.         -0.00406742  0.          0.          0.          0.
  0.          0.          0.          0.00128528  0.          0.
 -0.00298207  0.          0.000613    0.         -0.00460412  0.
  0.          0.03492556 -0.03492556  0.01671382 -0.01671382  0.04298162
 -0.04298162  0.          0.          0.          0.          0.03116705
 -0.03116705  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.0178903  -0.0178903   0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.01261888 -0.01261888  0.          0.          0.
  0.          0.0172442  -0.0172442   0.          0.          0.00446865
 -0.00446865  0.          0.          0.02028072 -0.02028072 -0.01839271
  0.01839271]

[2020-01-28 17:04:34.615105][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:34.645030][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.05962129  0.24582576  0.01553827 -0.2968704   1.39813548  0.
  0.33908653  0.10099917  0.42949913  0.          0.          0.28046826
  0.          0.          0.          0.          0.          0.
  0.          0.18369121  0.          0.          0.          0.
  0.          0.          0.         -0.05804509  0.          0.
  0.13467491  0.         -0.02768387  0.          0.20792957  0.
 -0.31153172 -0.09279179 -0.39459722  0.          0.         -0.25767688
  0.          0.          0.          0.          0.          0.
  0.         -0.16876411  0.          0.          0.          0.
  0.          0.          0.          0.05332824  0.          0.
 -0.12373097  0.          0.02543423  0.         -0.19103282  0.
  0.          0.34215351 -0.34215351  0.15536232 -0.15536232  0.39119047
 -0.39119047  0.          0.          0.          0.          0.24831838
 -0.24831838  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.2099194  -0.2099194   0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.02672904 -0.02672904  0.          0.          0.
  0.          0.18770587 -0.18770587  0.          0.          0.05230751
 -0.05230751  0.          0.          0.21671697 -0.21671697 -0.76314435
  0.76314435]

[2020-01-28 17:04:34.690758][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.005448307457466587, New policy loss value: -0.0611481523467351

[2020-01-28 17:04:34.728128][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 36.230491093613885

[2020-01-28 17:04:34.728550][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:34.731823][__main__.TRPOAgent.log][batch_info]: Batch #2, batch length: 12

[2020-01-28 17:04:34.746086][__main__.TRPOAgent.log][training]: policy_gradient: [-3.90503174e-03 -4.44937857e-03  1.53327275e-03  1.23269700e-02
  8.72366772e-02  0.00000000e+00  4.06676974e-02  1.33782219e-02
  5.05125008e-02  0.00000000e+00  0.00000000e+00  3.28164415e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.26121160e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.94261501e-03
  0.00000000e+00  0.00000000e+00  1.73783164e-02  0.00000000e+00
 -1.42100137e-03  0.00000000e+00  2.51011089e-02  0.00000000e+00
  8.18196726e-04  2.69157539e-04  1.01626513e-03  0.00000000e+00
  0.00000000e+00  6.60236668e-04  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  4.54935009e-04  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -9.94408751e-05  0.00000000e+00  0.00000000e+00
  3.49635768e-04  0.00000000e+00 -2.85892426e-05  0.00000000e+00
  5.05011261e-04  0.00000000e+00  0.00000000e+00  5.44555227e-02
 -5.44555227e-02  2.57536511e-02 -2.57536511e-02  6.86042549e-02
 -6.86042549e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  5.10971369e-02 -5.10971369e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.63335801e-02 -2.63335801e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.22664938e-02 -2.22664938e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.55983130e-02
 -2.55983130e-02  0.00000000e+00  0.00000000e+00  5.72922218e-03
 -5.72922218e-03  0.00000000e+00  0.00000000e+00  3.08769104e-02
 -3.08769104e-02  1.60517471e-03 -1.60517471e-03]

[2020-01-28 17:04:34.746552][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:34.789139][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.0084362  -0.08725915  0.01049775  0.17473349  0.19881703  0.
  0.16024465  0.05271477  0.19903654  0.          0.          0.12930801
  0.          0.          0.          0.          0.          0.
  0.          0.08909948  0.          0.          0.          0.
  0.          0.          0.         -0.01947559  0.          0.
  0.06847652  0.         -0.00559923  0.          0.09890696  0.
 -0.17774301 -0.05847111 -0.2207709   0.          0.         -0.14342817
  0.          0.          0.          0.          0.          0.
  0.         -0.09882894  0.          0.          0.          0.
  0.          0.          0.          0.02160229  0.          0.
 -0.075954    0.          0.00621066  0.         -0.10970738  0.
  0.          0.14730993 -0.14730993  0.06058936 -0.06058936  0.1676761
 -0.1676761   0.          0.          0.          0.          0.10121281
 -0.10121281  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.09351624 -0.09351624  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.         -0.01163434  0.01163434  0.          0.          0.
  0.          0.07892121 -0.07892121  0.          0.          0.01636979
 -0.01636979  0.          0.          0.09548623 -0.09548623 -0.34870422
  0.34870422]

[2020-01-28 17:04:34.836169][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.004153662879187334, New policy loss value: -0.028976131835317238

[2020-01-28 17:04:34.871289][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 39.94012924687316

[2020-01-28 17:04:34.871678][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:34.874499][__main__.TRPOAgent.log][batch_info]: Batch #3, batch length: 10

[2020-01-28 17:04:34.887360][__main__.TRPOAgent.log][training]: policy_gradient: [-0.01053975  0.03716937  0.00297874 -0.0434262   0.24195177  0.
  0.07564092  0.02569179  0.0929324   0.          0.          0.05986062
  0.          0.          0.          0.          0.          0.
  0.          0.04283188  0.          0.          0.          0.
  0.          0.          0.         -0.0087752   0.          0.
  0.03338802  0.         -0.00120859  0.          0.04699163  0.
  0.0555432   0.01886551  0.06824036  0.          0.          0.04395572
  0.          0.          0.          0.          0.          0.
  0.          0.03145149  0.          0.          0.          0.
  0.          0.          0.         -0.00644364  0.          0.
  0.02451686  0.         -0.00088747  0.          0.03450601  0.
  0.          0.10659915 -0.10659915  0.05262935 -0.05262935  0.13893015
 -0.13893015  0.          0.          0.          0.          0.10950901
 -0.10950901  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.04583349 -0.04583349  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.06173051 -0.06173051  0.          0.          0.
  0.          0.04755455 -0.04755455  0.          0.          0.01084998
 -0.01084998  0.          0.          0.05738604 -0.05738604  0.09481992
 -0.09481992]

[2020-01-28 17:04:34.887766][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:34.935308][__main__.TRPOAgent.log][training]: gradient_step_direction: [-0.02309341 -0.06909935  0.00767793  0.12594534  0.49439967  0.
  0.2535811   0.08613001  0.31154962  0.          0.          0.20067872
  0.          0.          0.          0.          0.          0.
  0.          0.143591    0.          0.          0.          0.
  0.          0.          0.         -0.02941828  0.          0.
  0.1119311   0.         -0.0040517   0.          0.15753629  0.
 -0.16777479 -0.05698548 -0.20612803  0.          0.         -0.13277341
  0.          0.          0.          0.          0.          0.
  0.         -0.09500294  0.          0.          0.          0.
  0.          0.          0.          0.0194638   0.          0.
 -0.07405605  0.          0.0026807   0.         -0.10422945  0.
  0.          0.27060371 -0.27060371  0.11596062 -0.11596062  0.3254751
 -0.3254751   0.          0.          0.          0.          0.21906869
 -0.21906869  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.15162838 -0.15162838  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.03443749 -0.03443749  0.          0.          0.
  0.          0.13391913 -0.13391913  0.          0.          0.02484302
 -0.02484302  0.          0.          0.16493623 -0.16493623 -0.28641486
  0.28641486]

[2020-01-28 17:04:34.978991][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.004306439159252492, New policy loss value: -0.055369642466894395

[2020-01-28 17:04:35.014716][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 23.44929808303714

[2020-01-28 17:04:35.015293][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:35.018657][__main__.TRPOAgent.log][batch_info]: Batch #4, batch length: 11

[2020-01-28 17:04:35.033106][__main__.TRPOAgent.log][training]: policy_gradient: [-8.92377020e-03 -2.07601676e-03  1.72377320e-03  1.50026750e-02
  2.23588974e-01  0.00000000e+00  9.52788610e-02  3.33615680e-02
  1.16769069e-01  0.00000000e+00  0.00000000e+00  7.56061319e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.38853313e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -8.31699096e-03
  0.00000000e+00  0.00000000e+00  4.26579037e-02  0.00000000e+00
 -3.09961767e-04  0.00000000e+00  5.90596405e-02  0.00000000e+00
  3.97474274e-02  1.39174260e-02  4.87124852e-02  0.00000000e+00
  0.00000000e+00  3.15405663e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  3.93068470e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -3.46959431e-03  0.00000000e+00  0.00000000e+00
  1.77955730e-02  0.00000000e+00 -1.29306571e-04  0.00000000e+00
  2.46378761e-02  0.00000000e+00  0.00000000e+00  1.15706294e-01
 -1.15706294e-01  5.52098355e-02 -5.52098355e-02  1.48466625e-01
 -1.48466625e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.13528740e-01 -1.13528740e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  5.24587139e-02 -5.24587139e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  5.51474398e-02 -5.51474398e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.25931743e-02
 -5.25931743e-02  0.00000000e+00  0.00000000e+00  1.11243314e-02
 -1.11243314e-02  0.00000000e+00  0.00000000e+00  6.40551184e-02
 -6.40551184e-02  5.98436067e-02 -5.98436067e-02]

[2020-01-28 17:04:35.033863][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:35.097257][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 5.89014716e-01 -2.26751121e-01 -7.80497574e-01  5.34117682e-01
  4.68048261e-01  0.00000000e+00  3.11564540e-01  1.09093259e-01
  3.81838124e-01  0.00000000e+00  0.00000000e+00  2.47234167e-01
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.75742350e-01
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.71967951e-02
  0.00000000e+00  0.00000000e+00  1.39492537e-01  0.00000000e+00
 -1.01358547e-03  0.00000000e+00  1.93126676e-01  0.00000000e+00
 -2.51394803e-01 -8.80249550e-02 -3.08097122e-01  0.00000000e+00
  0.00000000e+00 -1.99488039e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -3.25787503e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.19446407e-02  0.00000000e+00  0.00000000e+00
 -1.12553489e-01  0.00000000e+00  8.17954137e-04  0.00000000e+00
 -1.55829800e-01  0.00000000e+00  0.00000000e+00  3.09878643e-01
 -3.09878643e-01  1.27814837e-01 -1.27814837e-01  3.69345965e-01
 -3.69345965e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.41609096e-01 -2.41609096e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.64954555e-01 -2.64954555e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.47975717e-02 -1.47975717e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.53907810e-01
 -1.53907810e-01  0.00000000e+00  0.00000000e+00  2.51974365e-02
 -2.51974365e-02  0.00000000e+00  0.00000000e+00  1.92053192e-01
 -1.92053192e-01 -3.78501342e-01  3.78501342e-01]

[2020-01-28 17:04:35.135105][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.003637382954046517, New policy loss value: -0.046886529961828044

[2020-01-28 17:04:35.170825][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 24.117233816449616

[2020-01-28 17:04:35.171228][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:35.173559][__main__.TRPOAgent.log][batch_info]: Batch #5, batch length: 15

[2020-01-28 17:04:35.185632][__main__.TRPOAgent.log][training]: policy_gradient: [-0.01143205 -0.02810642  0.00297057  0.05793662  0.28013564  0.
  0.13364253  0.04781243  0.16323612  0.          0.          0.10582267
  0.          0.          0.          0.          0.          0.
  0.          0.09384529  0.          0.          0.          0.
  0.          0.          0.         -0.00945997  0.          0.
  0.06063358  0.          0.00094656  0.          0.08283828  0.
  0.13243635  0.04738091  0.16176284  0.          0.          0.10486757
  0.          0.          0.          0.          0.          0.
  0.          0.06302391  0.          0.          0.          0.
  0.          0.          0.         -0.00937459  0.          0.
  0.06008634  0.          0.00093802  0.          0.08209063  0.
  0.          0.15619186 -0.15619186  0.07785674 -0.07785674  0.20530987
 -0.20530987  0.          0.          0.          0.          0.16396387
 -0.16396387  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.01362792 -0.01362792  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.09697168 -0.09697168  0.          0.          0.
  0.          0.06867997 -0.06867997  0.          0.          0.01566422
 -0.01566422  0.          0.          0.08295802 -0.08295802  0.1750251
 -0.1750251 ]

[2020-01-28 17:04:35.186204][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:35.284199][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 1.27009596e-01 -3.90501923e-01  1.47002004e-01  1.12408370e+00
 -3.04042547e-01  0.00000000e+00 -7.00496794e-02 -2.50612756e-02
 -8.55614238e-02  0.00000000e+00  0.00000000e+00 -5.54678283e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.48791719e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  4.95821455e-03
  0.00000000e+00  0.00000000e+00 -3.17815006e-02  0.00000000e+00
 -4.96168981e-04  0.00000000e+00 -4.34202280e-02  0.00000000e+00
  2.78099331e-01  9.94939229e-02  3.39681319e-01  0.00000000e+00
  0.00000000e+00  2.20208703e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  5.32732755e-03  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.96848138e-02  0.00000000e+00  0.00000000e+00
  1.26173551e-01  0.00000000e+00  1.96976681e-03  0.00000000e+00
  1.72379689e-01  0.00000000e+00  0.00000000e+00 -4.43203020e-02
  4.43203020e-02 -4.67100721e-03  4.67100721e-03 -3.58307684e-02
  3.58307684e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  4.07355618e-03 -4.07355618e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  3.05868189e+00 -3.05868189e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  8.30806304e-02 -8.30806304e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.92565869e-02
  2.92565869e-02  0.00000000e+00  0.00000000e+00  7.87502307e-04
 -7.87502307e-04  0.00000000e+00  0.00000000e+00 -4.02378818e-02
  4.02378818e-02  3.67529923e-01 -3.67529923e-01]

[2020-01-28 17:04:35.323422][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.010500028548082383, New policy loss value: -0.09109013119452107

[2020-01-28 17:04:35.358605][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 41.987120322386424

[2020-01-28 17:04:35.359041][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:35.362093][__main__.TRPOAgent.log][batch_info]: Batch #6, batch length: 10

[2020-01-28 17:04:35.372609][__main__.TRPOAgent.log][training]: policy_gradient: [-0.02746874  0.08015423  0.00795763 -0.08868441  0.62534937  0.
  0.15357819  0.05545447  0.18842052  0.          0.          0.12339352
  0.          0.          0.          0.          0.          0.
  0.          0.22727193  0.          0.          0.          0.
  0.          0.          0.         -0.0072276   0.          0.
  0.06926143  0.          0.00113796  0.          0.09461356  0.
  0.1182889   0.0427121   0.14512513  0.          0.          0.09504008
  0.          0.          0.          0.          0.          0.
  0.          0.20342271  0.          0.          0.          0.
  0.          0.          0.         -0.00556684  0.          0.
  0.0533465   0.          0.00087648  0.          0.0728732   0.
  0.          0.18142558 -0.18142558  0.0882508  -0.0882508   0.23595656
 -0.23595656  0.          0.          0.          0.          0.18460463
 -0.18460463  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.06864714 -0.06864714  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.09943448 -0.09943448  0.          0.          0.
  0.          0.08078708 -0.08078708  0.          0.          0.01737153
 -0.01737153  0.          0.          0.09830229 -0.09830229  0.15838425
 -0.15838425]

[2020-01-28 17:04:35.373016][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:35.420050][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 3.00818699e-03 -5.76566877e-01 -3.62834683e-02  8.78502058e-01
  5.48114379e-01  0.00000000e+00  6.98286927e-01  2.52139496e-01
  8.56707483e-01  0.00000000e+00  0.00000000e+00  5.61043734e-01
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.91127778e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.28623702e-02
  0.00000000e+00  0.00000000e+00  3.14916796e-01  0.00000000e+00
  5.17406461e-03  0.00000000e+00  4.30187491e-01  0.00000000e+00
 -2.68273459e-01 -9.68689133e-02 -3.29136739e-01  0.00000000e+00
  0.00000000e+00 -2.15546237e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -2.51091533e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.26255098e-02  0.00000000e+00  0.00000000e+00
 -1.20987230e-01  0.00000000e+00 -1.98775331e-03  0.00000000e+00
 -1.65272886e-01  0.00000000e+00  0.00000000e+00  7.03396309e-01
 -7.03396309e-01  3.04427904e-01 -3.04427904e-01  8.63514347e-01
 -8.63514347e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  6.01468809e-01 -6.01468809e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.07237862e+00 -1.07237862e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.39757365e-01 -1.39757365e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.36384671e-01
 -3.36384671e-01  0.00000000e+00  0.00000000e+00  5.76024783e-02
 -5.76024783e-02  0.00000000e+00  0.00000000e+00  4.18715326e-01
 -4.18715326e-01 -3.59208902e-01  3.59208902e-01]

[2020-01-28 17:04:35.460278][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.003975142251126095, New policy loss value: -0.08384980171749401

[2020-01-28 17:04:35.496450][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 12.150802176631988

[2020-01-28 17:04:35.496857][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:35.499291][__main__.TRPOAgent.log][batch_info]: Batch #7, batch length: 10

[2020-01-28 17:04:35.508379][__main__.TRPOAgent.log][training]: policy_gradient: [-0.03427336  0.09354787  0.00992339 -0.10111417  0.77976688  0.
  0.20154125  0.07469677  0.24728551  0.          0.          0.16331485
  0.          0.          0.          0.          0.          0.
  0.          0.2324559   0.          0.          0.          0.
  0.          0.          0.         -0.0028928   0.          0.
  0.09162285  0.          0.00349126  0.          0.12360422  0.
  0.17016398  0.06306748  0.20878646  0.          0.          0.13788892
  0.          0.          0.          0.          0.          0.
  0.          0.17754966  0.          0.          0.          0.
  0.          0.          0.         -0.00244243  0.          0.
  0.0773584   0.          0.00294772  0.          0.1043607   0.
  0.          0.21734467 -0.21734467  0.10520117 -0.10520117  0.28283272
 -0.28283272  0.          0.          0.          0.          0.22106227
 -0.22106227  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.04404138 -0.04404138  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.11771379 -0.11771379  0.          0.          0.
  0.          0.09646065 -0.09646065  0.          0.          0.02017265
 -0.02017265  0.          0.          0.11782845 -0.11782845  0.19751841
 -0.19751841]

[2020-01-28 17:04:35.508862][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:35.560450][__main__.TRPOAgent.log][training]: gradient_step_direction: [-3.63558523e-02 -4.91073318e-01 -2.04965556e-03  7.74710520e-01
  1.01003869e+00  0.00000000e+00  1.44351267e-01  5.35005717e-02
  1.77114984e-01  0.00000000e+00  0.00000000e+00  1.16972106e-01
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.87298492e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.07194717e-03
  0.00000000e+00  0.00000000e+00  6.56236557e-02  0.00000000e+00
  2.50056604e-03  0.00000000e+00  8.85298963e-02  0.00000000e+00
 -8.37303007e-02 -3.10327433e-02 -1.02734745e-01  0.00000000e+00
  0.00000000e+00 -6.78491241e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.19438397e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.20190101e-03  0.00000000e+00  0.00000000e+00
 -3.80646978e-02  0.00000000e+00 -1.45042014e-03  0.00000000e+00
 -5.13513736e-02  0.00000000e+00  0.00000000e+00  1.34021738e-01
 -1.34021738e-01  5.58227671e-02 -5.58227671e-02  1.62691676e-01
 -1.62691676e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.09924904e-01 -1.09924904e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  5.44319063e-01 -5.44319063e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.49999666e-02 -1.49999666e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  6.46015394e-02
 -6.46015394e-02  0.00000000e+00  0.00000000e+00  9.75914435e-03
 -9.75914435e-03  0.00000000e+00  0.00000000e+00  8.13628073e-02
 -8.13628073e-02 -9.71907039e-02  9.71907039e-02]

[2020-01-28 17:04:35.598387][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.005898342283276486, New policy loss value: -0.11596684922589824

[2020-01-28 17:04:35.632551][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 10.031072245538235

[2020-01-28 17:04:35.632958][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:35.635277][__main__.TRPOAgent.log][batch_info]: Batch #8, batch length: 10

[2020-01-28 17:04:35.644560][__main__.TRPOAgent.log][training]: policy_gradient: [-0.04507062  0.13632352  0.01309439 -0.15263783  1.02580792  0.
  0.23620343  0.08774446  0.28975788  0.          0.          0.19144586
  0.          0.          0.          0.          0.          0.
  0.          0.36197346  0.          0.          0.          0.
  0.          0.          0.         -0.00283745  0.          0.
  0.10750067  0.          0.00433468  0.          0.14483518  0.
  0.18128674  0.0673441   0.22238992  0.          0.          0.14693519
  0.          0.          0.          0.          0.          0.
  0.          0.30678022  0.          0.          0.          0.
  0.          0.          0.         -0.00217775  0.          0.
  0.08250704  0.          0.00332688  0.          0.11116137  0.
  0.          0.24943647 -0.24943647  0.11980262 -0.11980262  0.32348252
 -0.32348252  0.          0.          0.          0.          0.25114705
 -0.25114705  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.12553348 -0.12553348  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.12938017 -0.12938017  0.          0.          0.
  0.          0.11116106 -0.11116106  0.          0.          0.02282037
 -0.02282037  0.          0.          0.13607337 -0.13607337  0.2065286
 -0.2065286 ]

[2020-01-28 17:04:35.644985][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:35.695657][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 7.95341876e-02 -2.38964574e+00 -1.80434647e-01  3.57816691e+00
  9.63880645e-01  0.00000000e+00  2.50686030e+00  9.31244336e-01
  3.07524126e+00  0.00000000e+00  0.00000000e+00  2.03184191e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -7.17640112e-01
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.01143333e-02
  0.00000000e+00  0.00000000e+00  1.14091975e+00  0.00000000e+00
  4.60045822e-02  0.00000000e+00  1.53715615e+00  0.00000000e+00
 -5.73757820e-01 -2.13138506e-01 -7.03846031e-01  0.00000000e+00
  0.00000000e+00 -4.65037850e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.05832291e+01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  6.89281515e-03  0.00000000e+00  0.00000000e+00
 -2.61128057e-01  0.00000000e+00 -1.05292033e-02  0.00000000e+00
 -3.51816755e-01  0.00000000e+00  0.00000000e+00  2.40365122e+00
 -2.40365122e+00  1.04403068e+00 -1.04403068e+00  2.97537795e+00
 -2.97537795e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.10000724e+00 -2.10000724e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  3.87196681e+00 -3.87196681e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  5.46523126e-01 -5.46523126e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.13284285e+00
 -1.13284285e+00  0.00000000e+00  0.00000000e+00  1.86536072e-01
 -1.86536072e-01  0.00000000e+00  0.00000000e+00  1.41690613e+00
 -1.41690613e+00 -6.53648298e-01  6.53648298e-01]

[2020-01-28 17:04:35.735681][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.0047558061651203675, New policy loss value: -0.13583713081397836

[2020-01-28 17:04:35.768898][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 8.670481378212571

[2020-01-28 17:04:35.769322][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:35.772025][__main__.TRPOAgent.log][batch_info]: Batch #9, batch length: 12

[2020-01-28 17:04:35.784262][__main__.TRPOAgent.log][training]: policy_gradient: [-0.05809049 -0.00595005  0.02020987  0.08118234  1.29242549  0.
  0.39258752  0.15038194  0.4824032   0.          0.          0.3227621
  0.          0.          0.          0.          0.          0.
  0.          0.54893306  0.          0.          0.          0.
  0.          0.          0.          0.01258539  0.          0.
  0.17984358  0.          0.01148711  0.          0.2390139   0.
  0.30690221  0.1175599   0.37711491  0.          0.          0.25231673
  0.          0.          0.          0.          0.          0.
  0.          0.31299238  0.          0.          0.          0.
  0.          0.          0.          0.00983853  0.          0.
  0.1405913   0.          0.00897996  0.          0.1574244   0.
  0.          0.36964864 -0.36964864  0.17437401 -0.17437401  0.47746902
 -0.47746902  0.          0.          0.          0.          0.36669217
 -0.36669217  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.11530426 -0.11530426  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.17658875 -0.17658875  0.          0.          0.
  0.          0.16491394 -0.16491394  0.          0.          0.03161599
 -0.03161599  0.          0.          0.20377343 -0.20377343  0.2852674
 -0.2852674 ]

[2020-01-28 17:04:35.784693][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:35.857696][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 2.06540766e+00 -4.31702859e+00 -2.16019155e+00  1.22875672e+01
  6.84544150e+00  0.00000000e+00 -8.19381915e-01 -3.13867116e-01
 -1.00683919e+00  0.00000000e+00  0.00000000e+00 -6.73647372e-01
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.90823176e+01
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.62682738e-02
  0.00000000e+00  0.00000000e+00 -3.75357246e-01  0.00000000e+00
 -2.39752462e-02  0.00000000e+00 -4.98853436e-01  0.00000000e+00
  3.10991690e-01  1.19126490e-01  3.82140039e-01  0.00000000e+00
  0.00000000e+00  2.55679039e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -4.33348759e+01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  9.97012756e-03  0.00000000e+00  0.00000000e+00
  1.42464681e-01  0.00000000e+00  9.09968983e-03  0.00000000e+00
  7.39094085e+00  0.00000000e+00  0.00000000e+00 -7.16679478e-01
  7.16679478e-01 -3.01011214e-01  3.01011214e-01 -8.79897635e-01
  8.79897635e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -6.06525880e-01  6.06525880e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  4.71119169e+01 -4.71119169e+01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.11386473e-01  1.11386473e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.39126680e-01
  3.39126680e-01  0.00000000e+00  0.00000000e+00 -4.90701342e-02
  4.90701342e-02  0.00000000e+00  0.00000000e+00 -4.83228451e-01
  4.83228451e-01  2.89067253e-01 -2.89067253e-01]

[2020-01-28 17:04:35.887997][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.014456314976173142, New policy loss value: -0.20249937992583425

[2020-01-28 17:04:35.926365][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 12.690955741330981

[2020-01-28 17:04:35.926989][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:36.617904][__main__.TRPOAgent.log][learning]: Episode #2

[2020-01-28 17:04:36.618859][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 50

[2020-01-28 17:04:36.639145][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:04:36.639713][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:04:36.639839][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:04:36.641950][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:04:36.681560][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 13

[2020-01-28 17:04:36.681946][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 12

[2020-01-28 17:04:36.682741][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:04:36.683255][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:04:36.683181][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:04:36.684099][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:04:36.717537][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 11

[2020-01-28 17:04:36.717152][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 10

[2020-01-28 17:04:36.718660][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:04:36.719357][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:04:36.719431][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:04:36.724356][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:04:36.769439][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 9

[2020-01-28 17:04:36.768863][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 11

[2020-01-28 17:04:36.770455][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:04:36.771200][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:04:36.771281][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:04:36.774506][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:04:36.798949][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 9

[2020-01-28 17:04:36.801799][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 9

[2020-01-28 17:04:36.802244][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:04:36.802767][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:04:36.802709][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:04:36.803697][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:04:36.834479][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 12

[2020-01-28 17:04:36.835004][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 10

[2020-01-28 17:04:36.835896][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:04:36.837096][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 106, Batch size: 1000, Number of batches: 10

[2020-01-28 17:04:36.837441][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:04:36.837857][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 13

[2020-01-28 17:04:36.847658][__main__.TRPOAgent.log][training]: policy_gradient: [-7.41183392e-02  6.05387803e-02  2.20815747e-02 -1.00538650e-02
  1.66138373e+00  0.00000000e+00  1.76269857e-01  6.72155857e-02
  2.16605213e-01  2.52710999e-14  0.00000000e+00  1.44719086e-01
  0.00000000e+00  0.00000000e+00 -2.05798453e-26  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  9.26862745e-01
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.10955109e-14
  0.00000000e+00  7.39338569e-14  0.00000000e+00  4.63209297e-03
  0.00000000e+00  0.00000000e+00  8.06242403e-02  0.00000000e+00
  4.83388323e-03  0.00000000e+00  1.06775653e-01  0.00000000e+00
  9.88811143e-02  3.77055505e-02  1.21507813e-01  8.03994551e-15
  0.00000000e+00  8.11822546e-02  0.00000000e+00  0.00000000e+00
 -4.35497308e-27  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  5.75503426e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -9.89296907e-15  0.00000000e+00  2.35218955e-14
  0.00000000e+00  2.59843924e-03  0.00000000e+00  0.00000000e+00
  4.52273283e-02  0.00000000e+00  2.71163639e-03  0.00000000e+00
  5.98973397e-02  0.00000000e+00  0.00000000e+00  1.67682826e-01
 -1.67682826e-01  7.78433127e-02 -7.78433127e-02  2.14864849e-01
 -2.14864849e-01  5.64278267e-16 -5.64279705e-16  0.00000000e+00
  0.00000000e+00  1.62502038e-01 -1.62502038e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -7.13174536e-29  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.36157529e-01 -1.36157529e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.51416837e-15 -2.51417455e-15  0.00000000e+00
  0.00000000e+00  4.88464576e-15 -4.88465743e-15  0.00000000e+00
  0.00000000e+00  7.18718041e-02 -7.18718041e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  7.55952244e-02
 -7.55952244e-02  0.00000000e+00  0.00000000e+00  1.40274471e-02
 -1.40274471e-02  0.00000000e+00  0.00000000e+00  1.16873491e-01
 -1.16873491e-01  9.62162829e-02 -9.62162829e-02]

[2020-01-28 17:04:36.848104][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:36.876494][__main__.TRPOAgent.log][training]: gradient_step_direction: [-1.55232396e+01 -8.62111658e+01  6.19779878e+00  1.39483302e+02
  2.97927044e+02  0.00000000e+00 -2.76583091e+01 -1.05466967e+01
 -3.39872599e+01  1.36052708e-07  0.00000000e+00 -2.27076500e+01
  0.00000000e+00  0.00000000e+00 -1.95018313e-17  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  4.28858482e+02
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.67432109e-07
  0.00000000e+00  3.98100922e-07  0.00000000e+00 -7.26667223e-01
  0.00000000e+00  0.00000000e+00 -1.26506690e+01  0.00000000e+00
 -7.58465961e-01  0.00000000e+00 -1.67539722e+01  0.00000000e+00
 -8.00335154e+01 -3.05185280e+01 -9.83473523e+01  4.36148692e-08
  0.00000000e+00 -6.57081722e+01  0.00000000e+00  0.00000000e+00
 -4.15392758e-18  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.67386470e+02  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -5.36742051e-08  0.00000000e+00  1.27620364e-07
  0.00000000e+00 -2.10305853e+00  0.00000000e+00  0.00000000e+00
 -3.66066122e+01  0.00000000e+00 -2.19476642e+00  0.00000000e+00
 -4.84803369e+01  0.00000000e+00  0.00000000e+00 -3.08581483e+01
  3.08581483e+01 -1.69322942e+01  1.69322942e+01 -4.27992542e+01
  4.27992542e+01  2.81375235e-09 -2.81466136e-09  0.00000000e+00
  0.00000000e+00 -3.73094266e+01  3.73094266e+01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -6.19018873e-20  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  6.24409711e+01 -6.24409711e+01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.28784638e-08 -1.28824983e-08  0.00000000e+00
  0.00000000e+00  2.55067604e-08 -2.55145767e-08  0.00000000e+00
  0.00000000e+00 -2.95530078e+01  2.95530078e+01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.25218106e+01
  1.25218106e+01  0.00000000e+00  0.00000000e+00 -3.42096915e+00
  3.42096915e+00  0.00000000e+00  0.00000000e+00 -3.36148758e+01
  3.36148758e+01 -7.78767230e+01  7.78767230e+01]

[2020-01-28 17:04:36.926622][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 3, New mean kl div: 0.013958222625610722, New policy loss value: -0.1367489876173527

[2020-01-28 17:04:36.955643][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 15.746011305313845

[2020-01-28 17:04:36.956224][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:36.959442][__main__.TRPOAgent.log][batch_info]: Batch #1, batch length: 12

[2020-01-28 17:04:36.968677][__main__.TRPOAgent.log][training]: policy_gradient: [-7.77956119e-02  6.51174806e-02  2.31756894e-02 -1.28748403e-02
  1.74398621e+00  0.00000000e+00  1.96853963e-01  7.36017811e-02
  2.40517401e-01  5.56379897e-22  0.00000000e+00  1.58227287e-01
  0.00000000e+00  0.00000000e+00 -2.83593102e-32  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  9.89421020e-01
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.28136066e-20
  0.00000000e+00 -4.54736610e-14  0.00000000e+00 -2.96751197e-03
  0.00000000e+00  0.00000000e+00  9.04902416e-02  0.00000000e+00
  4.66913089e-03  0.00000000e+00  1.15018045e-01  0.00000000e+00
  1.06173816e-01  3.96973566e-02  1.29723832e-01  1.62088916e-22
  0.00000000e+00  8.53403946e-02  0.00000000e+00  0.00000000e+00
 -5.61770250e-33  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  5.33647400e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  3.73295947e-21  0.00000000e+00 -1.72652333e-14
  0.00000000e+00 -1.60053710e-03  0.00000000e+00  0.00000000e+00
  4.88062020e-02  0.00000000e+00  2.51831071e-03  0.00000000e+00
  6.20353513e-02  0.00000000e+00  0.00000000e+00  1.85235392e-01
 -1.85235392e-01  8.66437381e-02 -8.66437381e-02  2.37658966e-01
 -2.37658966e-01 -5.24679209e-72  9.77626246e-22  0.00000000e+00
  0.00000000e+00  1.80487723e-01 -1.80487723e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -5.69745827e-73
 -1.78724101e-34  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.64027313e-01 -2.64027313e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.66582457e-71  3.68639418e-21  0.00000000e+00
  0.00000000e+00 -7.11870286e-16  7.12031859e-16  0.00000000e+00
  0.00000000e+00  8.23061626e-02 -8.23061626e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  8.35381465e-02
 -8.35381465e-02  0.00000000e+00  0.00000000e+00  1.60019728e-02
 -1.60019728e-02  0.00000000e+00  0.00000000e+00  1.29188844e-01
 -1.29188844e-01  1.07899271e-01 -1.07899271e-01]

[2020-01-28 17:04:36.969103][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:37.000530][__main__.TRPOAgent.log][training]: gradient_step_direction: [-2.81533477e+00 -3.49357143e+02  1.09514195e+00  5.18224268e+02
  2.56135797e+01  0.00000000e+00  8.86936817e+01  3.31617045e+01
  1.08366494e+02 -1.22268001e-15  0.00000000e+00  7.12902113e+01
  0.00000000e+00  0.00000000e+00 -5.34204230e-25  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  4.45789318e+02
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.81587108e-14
  0.00000000e+00  2.23604497e-08  0.00000000e+00 -1.33703000e+00
  0.00000000e+00  0.00000000e+00  4.07708973e+01  0.00000000e+00
  2.10370363e+00  0.00000000e+00  5.18220396e+01  0.00000000e+00
  1.55935404e+00  5.83027242e-01  1.90522847e+00 -3.59351235e-16
  0.00000000e+00  1.25337755e+00  0.00000000e+00  0.00000000e+00
 -1.06318428e-25  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  7.83757713e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -8.27597364e-15  0.00000000e+00  8.60751650e-09
  0.00000000e+00 -2.35070683e-02  0.00000000e+00  0.00000000e+00
  7.16807134e-01  0.00000000e+00  3.69858961e-02  0.00000000e+00
  9.11100981e-01  0.00000000e+00  0.00000000e+00  8.27168035e+01
 -8.27168035e+01  3.65194512e+01 -3.65194512e+01  1.03546817e+02
 -1.03546817e+02 -5.24007640e-69 -2.05564604e-15  0.00000000e+00
  0.00000000e+00  7.46590070e+01 -7.46590070e+01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -5.69016574e-70
 -3.26220653e-27  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.25703881e+02 -2.25703881e+02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.66369237e-68 -7.82918266e-15  0.00000000e+00
  0.00000000e+00  2.53556869e-10 -2.53570452e-10  0.00000000e+00
  0.00000000e+00  2.34627182e+01 -2.34627182e+01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.83626490e+01
 -3.83626490e+01  0.00000000e+00  0.00000000e+00  6.36896136e+00
 -6.36896136e+00  0.00000000e+00  0.00000000e+00  4.83767501e+01
 -4.83767501e+01  1.58469611e+00 -1.58469611e+00]

[2020-01-28 17:04:37.054121][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 2, New mean kl div: 0.009194832411387197, New policy loss value: 0.04848550043962779

[2020-01-28 17:04:37.088908][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 12.026461815383906

[2020-01-28 17:04:37.089314][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:37.091583][__main__.TRPOAgent.log][batch_info]: Batch #2, batch length: 10

[2020-01-28 17:04:37.101907][__main__.TRPOAgent.log][training]: policy_gradient: [ 1.76662433e-013 -1.84492204e-013 -5.26018945e-014  8.32421947e-014
 -3.96424144e-012  0.00000000e+000 -3.79987955e-013 -1.47375540e-013
 -4.66625486e-013  5.63832069e-027  0.00000000e+000 -3.13175181e-013
  0.00000000e+000  0.00000000e+000  2.97458127e-049  0.00000000e+000
  0.00000000e+000  0.00000000e+000  0.00000000e+000 -1.72972843e-012
  0.00000000e+000  0.00000000e+000  0.00000000e+000  1.29852325e-025
  0.00000000e+000 -3.57909270e-025  0.00000000e+000 -1.76958949e-014
  0.00000000e+000  0.00000000e+000 -1.74994205e-013  0.00000000e+000
 -1.31898642e-014  0.00000000e+000 -2.22065092e-013  0.00000000e+000
 -2.09370006e-013 -8.12026203e-014 -2.57106520e-013  1.90373337e-027
  0.00000000e+000 -1.72556757e-013  0.00000000e+000  0.00000000e+000
  5.65759146e-050  0.00000000e+000  0.00000000e+000  0.00000000e+000
  0.00000000e+000 -9.53065078e-013  0.00000000e+000  0.00000000e+000
  0.00000000e+000  4.38435871e-026  0.00000000e+000 -1.20845170e-025
  0.00000000e+000 -9.75028172e-015  0.00000000e+000  0.00000000e+000
 -9.64202605e-014  0.00000000e+000 -7.26749861e-015  0.00000000e+000
 -1.22355903e-013  0.00000000e+000  0.00000000e+000 -3.26276965e-013
  3.26281030e-013 -1.48796564e-013  1.48798418e-013 -4.16214557e-013
  4.16219742e-013  6.50446449e-106  2.21975286e-027  0.00000000e+000
  0.00000000e+000 -3.11123797e-013  3.11127673e-013  0.00000000e+000
  0.00000000e+000  0.00000000e+000  0.00000000e+000  6.50498980e-107
  2.36707597e-051  0.00000000e+000  0.00000000e+000  0.00000000e+000
  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000
  0.00000000e+000 -6.09726881e-013  6.09734477e-013  0.00000000e+000
  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000
  0.00000000e+000  2.07357076e-105  1.48213803e-026  0.00000000e+000
  0.00000000e+000  2.85608184e-105  3.58082618e-026  0.00000000e+000
  0.00000000e+000 -1.26483506e-013  1.26485082e-013  0.00000000e+000
  0.00000000e+000  0.00000000e+000  0.00000000e+000 -1.47434519e-013
  1.47436356e-013  0.00000000e+000  0.00000000e+000 -2.55850385e-014
  2.55853573e-014  0.00000000e+000  0.00000000e+000 -2.23459063e-013
  2.23461847e-013 -1.68864922e-013  1.68867026e-013]

[2020-01-28 17:04:37.102519][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:37.117344][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 3.92155557e-028 -4.09536094e-028 -1.16765771e-028  1.84781159e-028
 -8.79982960e-027  0.00000000e+000 -8.43497881e-028 -3.27144464e-028
 -1.03581601e-027  1.25159534e-041  0.00000000e+000 -6.95186775e-028
  0.00000000e+000  0.00000000e+000  6.60298035e-064  0.00000000e+000
  0.00000000e+000  0.00000000e+000  0.00000000e+000 -3.83965397e-027
  0.00000000e+000  0.00000000e+000  0.00000000e+000  2.88246402e-040
  0.00000000e+000 -7.94487579e-040  0.00000000e+000 -3.92813763e-029
  0.00000000e+000  0.00000000e+000 -3.88452420e-028  0.00000000e+000
 -2.92788820e-029  0.00000000e+000 -4.92940451e-028  0.00000000e+000
 -4.64759879e-028 -1.80253709e-028 -5.70725470e-028  4.22591043e-042
  0.00000000e+000 -3.83041770e-028  0.00000000e+000  0.00000000e+000
  1.25587307e-064  0.00000000e+000  0.00000000e+000  0.00000000e+000
  0.00000000e+000 -2.11561541e-027  0.00000000e+000  0.00000000e+000
  0.00000000e+000  9.73240660e-041  0.00000000e+000 -2.68252304e-040
  0.00000000e+000 -2.16436912e-029  0.00000000e+000  0.00000000e+000
 -2.14033851e-028  0.00000000e+000 -1.61324052e-029  0.00000000e+000
 -2.71605833e-028  0.00000000e+000  0.00000000e+000 -7.24270138e-028
  7.24279162e-028 -3.30298855e-028  3.30302970e-028 -9.23913750e-028
  9.23925261e-028  1.44386209e-120  4.92741100e-042  0.00000000e+000
  0.00000000e+000 -6.90633110e-028  6.90641715e-028  0.00000000e+000
  0.00000000e+000  0.00000000e+000  0.00000000e+000  1.44397869e-121
  5.25443908e-066  0.00000000e+000  0.00000000e+000  0.00000000e+000
  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000
  0.00000000e+000 -1.35347272e-027  1.35348958e-027  0.00000000e+000
  0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000
  0.00000000e+000  4.60291574e-120  3.29005241e-041  0.00000000e+000
  0.00000000e+000  6.33993511e-120  7.94872378e-041  0.00000000e+000
  0.00000000e+000 -2.80768293e-028  2.80771791e-028  0.00000000e+000
  0.00000000e+000  0.00000000e+000  0.00000000e+000 -3.27275385e-028
  3.27279463e-028  0.00000000e+000  0.00000000e+000 -5.67937101e-029
  5.67944177e-029  0.00000000e+000  0.00000000e+000 -4.96034792e-028
  4.96040972e-028 -3.74846629e-028  3.74851299e-028]

[2020-01-28 17:04:37.180766][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 3, New mean kl div: 3.967549976888002e-06, New policy loss value: -0.016453067408969214

[2020-01-28 17:04:37.211672][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 7.0182811096310616

[2020-01-28 17:04:37.212137][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:37.216606][__main__.TRPOAgent.log][batch_info]: Batch #3, batch length: 11

[2020-01-28 17:04:37.231203][__main__.TRPOAgent.log][training]: policy_gradient: [ 5.32387580e-06 -5.55983273e-06 -1.58520376e-06  2.50857580e-06
 -1.19465857e-04  0.00000000e+00 -8.10988014e-06 -3.09954425e-06
 -9.92693450e-06  1.02869687e-29  0.00000000e+00 -6.59701145e-06
  0.00000000e+00  0.00000000e+00 -8.47043307e-41  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.87188622e-05
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.36912140e-28
  0.00000000e+00 -6.52996019e-28  0.00000000e+00 -1.48582870e-07
  0.00000000e+00  0.00000000e+00 -3.74064534e-06  0.00000000e+00
 -2.52166792e-07  0.00000000e+00 -4.67191459e-06  0.00000000e+00
 -6.56088264e-06 -2.50752733e-06 -8.03087730e-06  2.86055192e-30
  0.00000000e+00 -5.33697381e-06  0.00000000e+00  0.00000000e+00
 -1.77416119e-41  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -3.13235099e-05  0.00000000e+00  0.00000000e+00
  0.00000000e+00  6.58794146e-29  0.00000000e+00 -1.81582064e-28
  0.00000000e+00 -1.20203352e-07  0.00000000e+00  0.00000000e+00
 -3.02617729e-06  0.00000000e+00 -2.04002612e-07  0.00000000e+00
 -3.77957292e-06  0.00000000e+00  0.00000000e+00 -7.00811076e-06
  7.00811076e-06 -3.31890957e-06  3.31890957e-06 -9.06703502e-06
  9.06703502e-06  6.34443436e-38  2.20887523e-29  0.00000000e+00
  0.00000000e+00 -6.98644789e-06  6.98644789e-06  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -3.31915180e-43  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -7.39151267e-06  7.39151267e-06  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.31971741e-37  7.99234591e-29  0.00000000e+00
  0.00000000e+00  3.78574909e-37  1.28978881e-28  0.00000000e+00
  0.00000000e+00 -3.42589412e-06  3.42589412e-06  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.12072674e-06
  3.12072674e-06  0.00000000e+00  0.00000000e+00 -6.04421415e-07
  6.04421415e-07  0.00000000e+00  0.00000000e+00 -5.21825531e-06
  5.21825531e-06 -5.72986638e-06  5.72986638e-06]

[2020-01-28 17:04:37.231810][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:37.249090][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 9.47670196e-06 -9.89671431e-06 -2.82172315e-06  4.46536060e-06
 -2.12653782e-04  0.00000000e+00 -1.44358959e-05 -5.51730697e-06
 -1.76703220e-05  1.83111967e-29  0.00000000e+00 -1.17429320e-05
  0.00000000e+00  0.00000000e+00 -1.50776939e-40  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.89210513e-05
  0.00000000e+00  0.00000000e+00  0.00000000e+00  4.21712645e-28
  0.00000000e+00 -1.16235782e-27  0.00000000e+00 -2.64483176e-07
  0.00000000e+00  0.00000000e+00 -6.65849137e-06  0.00000000e+00
 -4.48866507e-07  0.00000000e+00 -8.31618616e-06  0.00000000e+00
 -1.16786213e-05 -4.46349427e-06 -1.42952679e-05  5.09189152e-30
  0.00000000e+00 -9.50001692e-06  0.00000000e+00  0.00000000e+00
 -3.15807459e-41  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -5.57570423e-05  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.17267870e-28  0.00000000e+00 -3.23222999e-28
  0.00000000e+00 -2.13966550e-07  0.00000000e+00  0.00000000e+00
 -5.38671099e-06  0.00000000e+00 -3.63132430e-07  0.00000000e+00
 -6.72778395e-06  0.00000000e+00  0.00000000e+00 -1.24747044e-05
  1.24747044e-05 -5.90778561e-06  5.90778561e-06 -1.61396681e-05
  1.61396681e-05  1.12933351e-37  3.93188216e-29  0.00000000e+00
  0.00000000e+00 -1.24361437e-05  1.24361437e-05  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -5.90821679e-43  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.31571745e-05  1.31571745e-05  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  4.12918545e-37  1.42266805e-28  0.00000000e+00
  0.00000000e+00  6.73877776e-37  2.29587327e-28  0.00000000e+00
  0.00000000e+00 -6.09822220e-06  6.09822220e-06  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -5.55501261e-06
  5.55501261e-06  0.00000000e+00  0.00000000e+00 -1.07589317e-06
  1.07589317e-06  0.00000000e+00  0.00000000e+00 -9.28869346e-06
  9.28869346e-06 -1.01993807e-05  1.01993807e-05]

[2020-01-28 17:04:37.326719][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 4, New mean kl div: 0.00031784685672390405, New policy loss value: -0.08811121147368746

[2020-01-28 17:04:37.359523][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 7.160978523030363

[2020-01-28 17:04:37.359970][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:37.363034][__main__.TRPOAgent.log][batch_info]: Batch #4, batch length: 11

[2020-01-28 17:04:37.372833][__main__.TRPOAgent.log][training]: policy_gradient: [-1.36361927e-01  1.42384505e-01  4.06205321e-02 -6.42734782e-02
  3.05943025e+00  0.00000000e+00  1.79001544e-01  6.81104143e-02
  2.18876542e-01  5.91948249e-27  0.00000000e+00  1.45001544e-01
  0.00000000e+00  0.00000000e+00 -7.90596707e-37  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  8.66929508e-01
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.36327571e-25
  0.00000000e+00 -3.75756856e-25  0.00000000e+00  1.72035250e-03
  0.00000000e+00  0.00000000e+00  8.26164797e-02  0.00000000e+00
  5.38307688e-03  0.00000000e+00  1.02560215e-01  0.00000000e+00
  1.69215292e-01  1.90741515e-02  6.12958293e-02  1.74779037e-27
  0.00000000e+00  4.06073205e-02  0.00000000e+00  0.00000000e+00
 -1.73965308e-37  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  8.19533321e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  4.02521700e-26  0.00000000e+00 -1.10946221e-25
  0.00000000e+00  4.81780423e-04  0.00000000e+00  0.00000000e+00
  7.80997271e-02  0.00000000e+00  1.50751725e-03  0.00000000e+00
  2.87217322e-02  0.00000000e+00  0.00000000e+00  1.53897553e-01
 -1.53897553e-01  7.01203385e-02 -7.01203385e-02  1.97527820e-01
 -1.97527820e-01  0.00000000e+00  9.71588606e-27  0.00000000e+00
  0.00000000e+00  1.45167280e-01 -1.45167280e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -1.34177330e-39  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  9.79998254e-02 -9.79998254e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  3.72114191e-26  0.00000000e+00
  0.00000000e+00  0.00000000e+00  6.36523921e-26  0.00000000e+00
  0.00000000e+00  5.27034895e-02 -5.27034895e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  6.79809542e-02
 -6.79809542e-02  0.00000000e+00  0.00000000e+00  1.20930422e-02
 -1.20930422e-02  0.00000000e+00  0.00000000e+00  9.97301361e-02
 -9.97301361e-02  4.45899388e-02 -4.45899388e-02]

[2020-01-28 17:04:37.373244][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:37.409447][__main__.TRPOAgent.log][training]: gradient_step_direction: [-6.95163439e+00  1.08745777e+00  7.42406515e+00 -9.32116164e+00
  1.45872317e+01  0.00000000e+00 -6.89393035e-01 -2.62314997e-01
 -8.42964375e-01 -2.13062046e-19  0.00000000e+00 -5.58446945e-01
  0.00000000e+00  0.00000000e+00 -8.73809753e-28  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.33881749e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.90688691e-18
  0.00000000e+00  1.35247506e-17  0.00000000e+00 -6.62285254e-03
  0.00000000e+00  0.00000000e+00 -3.18182827e-01  0.00000000e+00
 -2.07318788e-02  0.00000000e+00 -3.94990560e-01  0.00000000e+00
  8.06811625e-01 -1.27177108e+00 -4.08690636e+00 -6.36042928e-20
  0.00000000e+00 -2.70749720e+00  0.00000000e+00  0.00000000e+00
 -1.93699000e-28  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  3.90751026e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.46482716e-18  0.00000000e+00  4.03747272e-18
  0.00000000e+00 -3.21212869e-02  0.00000000e+00  0.00000000e+00
  3.72376362e-01  0.00000000e+00 -1.00513834e-01  0.00000000e+00
 -1.91502368e+00  0.00000000e+00  0.00000000e+00 -6.21221231e-01
  6.21221231e-01 -3.79100709e-01  3.79100709e-01 -8.41296147e-01
  8.41296147e-01  0.00000000e+00 -3.29234179e-19  0.00000000e+00
  0.00000000e+00 -8.68815080e-01  8.68815080e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -1.18445150e-30  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -3.54636913e+00  3.54636913e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00 -1.27934531e-18  0.00000000e+00
  0.00000000e+00  0.00000000e+00 -2.21882651e-18  0.00000000e+00
  0.00000000e+00 -1.00972072e+00  1.00972072e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.04359738e-01
  3.04359738e-01  0.00000000e+00  0.00000000e+00 -9.30101656e-02
  9.30101656e-02  0.00000000e+00  0.00000000e+00 -9.08028055e-01
  9.08028055e-01 -2.97303829e+00  2.97303829e+00]

[2020-01-28 17:04:37.445748][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: 0.009350880572696688, New policy loss value: 0.062120731806002964

[2020-01-28 17:04:37.482168][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 6.043924774974585

[2020-01-28 17:04:37.482707][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:37.486155][__main__.TRPOAgent.log][batch_info]: Batch #5, batch length: 9

[2020-01-28 17:04:37.499848][__main__.TRPOAgent.log][training]: policy_gradient: [ 5.92045175e-07 -6.18284922e-07 -1.76283646e-07  2.78967850e-07
 -1.32852807e-05  0.00000000e+00 -1.10716638e-06 -4.13725710e-07
 -1.34947948e-06  9.11429550e-27  0.00000000e+00 -8.77521102e-07
  0.00000000e+00  0.00000000e+00  1.54091311e-34  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -5.33370564e-06
  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.09905134e-25
  0.00000000e+00 -1.53729880e-15  0.00000000e+00  4.24784959e-08
  0.00000000e+00  0.00000000e+00 -5.10068660e-07  0.00000000e+00
 -2.93620741e-08  0.00000000e+00 -6.05141583e-07  0.00000000e+00
 -7.60639323e-07 -2.84235549e-07 -9.27111929e-07  2.51905684e-27
  0.00000000e+00 -6.02869695e-07  0.00000000e+00  0.00000000e+00
  3.27329590e-35  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -3.66433296e-06  0.00000000e+00  0.00000000e+00
  0.00000000e+00  5.80146829e-26  0.00000000e+00 -6.06197291e-16
  0.00000000e+00  2.91833414e-08  0.00000000e+00  0.00000000e+00
 -3.50424550e-07  0.00000000e+00 -2.01721698e-08  0.00000000e+00
 -4.15741024e-07  0.00000000e+00  0.00000000e+00 -9.82339106e-07
  9.82339106e-07 -4.32593838e-07  4.32593838e-07 -1.17330193e-06
  1.17330193e-06  0.00000000e+00  2.00241887e-26  0.00000000e+00
  0.00000000e+00 -9.06189959e-07  9.06189958e-07  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  5.07734612e-37  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.24667671e-06  1.24667671e-06  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  7.21418737e-26  0.00000000e+00
  0.00000000e+00 -5.63654120e-18  5.59344134e-18  0.00000000e+00
  0.00000000e+00 -4.53754749e-07  4.53754749e-07  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.39903383e-07
  4.39903383e-07  0.00000000e+00  0.00000000e+00 -8.14845875e-08
  8.14845875e-08  0.00000000e+00  0.00000000e+00 -6.67093949e-07
  6.67093949e-07 -6.96682807e-07  6.96682807e-07]

[2020-01-28 17:04:37.500307][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:37.512156][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 1.41194938e-08 -1.47452771e-08 -4.20413164e-09  6.65301400e-09
 -3.16836362e-07  0.00000000e+00 -2.64044528e-08 -9.86681061e-09
 -3.21832995e-08  2.17363885e-28  0.00000000e+00 -2.09277169e-08
  0.00000000e+00  0.00000000e+00  3.67487382e-36  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.27201820e-07
  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.00595964e-27
  0.00000000e+00 -3.66625417e-17  0.00000000e+00  1.01305591e-09
  0.00000000e+00  0.00000000e+00 -1.21644624e-08  0.00000000e+00
 -7.00246606e-10  0.00000000e+00 -1.44318258e-08  0.00000000e+00
 -1.81402411e-08 -6.77864166e-09 -2.21103924e-08  6.00761715e-29
  0.00000000e+00 -1.43776443e-08  0.00000000e+00  0.00000000e+00
  7.80637749e-37  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -8.73894912e-08  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.38357340e-27  0.00000000e+00 -1.44570031e-17
  0.00000000e+00  6.95984067e-10  0.00000000e+00  0.00000000e+00
 -8.35716172e-09  0.00000000e+00 -4.81079551e-10  0.00000000e+00
 -9.91487318e-09  0.00000000e+00  0.00000000e+00 -2.34274875e-08
  2.34274875e-08 -1.03167905e-08  1.03167905e-08 -2.79816982e-08
  2.79816982e-08  0.00000000e+00  4.77550398e-28  0.00000000e+00
  0.00000000e+00 -2.16114311e-08  2.16114311e-08  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  1.21087985e-38  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -2.97315895e-08  2.97315895e-08  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  1.72048821e-27  0.00000000e+00
  0.00000000e+00 -1.34424048e-19  1.33396173e-19  0.00000000e+00
  0.00000000e+00 -1.08214502e-08  1.08214502e-08  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.04911135e-08
  1.04911135e-08  0.00000000e+00  0.00000000e+00 -1.94329957e-09
  1.94329957e-09  0.00000000e+00  0.00000000e+00 -1.59093078e-08
  1.59093078e-08 -1.66149629e-08  1.66149629e-08]

[2020-01-28 17:04:37.590985][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 4, New mean kl div: 0.00032323157904288574, New policy loss value: -0.0005121437873022808

[2020-01-28 17:04:37.622979][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 2.4770170671658382

[2020-01-28 17:04:37.623403][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:37.626537][__main__.TRPOAgent.log][batch_info]: Batch #6, batch length: 9

[2020-01-28 17:04:37.639382][__main__.TRPOAgent.log][training]: policy_gradient: [ 4.20336959e-04 -4.38966507e-04 -1.25156888e-04  1.98060047e-04
 -9.43221012e-03  0.00000000e+00 -6.50460597e-04 -2.41436712e-04
 -7.93416512e-04  4.47920117e-23  0.00000000e+00 -5.12374384e-04
  0.00000000e+00  0.00000000e+00  1.95411318e-30  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.22013361e-03
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.03157432e-21
  0.00000000e+00 -2.84330691e-21  0.00000000e+00  3.71629694e-05
  0.00000000e+00  0.00000000e+00 -2.99979899e-04  0.00000000e+00
 -1.58733447e-05  0.00000000e+00 -3.52287393e-04  0.00000000e+00
 -5.47816650e-04 -2.03337530e-04 -6.68213844e-04  1.33386143e-23
  0.00000000e+00 -4.31520710e-04  0.00000000e+00  0.00000000e+00
  4.38984728e-31  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -2.71199026e-03  0.00000000e+00  0.00000000e+00
  0.00000000e+00  3.07192545e-22  0.00000000e+00 -8.46708439e-22
  0.00000000e+00  3.12985806e-05  0.00000000e+00  0.00000000e+00
 -2.52642488e-04  0.00000000e+00 -1.33685001e-05  0.00000000e+00
 -2.96695757e-04  0.00000000e+00  0.00000000e+00 -5.76978709e-04
  5.76978709e-04 -2.56122265e-04  2.56122265e-04 -6.81245266e-04
  6.81245266e-04  0.00000000e+00  7.01836820e-23  0.00000000e+00
  0.00000000e+00 -5.38982919e-04  5.38982919e-04  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  1.42945357e-33  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -4.30810615e-04  4.30810615e-04  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  2.71796781e-22  0.00000000e+00
  0.00000000e+00  0.00000000e+00  4.69881995e-22  0.00000000e+00
  0.00000000e+00 -3.04957690e-04  3.04957690e-04  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.55924653e-04
  2.55924653e-04  0.00000000e+00  0.00000000e+00 -5.04308273e-05
  5.04308273e-05  0.00000000e+00  0.00000000e+00 -4.07902963e-04
  4.07902963e-04 -5.20576614e-04  5.20576614e-04]

[2020-01-28 17:04:37.639807][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:37.654893][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 3.05648024e-03 -3.19194500e-03 -9.10078324e-04  1.44019366e-03
 -6.85863169e-02  0.00000000e+00 -4.72982431e-03 -1.75560708e-03
 -5.76932826e-03  3.25705118e-22  0.00000000e+00 -3.72573039e-03
  0.00000000e+00  0.00000000e+00  1.42093342e-29  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.34152019e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  7.50109281e-21
  0.00000000e+00 -2.06751065e-20  0.00000000e+00  2.70230536e-04
  0.00000000e+00  0.00000000e+00 -2.18130387e-03  0.00000000e+00
 -1.15423028e-04  0.00000000e+00 -2.56165782e-03  0.00000000e+00
 -3.98344883e-03 -1.47856887e-03 -4.85891704e-03  9.69917355e-23
  0.00000000e+00 -3.13780289e-03  0.00000000e+00  0.00000000e+00
  3.19207750e-30  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.97202375e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  2.23375062e-21  0.00000000e+00 -6.15684051e-21
  0.00000000e+00  2.27587632e-04  0.00000000e+00  0.00000000e+00
 -1.83708988e-03  0.00000000e+00 -9.72090497e-05  0.00000000e+00
 -2.15742323e-03  0.00000000e+00  0.00000000e+00 -4.19550074e-03
  4.19550074e-03 -1.86239308e-03  1.86239308e-03 -4.95367503e-03
  4.95367503e-03  0.00000000e+00  5.10340651e-22  0.00000000e+00
  0.00000000e+00 -3.91921435e-03  3.91921435e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  1.03942718e-32  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -3.13263943e-03  3.13263943e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  1.97637033e-21  0.00000000e+00
  0.00000000e+00  0.00000000e+00  3.41674698e-21  0.00000000e+00
  0.00000000e+00 -2.21749988e-03  2.21749988e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.86095615e-03
  1.86095615e-03  0.00000000e+00  0.00000000e+00 -3.66707767e-04
  3.66707767e-04  0.00000000e+00  0.00000000e+00 -2.96606644e-03
  2.96606644e-03 -3.78537291e-03  3.78537291e-03]

[2020-01-28 17:04:37.707033][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 2, New mean kl div: 0.002318754166394778, New policy loss value: -0.004862557196398252

[2020-01-28 17:04:37.739036][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 1.843162056679527

[2020-01-28 17:04:37.739448][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:37.741866][__main__.TRPOAgent.log][batch_info]: Batch #7, batch length: 9

[2020-01-28 17:04:37.751877][__main__.TRPOAgent.log][training]: policy_gradient: [ 4.32214655e-03 -4.51370628e-03 -1.28693516e-03  2.03656739e-03
 -9.69874136e-02  0.00000000e+00 -6.12777985e-03 -2.26907963e-03
 -7.47743181e-03  8.29989694e-22  0.00000000e+00 -4.81600468e-03
  0.00000000e+00  0.00000000e+00 -1.76850016e-38  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.06490270e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.91149276e-20
  0.00000000e+00 -5.26860783e-20  0.00000000e+00  3.93732692e-04
  0.00000000e+00  0.00000000e+00 -2.82732677e-03  0.00000000e+00
 -1.44844093e-04  0.00000000e+00 -3.30646642e-03  0.00000000e+00
 -5.65523462e-03 -2.09409900e-03 -6.90080785e-03  2.54800495e-22
  0.00000000e+00 -4.44461732e-03  0.00000000e+00  0.00000000e+00
 -3.23919614e-39  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -2.82855199e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  5.86813673e-21  0.00000000e+00 -1.61742235e-20
  0.00000000e+00  3.63369900e-04  0.00000000e+00  0.00000000e+00
 -2.60929679e-03  0.00000000e+00 -1.33674406e-04  0.00000000e+00
 -3.05148746e-03  0.00000000e+00  0.00000000e+00 -5.41927320e-03
  5.41927320e-03 -2.41449257e-03  2.41449257e-03 -6.35888506e-03
  6.35888506e-03  0.00000000e+00  1.07564537e-21  0.00000000e+00
  0.00000000e+00 -5.09375026e-03  5.09375026e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -1.66837885e-40  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -2.59027195e-03  2.59027195e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  4.37719706e-21  0.00000000e+00
  0.00000000e+00  0.00000000e+00  7.91350110e-21  0.00000000e+00
  0.00000000e+00 -3.04893491e-03  3.04893491e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.39155424e-03
  2.39155424e-03  0.00000000e+00  0.00000000e+00 -4.85490400e-04
  4.85490400e-04  0.00000000e+00  0.00000000e+00 -3.91022909e-03
  3.91022909e-03 -5.43936492e-03  5.43936492e-03]

[2020-01-28 17:04:37.752470][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:37.765507][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 3.32322222e-03 -3.47050911e-03 -9.89501738e-04  1.56588073e-03
 -7.45719110e-02  0.00000000e+00 -4.71154180e-03 -1.74465529e-03
 -5.74926538e-03  6.38164431e-22  0.00000000e+00 -3.70294102e-03
  0.00000000e+00  0.00000000e+00 -1.35976856e-38  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.35654961e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.46971305e-20
  0.00000000e+00 -4.05093960e-20  0.00000000e+00  3.02734119e-04
  0.00000000e+00  0.00000000e+00 -2.17388167e-03  0.00000000e+00
 -1.11368068e-04  0.00000000e+00 -2.54228368e-03  0.00000000e+00
 -4.34821012e-03 -1.61011577e-03 -5.30590939e-03  1.95911605e-22
  0.00000000e+00 -3.41738783e-03  0.00000000e+00  0.00000000e+00
 -2.49056076e-39  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -2.17482371e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  4.51190678e-21  0.00000000e+00 -1.24360751e-20
  0.00000000e+00  2.79388704e-04  0.00000000e+00  0.00000000e+00
 -2.00624226e-03  0.00000000e+00 -1.02779892e-04  0.00000000e+00
 -2.34623486e-03  0.00000000e+00  0.00000000e+00 -4.16678354e-03
  4.16678354e-03 -1.85646074e-03  1.85646074e-03 -4.88923452e-03
  4.88923452e-03  0.00000000e+00  8.27044748e-22  0.00000000e+00
  0.00000000e+00 -3.91649470e-03  3.91649470e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -1.28278706e-40  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.99161439e-03  1.99161439e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  3.36554958e-21  0.00000000e+00
  0.00000000e+00  0.00000000e+00  6.08455136e-21  0.00000000e+00
  0.00000000e+00 -2.34427225e-03  2.34427225e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.83882385e-03
  1.83882385e-03  0.00000000e+00  0.00000000e+00 -3.73285002e-04
  3.73285002e-04  0.00000000e+00  0.00000000e+00 -3.00650615e-03
  3.00650615e-03 -4.18223171e-03  4.18223171e-03]

[2020-01-28 17:04:37.807418][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.006128875176734711, New policy loss value: -0.017210930207800686

[2020-01-28 17:04:37.845026][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 1.2886855254570644

[2020-01-28 17:04:37.845426][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:37.847973][__main__.TRPOAgent.log][batch_info]: Batch #8, batch length: 10

[2020-01-28 17:04:37.857538][__main__.TRPOAgent.log][training]: policy_gradient: [ 1.58168037e-02 -1.65178123e-02 -4.70951194e-03  7.45277507e-03
 -3.54923384e-01  0.00000000e+00 -2.10595127e-02 -7.78657102e-03
 -2.57051488e-02  5.60290271e-21  0.00000000e+00 -1.65274776e-02
  0.00000000e+00  0.00000000e+00 -2.63847115e-37  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.06032077e-01
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.29036638e-19
  0.00000000e+00 -3.55661007e-19  0.00000000e+00  1.45011325e-03
  0.00000000e+00  0.00000000e+00 -9.71986054e-03  0.00000000e+00
 -4.87589050e-04  0.00000000e+00 -1.13352816e-02  0.00000000e+00
 -2.07400779e-02 -7.66846278e-03 -2.53152480e-02  1.75731568e-21
  0.00000000e+00 -1.62767856e-02  0.00000000e+00  0.00000000e+00
 -4.79523802e-38  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.04423762e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  4.04715409e-20  0.00000000e+00 -1.11550869e-19
  0.00000000e+00  1.42811764e-03  0.00000000e+00  0.00000000e+00
 -9.57242778e-03  0.00000000e+00 -4.80193203e-04  0.00000000e+00
 -1.11633458e-02  0.00000000e+00  0.00000000e+00 -1.85663594e-02
  1.85663594e-02 -8.29431144e-03  8.29431144e-03 -2.16793298e-02
  2.16793298e-02  3.99982640e-39  6.16411468e-21  0.00000000e+00
  0.00000000e+00 -1.75323870e-02  1.75323870e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -2.56755559e-39  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -5.04334316e-03  5.04334316e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.34270262e-38  2.63323331e-20  0.00000000e+00
  0.00000000e+00  1.98374345e-38  4.95496576e-20  0.00000000e+00
  0.00000000e+00 -1.09301766e-02  1.09301766e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -8.16090309e-03
  8.16090309e-03  0.00000000e+00  0.00000000e+00 -1.69374754e-03
  1.69374754e-03  0.00000000e+00  0.00000000e+00 -1.36056034e-02
  1.36056034e-02 -2.00949103e-02  2.00949103e-02]

[2020-01-28 17:04:37.858007][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:37.872842][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 3.79082555e-03 -3.95883684e-03 -1.12873236e-03  1.78621235e-03
 -8.50647614e-02  0.00000000e+00 -5.04734967e-03 -1.86621349e-03
 -6.16077286e-03  1.34285202e-21  0.00000000e+00 -3.96115332e-03
  0.00000000e+00  0.00000000e+00 -6.32364417e-38  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.54127898e-02
  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.09263105e-20
  0.00000000e+00 -8.52415482e-20  0.00000000e+00  3.47549761e-04
  0.00000000e+00  0.00000000e+00 -2.32956648e-03  0.00000000e+00
 -1.16860844e-04  0.00000000e+00 -2.71673570e-03  0.00000000e+00
 -4.97079047e-03 -1.83790639e-03 -6.06732504e-03  4.21177205e-22
  0.00000000e+00 -3.90106977e-03  0.00000000e+00  0.00000000e+00
 -1.14927840e-38  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -2.50273236e-02  0.00000000e+00  0.00000000e+00
  0.00000000e+00  9.69984545e-21  0.00000000e+00 -2.67354828e-20
  0.00000000e+00  3.42278058e-04  0.00000000e+00  0.00000000e+00
 -2.29423115e-03  0.00000000e+00 -1.15088276e-04  0.00000000e+00
 -2.67552771e-03  0.00000000e+00  0.00000000e+00 -4.44981368e-03
  4.44981368e-03 -1.98790403e-03  1.98790403e-03 -5.19590172e-03
  5.19590172e-03  9.58641481e-40  1.47735812e-21  0.00000000e+00
  0.00000000e+00 -4.20200072e-03  4.20200072e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -6.15368030e-40  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.20874195e-03  1.20874195e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  3.21806573e-39  6.31109060e-21  0.00000000e+00
  0.00000000e+00  4.75445325e-39  1.18756047e-20  0.00000000e+00
  0.00000000e+00 -2.61964386e-03  2.61964386e-03  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.95592994e-03
  1.95592994e-03  0.00000000e+00  0.00000000e+00 -4.05941780e-04
  4.05941780e-04  0.00000000e+00  0.00000000e+00 -3.26086547e-03
  3.26086547e-03 -4.81616267e-03  4.81616267e-03]

[2020-01-28 17:04:37.918553][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: 0.004556276981538205, New policy loss value: -0.09243317787553025

[2020-01-28 17:04:37.953044][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 2.3109331770567225

[2020-01-28 17:04:37.953457][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-28 17:04:37.956517][__main__.TRPOAgent.log][batch_info]: Batch #9, batch length: 12

[2020-01-28 17:04:37.969758][__main__.TRPOAgent.log][training]: policy_gradient: [ 3.81509893e-02 -4.72566015e-02 -1.23920968e-02  2.80560248e-02
 -8.44740864e-01  0.00000000e+00 -4.60098560e-02 -1.69980074e-02
 -5.61688701e-02  1.57068680e-21  0.00000000e+00 -3.60800194e-02
  0.00000000e+00  0.00000000e+00 -3.41366766e-37  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.32503711e-01
  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.61734183e-20
  0.00000000e+00 -9.97040425e-20  0.00000000e+00  3.28544203e-03
  0.00000000e+00  0.00000000e+00 -2.12394274e-02  0.00000000e+00
 -1.05311869e-03  0.00000000e+00 -2.47300957e-02  0.00000000e+00
 -4.94148874e-02 -1.82559715e-02 -6.03257352e-02  5.00160497e-22
  0.00000000e+00 -3.87501776e-02  0.00000000e+00  0.00000000e+00
 -6.18138089e-38  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -2.49710512e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  1.15188559e-20  0.00000000e+00 -3.17491835e-20
  0.00000000e+00  3.52858630e-03  0.00000000e+00  0.00000000e+00
 -2.28112845e-02  0.00000000e+00 -1.13105639e-03  0.00000000e+00
 -2.65602852e-02  0.00000000e+00  0.00000000e+00 -4.04076083e-02
  4.04076083e-02 -1.80997075e-02  1.80997075e-02 -4.68599195e-02
  4.68599195e-02  2.08160101e-39  1.50650725e-21  0.00000000e+00
  0.00000000e+00 -3.83687839e-02  3.83687839e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -3.36958190e-39  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -1.80892548e-04  1.80892548e-04  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  6.98630031e-39  6.73249834e-21  0.00000000e+00
  0.00000000e+00  1.03190395e-38  1.31089220e-20  0.00000000e+00
  0.00000000e+00 -2.51373189e-02  2.51373189e-02  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.76640986e-02
  1.76640986e-02  0.00000000e+00  0.00000000e+00 -3.76305967e-03
  3.76305967e-03  0.00000000e+00  0.00000000e+00 -3.02202518e-02
  3.02202518e-02 -4.80633532e-02  4.80633532e-02]

[2020-01-28 17:04:37.970201][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:04:38.003562][__main__.TRPOAgent.log][training]: gradient_step_direction: [-2.95511683e-02 -6.17944443e+00  4.61796020e-01  1.00056317e+01
 -3.37255671e+00  0.00000000e+00  1.90883779e+00  7.05206267e-01
  2.33031074e+00 -8.99402534e-15  0.00000000e+00  1.49687285e+00
  0.00000000e+00  0.00000000e+00  4.52271891e-32  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  9.64601728e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.38071934e-14
  0.00000000e+00 -3.38134512e-14  0.00000000e+00 -1.36305046e-01
  0.00000000e+00  0.00000000e+00  8.81172539e-01  0.00000000e+00
  4.36913515e-02  0.00000000e+00  1.02599194e+00  0.00000000e+00
 -1.97284776e-01 -7.28854279e-02 -2.40845417e-01 -2.81934965e-15
  0.00000000e+00 -1.54706819e-01  0.00000000e+00  0.00000000e+00
  8.23723644e-33  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -9.96948228e-01  0.00000000e+00  0.00000000e+00
  0.00000000e+00  4.34646885e-15  0.00000000e+00 -1.06496708e-14
  0.00000000e+00  1.40875894e-02  0.00000000e+00  0.00000000e+00
 -9.10721322e-02  0.00000000e+00 -4.51564678e-03  0.00000000e+00
 -1.06039700e-01  0.00000000e+00  0.00000000e+00  1.73847113e+00
 -1.73847113e+00  7.60714271e-01 -7.60714271e-01  2.18756096e+00
 -2.18756096e+00 -2.31782850e-16  3.34373779e-16  0.00000000e+00
  0.00000000e+00  1.55199172e+00 -1.55199172e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  4.36443140e-34  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00  5.41759527e+00 -5.41759527e+00  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  0.00000000e+00 -9.89387807e-16  1.45669181e-15  0.00000000e+00
  0.00000000e+00 -1.86060812e-15  2.78302143e-15  0.00000000e+00
  0.00000000e+00  4.12277929e-01 -4.12277929e-01  0.00000000e+00
  0.00000000e+00  0.00000000e+00  0.00000000e+00  8.10957111e-01
 -8.10957111e-01  0.00000000e+00  0.00000000e+00  1.27141312e-01
 -1.27141312e-01  0.00000000e+00  0.00000000e+00  9.86802382e-01
 -9.86802382e-01 -1.91888898e-01  1.91888898e-01]

