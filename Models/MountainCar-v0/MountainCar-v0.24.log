LOGGER started at 2020-01-27 13:59:09.957224.
Currently active debug channels:
	rollouts
	training
	batch_info
	linesearch
	learning
	thread_rollouts
[2020-01-27 13:59:10.143755][__main__.TRPOAgent.log][learning]: Episode #0

[2020-01-27 13:59:10.479537][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 1000

[2020-01-27 13:59:10.515807][Environment.Environment.log][rollouts]: Rollout thread #1

[2020-01-27 13:59:10.516794][Environment.Environment.log][rollouts]: Rollout thread #2

[2020-01-27 13:59:10.516668][Environment.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-27 13:59:10.518585][Environment.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-27 13:59:32.895446][Environment.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 1367

[2020-01-27 13:59:42.496110][Environment.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 2987

[2020-01-27 13:59:42.496756][Environment.Environment.log][rollouts]: Rollout thread #3

[2020-01-27 13:59:42.503548][Environment.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-27 13:59:42.503651][Environment.Environment.log][rollouts]: Rollout thread #4

[2020-01-27 13:59:42.505642][Environment.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-27 13:59:59.777325][Environment.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 3424

[2020-01-27 14:00:15.434073][Environment.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 2564

[2020-01-27 14:00:15.434475][Environment.Environment.log][rollouts]: Rollout thread #5

[2020-01-27 14:00:15.435128][Environment.Environment.log][rollouts]: Rollout thread #6

[2020-01-27 14:00:15.435053][Environment.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-27 14:00:15.436137][Environment.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-27 14:00:38.831984][Environment.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 1303

[2020-01-27 14:00:39.706967][Environment.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 2151

[2020-01-27 14:00:39.707445][Environment.Environment.log][rollouts]: Rollout thread #7

[2020-01-27 14:00:39.708024][Environment.Environment.log][rollouts]: Rollout thread #8

[2020-01-27 14:00:39.707968][Environment.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-27 14:00:39.709098][Environment.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-27 14:01:20.644370][Environment.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 2950

[2020-01-27 14:01:23.842090][Environment.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 1476

[2020-01-27 14:01:23.842523][Environment.Environment.log][rollouts]: Rollout thread #9

[2020-01-27 14:01:23.843355][Environment.Environment.log][rollouts]: Rollout thread #10

[2020-01-27 14:01:23.843262][Environment.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-27 14:01:23.844236][Environment.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-27 14:01:50.265267][Environment.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 1726

[2020-01-27 14:02:44.134568][Environment.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 1649

[2020-01-27 14:02:44.135162][Environment.Environment.log][rollouts]: Rollout thread #11

[2020-01-27 14:02:44.141982][Environment.Environment.log][thread_rollouts]: Thread number: 10

[2020-01-27 14:02:44.142076][Environment.Environment.log][rollouts]: Rollout thread #12

[2020-01-27 14:02:44.145245][Environment.Environment.log][thread_rollouts]: Thread number: 11

[2020-01-27 14:02:49.520384][Environment.Environment.log][thread_rollouts]: Thread number: 10, Steps performed: 2296

[2020-01-27 14:02:57.559151][Environment.Environment.log][thread_rollouts]: Thread number: 11, Steps performed: 1363

[2020-01-27 14:02:57.559618][Environment.Environment.log][rollouts]: Rollout thread #13

[2020-01-27 14:02:57.560378][Environment.Environment.log][thread_rollouts]: Thread number: 12

[2020-01-27 14:02:57.560432][Environment.Environment.log][rollouts]: Rollout thread #14

[2020-01-27 14:02:57.562254][Environment.Environment.log][thread_rollouts]: Thread number: 13

[2020-01-27 14:03:05.211262][Environment.Environment.log][thread_rollouts]: Thread number: 13, Steps performed: 3032

[2020-01-27 14:03:12.957531][Environment.Environment.log][thread_rollouts]: Thread number: 12, Steps performed: 2353

[2020-01-27 14:03:12.958139][Environment.Environment.log][rollouts]: Rollout thread #15

[2020-01-27 14:03:12.958848][Environment.Environment.log][rollouts]: Rollout thread #16

[2020-01-27 14:03:12.958776][Environment.Environment.log][thread_rollouts]: Thread number: 14

[2020-01-27 14:03:12.959929][Environment.Environment.log][thread_rollouts]: Thread number: 15

[2020-01-27 14:04:03.513858][Environment.Environment.log][thread_rollouts]: Thread number: 14, Steps performed: 3006

[2020-01-27 14:04:22.128230][Environment.Environment.log][thread_rollouts]: Thread number: 15, Steps performed: 1889

[2020-01-27 14:04:22.128718][Environment.Environment.log][rollouts]: Rollout thread #17

[2020-01-27 14:04:22.129401][Environment.Environment.log][rollouts]: Rollout thread #18

[2020-01-27 14:04:22.129337][Environment.Environment.log][thread_rollouts]: Thread number: 16

[2020-01-27 14:04:22.130477][Environment.Environment.log][thread_rollouts]: Thread number: 17

[2020-01-27 14:04:36.674457][Environment.Environment.log][thread_rollouts]: Thread number: 17, Steps performed: 829

[2020-01-27 14:04:40.265640][Environment.Environment.log][thread_rollouts]: Thread number: 16, Steps performed: 3727

[2020-01-27 14:04:40.266055][Environment.Environment.log][rollouts]: Rollout thread #19

[2020-01-27 14:04:40.272925][Environment.Environment.log][thread_rollouts]: Thread number: 18

[2020-01-27 14:04:40.273020][Environment.Environment.log][rollouts]: Rollout thread #20

[2020-01-27 14:04:40.275233][Environment.Environment.log][thread_rollouts]: Thread number: 19

[2020-01-27 14:04:45.348649][Environment.Environment.log][thread_rollouts]: Thread number: 19, Steps performed: 1673

[2020-01-27 14:04:57.142655][Environment.Environment.log][thread_rollouts]: Thread number: 18, Steps performed: 2468

[2020-01-27 14:04:57.143105][Environment.Environment.log][rollouts]: Rollout thread #21

[2020-01-27 14:04:57.143866][Environment.Environment.log][rollouts]: Rollout thread #22

[2020-01-27 14:04:57.143777][Environment.Environment.log][thread_rollouts]: Thread number: 20

[2020-01-27 14:04:57.145244][Environment.Environment.log][thread_rollouts]: Thread number: 21

[2020-01-27 14:05:11.758173][Environment.Environment.log][thread_rollouts]: Thread number: 20, Steps performed: 1202

[2020-01-27 14:05:28.260039][Environment.Environment.log][thread_rollouts]: Thread number: 21, Steps performed: 3361

[2020-01-27 14:05:28.260484][Environment.Environment.log][rollouts]: Rollout thread #23

[2020-01-27 14:05:28.261340][Environment.Environment.log][rollouts]: Rollout thread #24

[2020-01-27 14:05:28.261114][Environment.Environment.log][thread_rollouts]: Thread number: 22

[2020-01-27 14:05:28.262331][Environment.Environment.log][thread_rollouts]: Thread number: 23

[2020-01-27 14:05:37.289138][Environment.Environment.log][thread_rollouts]: Thread number: 23, Steps performed: 3195

[2020-01-27 14:05:51.017736][Environment.Environment.log][thread_rollouts]: Thread number: 22, Steps performed: 2131

[2020-01-27 14:05:51.018203][Environment.Environment.log][rollouts]: Rollout thread #25

[2020-01-27 14:05:51.018917][Environment.Environment.log][thread_rollouts]: Thread number: 24

[2020-01-27 14:05:55.673829][Environment.Environment.log][thread_rollouts]: Thread number: 24, Steps performed: 3793

[2020-01-27 14:05:55.674236][__main__.TRPOAgent.log][rollouts]: Unpacking actions

[2020-01-27 14:05:55.689512][__main__.TRPOAgent.log][rollouts]: Unpacking rewards

[2020-01-27 14:05:56.579517][__main__.TRPOAgent.log][rollouts]: Unpacking observations

[2020-01-27 14:05:56.587594][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-27 14:05:56.588994][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 57915, Batch size: 4500, Number of batches: 13

[2020-01-27 14:05:56.589362][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-27 14:05:56.625369][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 4500

[2020-01-27 14:06:00.852759][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00465857  0.02376182  0.05112672 ...  0.49621085 -0.11769588
 -0.37851497]

[2020-01-27 14:06:00.853154][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-27 14:06:01.302026][__main__.TRPOAgent.log][training]: gradient_step_direction: tf.Tensor(
[-0.28421431  0.43499475 13.55338187 ...  2.51457275 -2.77304798
  0.25847523], shape=(4547,), dtype=float64)

[2020-01-27 14:06:01.391752][__main__.TRPOAgent.log][linesearch]: improvement: 0.17636125378683687

[2020-01-27 14:06:01.421076][__main__.TRPOAgent.log][linesearch]: improvement: 0.07020647746085729

[2020-01-27 14:06:01.448527][__main__.TRPOAgent.log][linesearch]: improvement: 0.04328334809449075

[2020-01-27 14:06:01.477502][__main__.TRPOAgent.log][linesearch]: improvement: 0.025725051897012463

[2020-01-27 14:06:01.505232][__main__.TRPOAgent.log][linesearch]: improvement: 0.01749071551233783

[2020-01-27 14:06:01.535575][__main__.TRPOAgent.log][linesearch]: improvement: 0.016749122042753584

[2020-01-27 14:06:01.559161][__main__.TRPOAgent.log][linesearch]: improvement: 0.014138556568681793

[2020-01-27 14:06:01.589478][__main__.TRPOAgent.log][linesearch]: improvement: 0.010523450457810668

[2020-01-27 14:06:01.615523][__main__.TRPOAgent.log][linesearch]: improvement: 0.008535499504048971

[2020-01-27 14:06:01.645183][__main__.TRPOAgent.log][linesearch]: improvement: 0.00647169665138847

[2020-01-27 14:06:01.645631][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 5.718235063829686e-07, Discarded policy loss value: -97.79872872380578

[2020-01-27 14:06:02.818090][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 121.72090375409131

[2020-01-27 14:06:02.824192][__main__.TRPOAgent.log][batch_info]: Batch #1, batch length: 4500

[2020-01-27 14:06:07.578796][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00028391  0.00680035  0.00065911 ...  0.18712466 -0.10898582
 -0.07813884]

[2020-01-27 14:06:07.579204][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-27 14:06:08.046262][__main__.TRPOAgent.log][training]: gradient_step_direction: tf.Tensor(
[ 0.17150348  0.05788539 -0.41934819 ...  1.54355068 -0.61593718
 -0.9276135 ], shape=(4547,), dtype=float64)

[2020-01-27 14:06:08.136757][__main__.TRPOAgent.log][linesearch]: improvement: 0.067144773013331

[2020-01-27 14:06:08.163190][__main__.TRPOAgent.log][linesearch]: improvement: 0.039632804684986755

[2020-01-27 14:06:08.190466][__main__.TRPOAgent.log][linesearch]: improvement: 0.02285371932250868

[2020-01-27 14:06:08.220259][__main__.TRPOAgent.log][linesearch]: improvement: 0.01357641663136988

[2020-01-27 14:06:08.246506][__main__.TRPOAgent.log][linesearch]: improvement: 0.00827925242041161

[2020-01-27 14:06:08.276182][__main__.TRPOAgent.log][linesearch]: improvement: 0.00566646371993329

[2020-01-27 14:06:08.305031][__main__.TRPOAgent.log][linesearch]: improvement: 0.0036985258807060717

[2020-01-27 14:06:08.330125][__main__.TRPOAgent.log][linesearch]: improvement: 0.002393433464858319

[2020-01-27 14:06:08.360422][__main__.TRPOAgent.log][linesearch]: improvement: 0.001576399547778884

[2020-01-27 14:06:08.389425][__main__.TRPOAgent.log][linesearch]: improvement: 0.0010681804626146985

[2020-01-27 14:06:08.389858][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.109709396055219e-07, Discarded policy loss value: -3.9353381552499074

[2020-01-27 14:06:09.177441][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 129.76159820382426

[2020-01-27 14:06:09.183123][__main__.TRPOAgent.log][batch_info]: Batch #2, batch length: 4500

[2020-01-27 14:06:13.678752][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.0007066  -0.04496789 -0.00079075 ... -0.11296833  0.27815188
 -0.16518355]

[2020-01-27 14:06:13.679153][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-27 14:06:14.097768][__main__.TRPOAgent.log][training]: gradient_step_direction: tf.Tensor(
[ 0.17962584 -0.12473397 -0.60007987 ... -0.94411909 -0.3184593
  1.26257839], shape=(4547,), dtype=float64)

[2020-01-27 14:06:14.184330][__main__.TRPOAgent.log][linesearch]: improvement: 0.14013131009046642

[2020-01-27 14:06:14.213498][__main__.TRPOAgent.log][linesearch]: improvement: 0.07852035719008654

[2020-01-27 14:06:14.242988][__main__.TRPOAgent.log][linesearch]: improvement: 0.057460171301249474

[2020-01-27 14:06:14.270555][__main__.TRPOAgent.log][linesearch]: improvement: 0.04154591917262351

[2020-01-27 14:06:14.297852][__main__.TRPOAgent.log][linesearch]: improvement: 0.02556648832657249

[2020-01-27 14:06:14.325272][__main__.TRPOAgent.log][linesearch]: improvement: 0.014319538424058642

[2020-01-27 14:06:14.356487][__main__.TRPOAgent.log][linesearch]: improvement: 0.008632610241993355

[2020-01-27 14:06:14.382594][__main__.TRPOAgent.log][linesearch]: improvement: 0.0051477195167715095

[2020-01-27 14:06:14.411964][__main__.TRPOAgent.log][linesearch]: improvement: 0.002923668445796057

[2020-01-27 14:06:14.441541][__main__.TRPOAgent.log][linesearch]: improvement: 0.0015821157268449682

[2020-01-27 14:06:14.442035][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 1.2753375491809741e-06, Discarded policy loss value: -2.9496267263162568

[2020-01-27 14:06:15.211335][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 205.56456247786411

[2020-01-27 14:06:15.218228][__main__.TRPOAgent.log][batch_info]: Batch #3, batch length: 4500

[2020-01-27 14:06:19.488160][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.0003806   0.00323244  0.0004439  ... -0.07820766  0.04767564
  0.03053201]

[2020-01-27 14:06:19.488563][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-27 14:06:19.915479][__main__.TRPOAgent.log][training]: gradient_step_direction: tf.Tensor(
[ 0.03821844  0.99082391 -0.82224007 ...  0.54682243  1.00891957
 -1.555742  ], shape=(4547,), dtype=float64)

[2020-01-27 14:06:20.010559][__main__.TRPOAgent.log][linesearch]: improvement: 0.12141695296224708

[2020-01-27 14:06:20.033938][__main__.TRPOAgent.log][linesearch]: improvement: 0.05833207155688436

[2020-01-27 14:06:20.063524][__main__.TRPOAgent.log][linesearch]: improvement: 0.029944282769526542

[2020-01-27 14:06:20.091574][__main__.TRPOAgent.log][linesearch]: improvement: 0.01844348665455564

[2020-01-27 14:06:20.117173][__main__.TRPOAgent.log][linesearch]: improvement: 0.011765837389482892

[2020-01-27 14:06:20.144511][__main__.TRPOAgent.log][linesearch]: improvement: 0.008020672132490692

[2020-01-27 14:06:20.175027][__main__.TRPOAgent.log][linesearch]: improvement: 0.005772731105094353

[2020-01-27 14:06:20.199617][__main__.TRPOAgent.log][linesearch]: improvement: 0.003684153786511546

[2020-01-27 14:06:20.227383][__main__.TRPOAgent.log][linesearch]: improvement: 0.0019831183647616157

[2020-01-27 14:06:20.257828][__main__.TRPOAgent.log][linesearch]: improvement: 0.0010532211073801534

[2020-01-27 14:06:20.258266][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 4.2175540709633065e-06, Discarded policy loss value: -0.8796563042046817

[2020-01-27 14:06:21.052324][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 274.96199358565104

[2020-01-27 14:06:21.058442][__main__.TRPOAgent.log][batch_info]: Batch #4, batch length: 4500

[2020-01-27 14:06:25.336138][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00061976  0.00560968  0.00230041 ...  0.12545051 -0.02860255
 -0.09684796]

[2020-01-27 14:06:25.336701][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-27 14:06:25.797861][__main__.TRPOAgent.log][training]: gradient_step_direction: tf.Tensor(
[-4.29853683 14.11794314 16.30654075 ... -8.56738174 -4.67879457
 13.24617631], shape=(4547,), dtype=float64)

[2020-01-27 14:06:25.850755][__main__.TRPOAgent.log][batch_info]: Batch #5, batch length: 4500

[2020-01-27 14:06:30.193965][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.00200089 -0.03391719 -0.00171932 ... -0.11566854  0.18577018
 -0.07010163]

[2020-01-27 14:06:30.194462][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-27 14:06:30.611375][__main__.TRPOAgent.log][training]: gradient_step_direction: tf.Tensor(
[ 0.58636469  0.38556037 -0.78185165 ... -0.17526787 -0.64845945
  0.82372732], shape=(4547,), dtype=float64)

[2020-01-27 14:06:30.700019][__main__.TRPOAgent.log][linesearch]: improvement: 0.07572770922472083

[2020-01-27 14:06:30.730513][__main__.TRPOAgent.log][linesearch]: improvement: 0.03197351898319267

[2020-01-27 14:06:30.754772][__main__.TRPOAgent.log][linesearch]: improvement: 0.013687728030939539

[2020-01-27 14:06:30.782576][__main__.TRPOAgent.log][linesearch]: improvement: 0.007435407327387011

[2020-01-27 14:06:30.810423][__main__.TRPOAgent.log][linesearch]: improvement: 0.007171362130189429

[2020-01-27 14:06:30.835334][__main__.TRPOAgent.log][linesearch]: improvement: 0.00526059231504572

[2020-01-27 14:06:30.864138][__main__.TRPOAgent.log][linesearch]: improvement: 0.00344124573365745

[2020-01-27 14:06:30.891215][__main__.TRPOAgent.log][linesearch]: improvement: 0.0022659165848586404

[2020-01-27 14:06:30.917966][__main__.TRPOAgent.log][linesearch]: improvement: 0.0013734356984382856

[2020-01-27 14:06:30.946420][__main__.TRPOAgent.log][linesearch]: improvement: 0.000864845408703907

[2020-01-27 14:06:30.946873][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 7.408024375055113e-07, Discarded policy loss value: -2.6155876973444987

[2020-01-27 14:06:31.743531][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 100.95553638097005

[2020-01-27 14:06:31.748840][__main__.TRPOAgent.log][batch_info]: Batch #6, batch length: 4500

[2020-01-27 14:06:36.024711][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.00134307  0.02646667 -0.0021866  ...  0.2031194  -0.14073019
 -0.06238921]

[2020-01-27 14:06:36.025134][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-27 14:06:36.471050][__main__.TRPOAgent.log][training]: gradient_step_direction: tf.Tensor(
[ 0.53742668 -0.31315836  0.44137154 ...  0.62855579  2.11621138
 -2.74476716], shape=(4547,), dtype=float64)

[2020-01-27 14:06:36.561920][__main__.TRPOAgent.log][linesearch]: improvement: -0.1831305502950889

[2020-01-27 14:06:36.587115][__main__.TRPOAgent.log][linesearch]: improvement: -0.05069611715385957

[2020-01-27 14:06:36.615366][__main__.TRPOAgent.log][linesearch]: improvement: -0.003998286882420973

[2020-01-27 14:06:36.645397][__main__.TRPOAgent.log][linesearch]: improvement: 0.008045645214039193

[2020-01-27 14:06:36.671494][__main__.TRPOAgent.log][linesearch]: improvement: 0.009007313776878426

[2020-01-27 14:06:36.701824][__main__.TRPOAgent.log][linesearch]: improvement: 0.006631265405148301

[2020-01-27 14:06:36.730591][__main__.TRPOAgent.log][linesearch]: improvement: 0.004573278224069735

[2020-01-27 14:06:36.754393][__main__.TRPOAgent.log][linesearch]: improvement: 0.003033880316882148

[2020-01-27 14:06:36.780653][__main__.TRPOAgent.log][linesearch]: improvement: 0.0018101511703222661

[2020-01-27 14:06:36.812507][__main__.TRPOAgent.log][linesearch]: improvement: 0.0011779766143093784

[2020-01-27 14:06:36.812957][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 5.570176422132223e-07, Discarded policy loss value: -0.06293036825404871

[2020-01-27 14:06:37.604169][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 191.55671793854282

[2020-01-27 14:06:37.610170][__main__.TRPOAgent.log][batch_info]: Batch #7, batch length: 4500

[2020-01-27 14:06:41.809576][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.00028855  0.01383979 -0.0012096  ...  0.156744    0.01849403
 -0.17523803]

[2020-01-27 14:06:41.809988][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-27 14:06:42.243606][__main__.TRPOAgent.log][training]: gradient_step_direction: tf.Tensor(
[ 0.04316654  0.12616237 -0.28411581 ... -0.0731951  -0.4699732
  0.5431683 ], shape=(4547,), dtype=float64)

[2020-01-27 14:06:42.339691][__main__.TRPOAgent.log][linesearch]: improvement: 0.02278902061618826

[2020-01-27 14:06:42.369553][__main__.TRPOAgent.log][linesearch]: improvement: 0.0023164769318286815

[2020-01-27 14:06:42.370041][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New policy loss value: 5.670618602540929

[2020-01-27 14:06:43.176779][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 208.97263138813662

[2020-01-27 14:06:43.177190][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-27 14:06:43.184905][__main__.TRPOAgent.log][batch_info]: Batch #8, batch length: 4500

[2020-01-27 14:06:47.313764][__main__.TRPOAgent.log][training]: policy_gradient: [ 1.16624004e-04  0.00000000e+00  2.73438716e-02 ... -3.04776442e-02
  2.07619753e-01 -1.77142109e-01]

[2020-01-27 14:06:47.314176][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-27 14:06:47.725802][__main__.TRPOAgent.log][training]: gradient_step_direction: tf.Tensor(
[ 0.02883507  0.          0.18162574 ...  0.36102102 -0.42915169
  0.06813068], shape=(4547,), dtype=float64)

[2020-01-27 14:06:47.810826][__main__.TRPOAgent.log][linesearch]: improvement: -0.018754595818834652

[2020-01-27 14:06:47.839356][__main__.TRPOAgent.log][linesearch]: improvement: -0.007644692725841118

[2020-01-27 14:06:47.867365][__main__.TRPOAgent.log][linesearch]: improvement: 0.00018834932345868083

[2020-01-27 14:06:47.895321][__main__.TRPOAgent.log][linesearch]: improvement: 0.0036511815020077165

[2020-01-27 14:06:47.920954][__main__.TRPOAgent.log][linesearch]: improvement: 0.004022023458756685

[2020-01-27 14:06:47.950639][__main__.TRPOAgent.log][linesearch]: improvement: 0.003538572314093713

[2020-01-27 14:06:47.978346][__main__.TRPOAgent.log][linesearch]: improvement: 0.003906666660019376

[2020-01-27 14:06:48.004271][__main__.TRPOAgent.log][linesearch]: improvement: 0.0032225379321655367

[2020-01-27 14:06:48.031864][__main__.TRPOAgent.log][linesearch]: improvement: 0.0021073283969776924

[2020-01-27 14:06:48.057235][__main__.TRPOAgent.log][linesearch]: improvement: 0.001479991034984529

[2020-01-27 14:06:48.057727][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 5.774538335776727e-07, Discarded policy loss value: -6.331224376809256

[2020-01-27 14:06:48.848364][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 294.9688151521445

[2020-01-27 14:06:48.853380][__main__.TRPOAgent.log][batch_info]: Batch #9, batch length: 4500

[2020-01-27 14:06:52.937229][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.00082788  0.         -0.02045548 ...  0.17129104 -0.07012387
 -0.10116717]

[2020-01-27 14:06:52.937619][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-27 14:06:53.355475][__main__.TRPOAgent.log][training]: gradient_step_direction: tf.Tensor(
[ 0.82948774  0.         -1.68938772 ...  0.07672932  0.5496739
 -0.62640322], shape=(4547,), dtype=float64)

[2020-01-27 14:06:53.439633][__main__.TRPOAgent.log][linesearch]: improvement: -0.038182586293756815

[2020-01-27 14:06:53.469640][__main__.TRPOAgent.log][linesearch]: improvement: -0.011084703456632261

[2020-01-27 14:06:53.499963][__main__.TRPOAgent.log][linesearch]: improvement: 0.001088905052200717

[2020-01-27 14:06:53.524653][__main__.TRPOAgent.log][linesearch]: improvement: 0.003223250187633364

[2020-01-27 14:06:53.552286][__main__.TRPOAgent.log][linesearch]: improvement: 0.0042154262893400185

[2020-01-27 14:06:53.580603][__main__.TRPOAgent.log][linesearch]: improvement: 0.005178797043383976

[2020-01-27 14:06:53.608119][__main__.TRPOAgent.log][linesearch]: improvement: 0.004378942093810512

[2020-01-27 14:06:53.636781][__main__.TRPOAgent.log][linesearch]: improvement: 0.0035275583715974612

[2020-01-27 14:06:53.667374][__main__.TRPOAgent.log][linesearch]: improvement: 0.0024516102654832395

[2020-01-27 14:06:53.692377][__main__.TRPOAgent.log][linesearch]: improvement: 0.0016118289183192358

[2020-01-27 14:06:53.693068][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.407756850728147e-07, Discarded policy loss value: -0.9318858330321853

[2020-01-27 14:06:54.479563][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 199.52792494025883

[2020-01-27 14:06:54.484881][__main__.TRPOAgent.log][batch_info]: Batch #10, batch length: 4500

[2020-01-27 14:06:58.497370][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00032295  0.          0.00312767 ...  0.10877183  0.09832004
 -0.20709187]

[2020-01-27 14:06:58.497757][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-27 14:06:58.913578][__main__.TRPOAgent.log][training]: gradient_step_direction: tf.Tensor(
[ 0.11747215  0.          0.76140563 ... -0.29883508 -0.9919716
  1.29080669], shape=(4547,), dtype=float64)

[2020-01-27 14:06:59.004276][__main__.TRPOAgent.log][linesearch]: improvement: 0.139469199817571

[2020-01-27 14:06:59.034807][__main__.TRPOAgent.log][linesearch]: improvement: 0.06474526692116633

[2020-01-27 14:06:59.060736][__main__.TRPOAgent.log][linesearch]: improvement: 0.032649179035938225

[2020-01-27 14:06:59.087954][__main__.TRPOAgent.log][linesearch]: improvement: 0.02058889742587766

[2020-01-27 14:06:59.119093][__main__.TRPOAgent.log][linesearch]: improvement: 0.013711246547159384

[2020-01-27 14:06:59.145915][__main__.TRPOAgent.log][linesearch]: improvement: 0.009603261366118332

[2020-01-27 14:06:59.171478][__main__.TRPOAgent.log][linesearch]: improvement: 0.007046171995294337

[2020-01-27 14:06:59.201223][__main__.TRPOAgent.log][linesearch]: improvement: 0.004862148430483604

[2020-01-27 14:06:59.226739][__main__.TRPOAgent.log][linesearch]: improvement: 0.0031509010658603565

[2020-01-27 14:06:59.253910][__main__.TRPOAgent.log][linesearch]: improvement: 0.0019870301652891165

[2020-01-27 14:06:59.254397][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 6.745439539708424e-07, Discarded policy loss value: -2.254729200747231

[2020-01-27 14:07:00.076207][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 202.88322630764156

[2020-01-27 14:07:00.083693][__main__.TRPOAgent.log][batch_info]: Batch #11, batch length: 4500

[2020-01-27 14:07:03.572440][__main__.TRPOAgent.log][training]: policy_gradient: [-0.00124474  0.          0.04368688 ... -0.19472543  0.17314382
  0.0215816 ]

[2020-01-27 14:07:03.572829][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-27 14:07:03.963383][__main__.TRPOAgent.log][training]: gradient_step_direction: tf.Tensor(
[-0.40792628  0.         -0.69675512 ... -0.47111505  0.85011131
 -0.37899626], shape=(4547,), dtype=float64)

[2020-01-27 14:07:04.042760][__main__.TRPOAgent.log][linesearch]: improvement: -0.04280878042613101

[2020-01-27 14:07:04.043217][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New policy loss value: 1.3794009284381101

[2020-01-27 14:07:04.893796][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 202.6376487034819

[2020-01-27 14:07:04.894185][__main__.TRPOAgent.log][linesearch]: Linesearch successful, updating policy parameters

[2020-01-27 14:07:04.902511][__main__.TRPOAgent.log][batch_info]: Batch #12, batch length: 3915

[2020-01-27 14:07:08.804426][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.          0.          0.         ...  0.13040846  0.0823922
 -0.21280066]

[2020-01-27 14:07:08.804823][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-27 14:07:09.161171][__main__.TRPOAgent.log][training]: gradient_step_direction: tf.Tensor(
[ 0.          0.          0.         ... -0.20634899  1.02279855
 -0.81644956], shape=(4547,), dtype=float64)

[2020-01-27 14:07:09.233334][__main__.TRPOAgent.log][linesearch]: improvement: 0.2292586751422645

[2020-01-27 14:07:09.258937][__main__.TRPOAgent.log][linesearch]: improvement: 0.14681714694101988

[2020-01-27 14:07:09.286357][__main__.TRPOAgent.log][linesearch]: improvement: 0.08611726469871683

[2020-01-27 14:07:09.311453][__main__.TRPOAgent.log][linesearch]: improvement: 0.04973074455566828

[2020-01-27 14:07:09.337943][__main__.TRPOAgent.log][linesearch]: improvement: 0.028599196619670586

[2020-01-27 14:07:09.360107][__main__.TRPOAgent.log][linesearch]: improvement: 0.016329662867207384

[2020-01-27 14:07:09.385392][__main__.TRPOAgent.log][linesearch]: improvement: 0.009148214072675076

[2020-01-27 14:07:09.407920][__main__.TRPOAgent.log][linesearch]: improvement: 0.005373479964775885

[2020-01-27 14:07:09.431848][__main__.TRPOAgent.log][linesearch]: improvement: 0.003341906347620438

[2020-01-27 14:07:09.455324][__main__.TRPOAgent.log][linesearch]: improvement: 0.0021184337785288276

[2020-01-27 14:07:09.455773][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: 9.454952466009701e-07, Discarded policy loss value: -0.5342100897789744

[2020-01-27 14:07:10.057410][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 217.4350248744952

[2020-01-27 14:07:10.062779][__main__.TRPOAgent.log][learning]: Episode #1

[2020-01-27 14:07:10.063131][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 1000

[2020-01-27 14:07:10.124650][Environment.Environment.log][rollouts]: Rollout thread #1

[2020-01-27 14:07:10.125269][Environment.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-27 14:07:10.125368][Environment.Environment.log][rollouts]: Rollout thread #2

[2020-01-27 14:07:10.127923][Environment.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-27 14:07:12.423958][Environment.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 1000

[2020-01-27 14:07:12.455252][Environment.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 1000

[2020-01-27 14:07:12.455756][Environment.Environment.log][rollouts]: Rollout thread #3

[2020-01-27 14:07:12.456430][Environment.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-27 14:07:12.456580][Environment.Environment.log][rollouts]: Rollout thread #4

[2020-01-27 14:07:12.458983][Environment.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-27 14:07:14.769034][Environment.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 1000

[2020-01-27 14:07:14.784602][Environment.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 1000

[2020-01-27 14:07:14.785306][Environment.Environment.log][rollouts]: Rollout thread #5

[2020-01-27 14:07:14.786672][Environment.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-27 14:07:14.786807][Environment.Environment.log][rollouts]: Rollout thread #6

[2020-01-27 14:07:14.789523][Environment.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-27 14:07:17.135022][Environment.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 1000

[2020-01-27 14:07:17.136679][Environment.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 1000

[2020-01-27 14:07:17.137549][Environment.Environment.log][rollouts]: Rollout thread #7

[2020-01-27 14:07:17.138052][Environment.Environment.log][rollouts]: Rollout thread #8

[2020-01-27 14:07:17.137994][Environment.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-27 14:07:17.139034][Environment.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-27 14:07:19.323823][Environment.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 1000

[2020-01-27 14:07:19.369373][Environment.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 1000

[2020-01-27 14:07:19.369845][Environment.Environment.log][rollouts]: Rollout thread #9

[2020-01-27 14:07:19.370425][Environment.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-27 14:07:19.370553][Environment.Environment.log][rollouts]: Rollout thread #10

[2020-01-27 14:07:19.372342][Environment.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-27 14:07:22.029491][Environment.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 1000

[2020-01-27 14:07:22.058038][Environment.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 1000

