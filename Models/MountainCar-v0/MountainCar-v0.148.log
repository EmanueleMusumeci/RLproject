LOGGER started at 2020-01-31 15:52:52.668490.
Currently active debug channels:
	act
	batch_info
	linesearch
	learning
	thread_rollouts
[2020-01-31 15:52:53.090684][__main__.TRPOAgent.log][learning]: Episode #0

[2020-01-31 15:52:53.272637][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 2000

[2020-01-31 15:52:53.279904][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-31 15:52:53.279663][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-31 15:52:58.004151][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 2000

[2020-01-31 15:52:58.011671][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 2000

[2020-01-31 15:52:58.012270][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-31 15:52:58.012521][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-31 15:53:02.709852][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 2000

[2020-01-31 15:53:02.802717][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 2000

[2020-01-31 15:53:02.803396][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-31 15:53:02.803535][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-31 15:53:07.658301][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 1894

[2020-01-31 15:53:07.747375][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 2000

[2020-01-31 15:53:07.748015][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-31 15:53:07.748296][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-31 15:53:10.885674][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 1257

[2020-01-31 15:53:11.578037][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 2000

[2020-01-31 15:53:11.578883][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-31 15:53:11.578696][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-31 15:53:16.370545][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 2000

[2020-01-31 15:53:16.448550][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 2000

[2020-01-31 15:53:16.449147][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 10

[2020-01-31 15:53:16.449587][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 11

[2020-01-31 15:53:18.420209][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 10, Steps performed: 825

[2020-01-31 15:53:19.477155][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 11, Steps performed: 2000

[2020-01-31 15:53:19.478018][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 13

[2020-01-31 15:53:19.477861][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 12

[2020-01-31 15:53:24.281704][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 13, Steps performed: 2000

[2020-01-31 15:53:24.349966][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 12, Steps performed: 2000

[2020-01-31 15:53:24.350653][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 14

[2020-01-31 15:53:26.288976][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 14, Steps performed: 2000

[2020-01-31 15:53:26.319919][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-31 15:53:26.320381][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 27976, Batch size: 4000

[2020-01-31 15:53:26.320895][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-31 15:53:31.790533][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 27976, Batch size: 4000, Number of batches: 7

[2020-01-31 15:53:31.790939][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-31 15:53:31.791326][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 4000

[2020-01-31 15:53:32.498408][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: tf.Tensor(0.0, shape=(), dtype=float64), New policy loss value: tf.Tensor(0.009331528208563524, shape=(), dtype=float64)

[2020-01-31 15:53:32.498961][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0

[2020-01-31 15:53:32.502893][__main__.TRPOAgent.log][batch_info]: Batch #1, batch length: 4000

[2020-01-31 15:53:33.207881][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: tf.Tensor(0.0, shape=(), dtype=float64), New policy loss value: tf.Tensor(0.013064474308436203, shape=(), dtype=float64)

[2020-01-31 15:53:33.208386][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0

[2020-01-31 15:53:33.211253][__main__.TRPOAgent.log][batch_info]: Batch #2, batch length: 4000

[2020-01-31 15:53:34.593969][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: tf.Tensor(0.0, shape=(), dtype=float64), Discarded policy loss value: tf.Tensor(-0.011426795381401693, shape=(), dtype=float64)

[2020-01-31 15:53:34.594540][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0

[2020-01-31 15:53:34.598053][__main__.TRPOAgent.log][batch_info]: Batch #3, batch length: 4000

[2020-01-31 15:53:35.945789][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: tf.Tensor(0.0, shape=(), dtype=float64), Discarded policy loss value: tf.Tensor(-0.05882125680573572, shape=(), dtype=float64)

[2020-01-31 15:53:35.946381][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0

[2020-01-31 15:53:35.949157][__main__.TRPOAgent.log][batch_info]: Batch #4, batch length: 4000

[2020-01-31 15:53:36.778519][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: tf.Tensor(0.0, shape=(), dtype=float64), New policy loss value: tf.Tensor(0.08276139168457823, shape=(), dtype=float64)

[2020-01-31 15:53:36.778949][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0

[2020-01-31 15:53:36.781345][__main__.TRPOAgent.log][batch_info]: Batch #5, batch length: 4000

[2020-01-31 15:53:37.436876][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: tf.Tensor(0.0, shape=(), dtype=float64), New policy loss value: tf.Tensor(0.007854198082092685, shape=(), dtype=float64)

[2020-01-31 15:53:37.437494][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0

[2020-01-31 15:53:37.440475][__main__.TRPOAgent.log][batch_info]: Batch #6, batch length: 3976

[2020-01-31 15:53:38.100897][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: tf.Tensor(0.0, shape=(), dtype=float64), New policy loss value: tf.Tensor(0.01006166444848454, shape=(), dtype=float64)

[2020-01-31 15:53:38.101480][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0

[2020-01-31 15:54:12.594432][__main__.TRPOAgent.log][learning]: Episode #1

[2020-01-31 15:54:12.598028][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 2000

[2020-01-31 15:54:12.599995][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-31 15:54:12.601347][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-31 15:54:16.778019][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 2000

[2020-01-31 15:54:16.869040][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 2000

[2020-01-31 15:54:16.869941][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-31 15:54:16.869627][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-31 15:54:21.091545][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 2000

[2020-01-31 15:54:21.097500][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 2000

[2020-01-31 15:54:21.098081][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-31 15:54:21.098201][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-31 15:54:25.288427][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 2000

[2020-01-31 15:54:25.369136][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 2000

[2020-01-31 15:54:25.369968][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-31 15:54:25.369782][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-31 15:54:30.671989][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 2000

[2020-01-31 15:54:30.674777][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 2000

[2020-01-31 15:54:30.675855][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-31 15:54:30.675712][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-31 15:54:35.372279][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 2000

[2020-01-31 15:54:35.487971][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 2000

[2020-01-31 15:54:35.489013][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 11

[2020-01-31 15:54:35.488649][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 10

[2020-01-31 15:54:40.596373][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 10, Steps performed: 2000

[2020-01-31 15:54:40.657174][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 11, Steps performed: 2000

[2020-01-31 15:54:40.658017][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 13

[2020-01-31 15:54:40.657835][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 12

[2020-01-31 15:54:45.923627][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 13, Steps performed: 2000

[2020-01-31 15:54:45.994306][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 12, Steps performed: 2000

[2020-01-31 15:54:45.994970][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 14

[2020-01-31 15:54:48.298342][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 14, Steps performed: 2000

[2020-01-31 15:54:48.329460][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-31 15:54:48.329885][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 30000, Batch size: 4000

[2020-01-31 15:54:48.330147][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-31 15:54:54.987774][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 30000, Batch size: 4000, Number of batches: 8

[2020-01-31 15:54:54.988482][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-31 15:54:54.988974][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 4000

[2020-01-31 15:54:55.747589][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: tf.Tensor(0.0, shape=(), dtype=float64), New policy loss value: tf.Tensor(0.011961084305811606, shape=(), dtype=float64)

[2020-01-31 15:54:55.748490][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0

[2020-01-31 15:54:55.751815][__main__.TRPOAgent.log][batch_info]: Batch #1, batch length: 4000

[2020-01-31 15:54:56.378990][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: tf.Tensor(0.0, shape=(), dtype=float64), New policy loss value: tf.Tensor(0.007449008490732979, shape=(), dtype=float64)

[2020-01-31 15:54:56.379860][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0

[2020-01-31 15:54:56.382630][__main__.TRPOAgent.log][batch_info]: Batch #2, batch length: 4000

[2020-01-31 15:54:57.317420][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: tf.Tensor(0.0, shape=(), dtype=float64), New policy loss value: tf.Tensor(0.010651938320997754, shape=(), dtype=float64)

[2020-01-31 15:54:57.318400][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0

[2020-01-31 15:54:57.324064][__main__.TRPOAgent.log][batch_info]: Batch #3, batch length: 4000

[2020-01-31 15:54:58.614340][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: tf.Tensor(0.0, shape=(), dtype=float64), New policy loss value: tf.Tensor(0.010822068611538558, shape=(), dtype=float64)

[2020-01-31 15:54:58.615037][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0

[2020-01-31 15:54:58.618134][__main__.TRPOAgent.log][batch_info]: Batch #4, batch length: 4000

[2020-01-31 15:54:59.907566][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 1, New mean kl div: tf.Tensor(0.0, shape=(), dtype=float64), New policy loss value: tf.Tensor(0.0020855886371416625, shape=(), dtype=float64)

[2020-01-31 15:54:59.908252][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0

[2020-01-31 15:54:59.910712][__main__.TRPOAgent.log][batch_info]: Batch #5, batch length: 4000

[2020-01-31 15:55:01.136600][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: tf.Tensor(0.0, shape=(), dtype=float64), New policy loss value: tf.Tensor(0.036908655440909724, shape=(), dtype=float64)

[2020-01-31 15:55:01.137673][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0

[2020-01-31 15:55:01.140607][__main__.TRPOAgent.log][batch_info]: Batch #6, batch length: 4000

[2020-01-31 15:55:03.187389][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: tf.Tensor(0.0, shape=(), dtype=float64), New policy loss value: tf.Tensor(0.04016395009460999, shape=(), dtype=float64)

[2020-01-31 15:55:03.188068][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0

[2020-01-31 15:55:03.190518][__main__.TRPOAgent.log][batch_info]: Batch #7, batch length: 2000

[2020-01-31 15:55:05.195913][__main__.TRPOAgent.log][linesearch]: Linesearch worked at 0, New mean kl div: tf.Tensor(0.0, shape=(), dtype=float64), New policy loss value: tf.Tensor(0.0025627799548015827, shape=(), dtype=float64)

[2020-01-31 15:55:05.196605][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 0

