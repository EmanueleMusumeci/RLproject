LOGGER started at 2020-01-28 17:27:02.645221.
Currently active debug channels:
	rollouts
	act
	training
	batch_info
	linesearch
	learning
	thread_rollouts
[2020-01-28 17:27:03.143551][__main__.TRPOAgent.log][learning]: Episode #0

[2020-01-28 17:27:03.445076][__main__.TRPOAgent.log][learning]: Performing rollouts: rollout length: 1000

[2020-01-28 17:27:03.474811][EnvironmentNew.Environment.log][rollouts]: Rollout thread #1

[2020-01-28 17:27:03.475732][EnvironmentNew.Environment.log][rollouts]: Rollout thread #2

[2020-01-28 17:27:03.475661][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0

[2020-01-28 17:27:03.482339][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1

[2020-01-28 17:27:06.063559][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 0, Steps performed: 1000

[2020-01-28 17:27:06.079041][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 1, Steps performed: 1000

[2020-01-28 17:27:06.079524][EnvironmentNew.Environment.log][rollouts]: Rollout thread #3

[2020-01-28 17:27:06.079989][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2

[2020-01-28 17:27:06.080053][EnvironmentNew.Environment.log][rollouts]: Rollout thread #4

[2020-01-28 17:27:06.082127][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3

[2020-01-28 17:27:08.198897][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 2, Steps performed: 1000

[2020-01-28 17:27:08.237805][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 3, Steps performed: 1000

[2020-01-28 17:27:08.238277][EnvironmentNew.Environment.log][rollouts]: Rollout thread #5

[2020-01-28 17:27:08.238857][EnvironmentNew.Environment.log][rollouts]: Rollout thread #6

[2020-01-28 17:27:08.238813][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4

[2020-01-28 17:27:08.239800][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5

[2020-01-28 17:27:10.417806][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 4, Steps performed: 1000

[2020-01-28 17:27:10.455277][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 5, Steps performed: 1000

[2020-01-28 17:27:10.455726][EnvironmentNew.Environment.log][rollouts]: Rollout thread #7

[2020-01-28 17:27:10.456285][EnvironmentNew.Environment.log][rollouts]: Rollout thread #8

[2020-01-28 17:27:10.456228][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6

[2020-01-28 17:27:10.457091][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7

[2020-01-28 17:27:12.566689][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 6, Steps performed: 1000

[2020-01-28 17:27:12.593041][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 7, Steps performed: 1000

[2020-01-28 17:27:12.593497][EnvironmentNew.Environment.log][rollouts]: Rollout thread #9

[2020-01-28 17:27:12.594034][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8

[2020-01-28 17:27:12.594097][EnvironmentNew.Environment.log][rollouts]: Rollout thread #10

[2020-01-28 17:27:12.596972][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9

[2020-01-28 17:27:14.686182][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 8, Steps performed: 1000

[2020-01-28 17:27:14.735639][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 9, Steps performed: 1000

[2020-01-28 17:27:14.736103][EnvironmentNew.Environment.log][rollouts]: Rollout thread #11

[2020-01-28 17:27:14.736674][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 10

[2020-01-28 17:27:14.736724][EnvironmentNew.Environment.log][rollouts]: Rollout thread #12

[2020-01-28 17:27:14.738839][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 11

[2020-01-28 17:27:16.949254][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 10, Steps performed: 1000

[2020-01-28 17:27:16.962430][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 11, Steps performed: 1000

[2020-01-28 17:27:16.962921][EnvironmentNew.Environment.log][rollouts]: Rollout thread #13

[2020-01-28 17:27:16.963535][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 12

[2020-01-28 17:27:16.963590][EnvironmentNew.Environment.log][rollouts]: Rollout thread #14

[2020-01-28 17:27:16.966668][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 13

[2020-01-28 17:27:19.132440][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 12, Steps performed: 1000

[2020-01-28 17:27:19.160945][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 13, Steps performed: 1000

[2020-01-28 17:27:19.161450][EnvironmentNew.Environment.log][rollouts]: Rollout thread #15

[2020-01-28 17:27:19.161934][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 14

[2020-01-28 17:27:20.311261][EnvironmentNew.Environment.log][thread_rollouts]: Thread number: 14, Steps performed: 1000

[2020-01-28 17:27:20.318699][__main__.TRPOAgent.log][learning]: Rollouts performed

[2020-01-28 17:27:20.337084][__main__.TRPOAgent.log][batch_info]: Rollout statistics size: 15000, Batch size: 1000, Number of batches: 1

[2020-01-28 17:27:20.337475][__main__.TRPOAgent.log][learning]: 

***************
BEGINNING TRAINING
***************



[2020-01-28 17:27:20.342927][__main__.TRPOAgent.log][batch_info]: Batch #0, batch length: 15000

[2020-01-28 17:27:20.379529][__main__.TRPOAgent.log][training]: policy_gradient: [ 0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.         -0.00291536  0.00126725  0.00164811]

[2020-01-28 17:27:20.379942][__main__.TRPOAgent.log][training]: Initiating conjugate gradients

[2020-01-28 17:27:20.428994][__main__.TRPOAgent.log][training]: gradient_step_direction: [ 0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.         -0.00869961  0.00378155  0.00491806]

[2020-01-28 17:27:20.725997][__main__.TRPOAgent.log][linesearch]: Linesearch failed. Mean kl divergence: -2.9999999490520353e-08, Discarded policy loss value: -1.6863547595373043e-16

[2020-01-28 17:27:23.054305][__main__.TRPOAgent.log][batch_info]: Current batch value loss: 406.55236084791255

